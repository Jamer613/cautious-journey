2023-04-18 17:16:00,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-18 17:16:00,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-18 17:16:00,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-18 17:16:00,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-18 17:16:01,892:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-18 17:17:23,512:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-18 17:17:23,512:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-18 17:17:23,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-18 17:17:23,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-18 17:17:25,186:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-18 17:23:43,768:WARNING:C:\Users\User\AppData\Local\Temp\ipykernel_4856\2777188505.py:3: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.
  from pandas_profiling import ProfileReport

2023-04-19 10:29:45,156:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-19 10:29:45,156:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-19 10:29:45,156:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-19 10:29:45,156:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-19 10:29:48,007:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-19 10:29:54,576:WARNING:C:\Users\User\AppData\Local\Temp\ipykernel_244\2777188505.py:3: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.
  from pandas_profiling import ProfileReport

2023-04-19 10:56:40,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-19 10:56:40,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-19 10:56:40,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-19 10:56:40,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-19 10:56:42,067:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-19 10:56:45,267:WARNING:C:\Users\User\AppData\Local\Temp\ipykernel_9800\2777188505.py:3: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.
  from pandas_profiling import ProfileReport

2023-04-19 11:42:53,843:INFO:PyCaret ClassificationExperiment
2023-04-19 11:42:53,843:INFO:Logging name: clf-default-name
2023-04-19 11:42:53,843:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-19 11:42:53,843:INFO:version 3.0.0
2023-04-19 11:42:53,843:INFO:Initializing setup()
2023-04-19 11:42:53,843:INFO:self.USI: 0eb6
2023-04-19 11:42:53,843:INFO:self._variable_keys: {'exp_id', 'gpu_param', 'X_train', 'X', 'logging_param', 'fix_imbalance', 'y', 'pipeline', 'target_param', 'fold_groups_param', 'seed', 'n_jobs_param', 'memory', 'y_test', 'y_train', 'X_test', 'is_multiclass', 'data', 'fold_generator', '_available_plots', 'html_param', 'gpu_n_jobs_param', '_ml_usecase', 'USI', 'exp_name_log', 'fold_shuffle_param', 'idx', 'log_plots_param'}
2023-04-19 11:42:53,843:INFO:Checking environment
2023-04-19 11:42:53,843:INFO:python_version: 3.10.9
2023-04-19 11:42:53,843:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-04-19 11:42:53,843:INFO:machine: AMD64
2023-04-19 11:42:53,843:INFO:platform: Windows-10-10.0.19044-SP0
2023-04-19 11:42:53,843:INFO:Memory: svmem(total=8483184640, available=3685785600, percent=56.6, used=4797399040, free=3685785600)
2023-04-19 11:42:53,843:INFO:Physical Core: 2
2023-04-19 11:42:53,843:INFO:Logical Core: 4
2023-04-19 11:42:53,843:INFO:Checking libraries
2023-04-19 11:42:53,843:INFO:System:
2023-04-19 11:42:53,843:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-04-19 11:42:53,843:INFO:executable: C:\Users\User\.conda\envs\My_envI\python.exe
2023-04-19 11:42:53,843:INFO:   machine: Windows-10-10.0.19044-SP0
2023-04-19 11:42:53,843:INFO:PyCaret required dependencies:
2023-04-19 11:42:53,843:INFO:                 pip: 22.3.1
2023-04-19 11:42:53,843:INFO:          setuptools: 66.0.0
2023-04-19 11:42:53,843:INFO:             pycaret: 3.0.0
2023-04-19 11:42:53,843:INFO:             IPython: 8.12.0
2023-04-19 11:42:53,843:INFO:          ipywidgets: 7.6.5
2023-04-19 11:42:53,843:INFO:                tqdm: 4.64.1
2023-04-19 11:42:53,843:INFO:               numpy: 1.23.5
2023-04-19 11:42:53,843:INFO:              pandas: 1.5.3
2023-04-19 11:42:53,843:INFO:              jinja2: 3.1.2
2023-04-19 11:42:53,843:INFO:               scipy: 1.10.1
2023-04-19 11:42:53,843:INFO:              joblib: 1.2.0
2023-04-19 11:42:53,843:INFO:             sklearn: 1.2.1
2023-04-19 11:42:53,843:INFO:                pyod: 1.0.9
2023-04-19 11:42:53,843:INFO:            imblearn: 0.10.1
2023-04-19 11:42:53,843:INFO:   category_encoders: 2.6.0
2023-04-19 11:42:53,843:INFO:            lightgbm: 3.3.5
2023-04-19 11:42:53,843:INFO:               numba: 0.56.4
2023-04-19 11:42:53,843:INFO:            requests: 2.28.1
2023-04-19 11:42:53,843:INFO:          matplotlib: 3.7.0
2023-04-19 11:42:53,843:INFO:          scikitplot: 0.3.7
2023-04-19 11:42:53,843:INFO:         yellowbrick: 1.5
2023-04-19 11:42:53,843:INFO:              plotly: 5.14.1
2023-04-19 11:42:53,853:INFO:             kaleido: 0.2.1
2023-04-19 11:42:53,853:INFO:         statsmodels: 0.13.5
2023-04-19 11:42:53,853:INFO:              sktime: 0.17.0
2023-04-19 11:42:53,853:INFO:               tbats: 1.1.2
2023-04-19 11:42:53,853:INFO:            pmdarima: 2.0.3
2023-04-19 11:42:53,853:INFO:              psutil: 5.9.0
2023-04-19 11:42:53,853:INFO:PyCaret optional dependencies:
2023-04-19 11:42:54,753:INFO:                shap: 0.41.0
2023-04-19 11:42:54,753:INFO:           interpret: 0.3.2
2023-04-19 11:42:54,753:INFO:                umap: 0.5.3
2023-04-19 11:42:54,753:INFO:    pandas_profiling: 4.1.2
2023-04-19 11:42:54,753:INFO:  explainerdashboard: 0.4.2.1
2023-04-19 11:42:54,753:INFO:             autoviz: 0.1.58
2023-04-19 11:42:54,753:INFO:           fairlearn: 0.7.0
2023-04-19 11:42:54,753:INFO:             xgboost: 1.7.5
2023-04-19 11:42:54,753:INFO:            catboost: 1.1.1
2023-04-19 11:42:54,753:INFO:              kmodes: 0.12.2
2023-04-19 11:42:54,753:INFO:             mlxtend: 0.22.0
2023-04-19 11:42:54,753:INFO:       statsforecast: 1.5.0
2023-04-19 11:42:54,753:INFO:        tune_sklearn: 0.4.5
2023-04-19 11:42:54,753:INFO:                 ray: 2.3.1
2023-04-19 11:42:54,753:INFO:            hyperopt: 0.2.7
2023-04-19 11:42:54,753:INFO:              optuna: 3.1.0
2023-04-19 11:42:54,753:INFO:               skopt: 0.9.0
2023-04-19 11:42:54,753:INFO:              mlflow: 1.30.1
2023-04-19 11:42:54,753:INFO:              gradio: Not installed
2023-04-19 11:42:54,753:INFO:             fastapi: 0.89.1
2023-04-19 11:42:54,753:INFO:             uvicorn: 0.21.1
2023-04-19 11:42:54,753:INFO:              m2cgen: 0.10.0
2023-04-19 11:42:54,753:INFO:           evidently: 0.2.8
2023-04-19 11:42:54,753:INFO:               fugue: 0.8.3
2023-04-19 11:42:54,753:INFO:           streamlit: Not installed
2023-04-19 11:42:54,753:INFO:             prophet: Not installed
2023-04-19 11:42:54,753:INFO:None
2023-04-19 11:42:54,753:INFO:Set up data.
2023-04-19 11:42:54,773:INFO:Set up train/test split.
2023-04-19 11:42:54,793:INFO:Set up index.
2023-04-19 11:42:54,793:INFO:Set up folding strategy.
2023-04-19 11:42:54,793:INFO:Assigning column types.
2023-04-19 11:42:54,803:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-19 11:42:54,877:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 11:42:54,883:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:42:54,973:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:42:55,861:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:42:56,189:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 11:42:56,189:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:42:56,248:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:42:56,253:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:42:56,253:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-19 11:42:56,333:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:42:56,393:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:42:56,393:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:42:56,484:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:42:56,543:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:42:56,548:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:42:57,073:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-19 11:42:57,223:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:42:57,228:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:42:57,388:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:42:57,393:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:42:57,403:INFO:Preparing preprocessing pipeline...
2023-04-19 11:42:57,413:INFO:Set up label encoding.
2023-04-19 11:42:57,413:INFO:Set up simple imputation.
2023-04-19 11:42:57,423:INFO:Set up encoding of ordinal features.
2023-04-19 11:42:57,428:INFO:Set up encoding of categorical features.
2023-04-19 11:42:57,433:INFO:Set up imbalanced handling.
2023-04-19 11:42:57,433:INFO:Set up feature selection.
2023-04-19 11:42:57,578:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:42:57,583:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:42:59,008:INFO:Finished creating preprocessing pipeline.
2023-04-19 11:42:59,164:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=10,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2023-04-19 11:42:59,166:INFO:Creating final display dataframe.
2023-04-19 11:43:01,083:INFO:Setup _display_container:                     Description                      Value
0                    Session id                        123
1                        Target                      class
2                   Target type                     Binary
3                Target mapping  Aprovado: 0, Reprovado: 1
4           Original data shape                  (950, 22)
5        Transformed data shape                 (1217, 11)
6   Transformed train set shape                  (932, 11)
7    Transformed test set shape                  (285, 11)
8              Ordinal features                          3
9              Numeric features                         10
10         Categorical features                         11
11                   Preprocess                       True
12              Imputation type                     simple
13           Numeric imputation                       mean
14       Categorical imputation                       mode
15     Maximum one-hot encoding                         25
16              Encoding method                       None
17                Fix imbalance                       True
18         Fix imbalance method                      SMOTE
19            Feature selection                       True
20     Feature selection method                    classic
21  Feature selection estimator                   lightgbm
22  Number of features selected                        0.5
23               Fold Generator            StratifiedKFold
24                  Fold Number                         10
25                     CPU Jobs                         -1
26                      Use GPU                      False
27               Log Experiment                      False
28              Experiment Name           clf-default-name
29                          USI                       0eb6
2023-04-19 11:43:01,283:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:43:01,288:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:43:01,411:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:43:01,413:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:43:01,413:INFO:setup() successfully completed in 9.52s...............
2023-04-19 11:46:42,088:INFO:Initializing get_config()
2023-04-19 11:46:42,088:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D5637FF10>, variable=X_transformed)
2023-04-19 11:46:42,378:INFO:Variable: X returned as      checking_status  duration  credit_history_existing paid  credit_amount  \
266              1.0      24.0                           1.0         1285.0   
400              2.0       9.0                           1.0         3195.0   
395              1.0       6.0                           0.0         1957.0   
553              0.0      30.0                           0.0         4272.0   
560              1.0      12.0                           1.0         1228.0   
..               ...       ...                           ...            ...   
290              1.0      24.0                           0.0         6419.0   
770              0.0      15.0                           1.0         1979.0   
257              2.0       9.0                           1.0         1199.0   
878              2.0      18.0                           0.0         2899.0   
278              2.0      16.0                           0.0         1175.0   

     savings_status  employment  installment_commitment  residence_since  \
266             0.0         3.0                     4.0              4.0   
400             0.0         2.0                     1.0              2.0   
395             1.0         3.0                     1.0              4.0   
553             2.0         2.0                     2.0              2.0   
560             1.0         2.0                     4.0              2.0   
..              ...         ...                     ...              ...   
290             1.0         4.0                     2.0              4.0   
770             0.0         4.0                     4.0              2.0   
257             1.0         3.0                     4.0              4.0   
878             0.0         4.0                     4.0              4.0   
278             1.0         0.0                     2.0              3.0   

      age  own_telephone  
266  32.0            0.0  
400  33.0            0.0  
395  31.0            0.0  
553  26.0            0.0  
560  24.0            0.0  
..    ...            ...  
290  44.0            1.0  
770  35.0            0.0  
257  67.0            1.0  
878  43.0            0.0  
278  68.0            1.0  

[1217 rows x 10 columns]
2023-04-19 11:46:42,378:INFO:get_config() successfully completed......................................
2023-04-19 11:48:52,223:INFO:PyCaret ClassificationExperiment
2023-04-19 11:48:52,223:INFO:Logging name: clf-default-name
2023-04-19 11:48:52,223:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-19 11:48:52,223:INFO:version 3.0.0
2023-04-19 11:48:52,223:INFO:Initializing setup()
2023-04-19 11:48:52,223:INFO:self.USI: 0e9b
2023-04-19 11:48:52,223:INFO:self._variable_keys: {'exp_id', 'gpu_param', 'X_train', 'X', 'logging_param', 'fix_imbalance', 'y', 'pipeline', 'target_param', 'fold_groups_param', 'seed', 'n_jobs_param', 'memory', 'y_test', 'y_train', 'X_test', 'is_multiclass', 'data', 'fold_generator', '_available_plots', 'html_param', 'gpu_n_jobs_param', '_ml_usecase', 'USI', 'exp_name_log', 'fold_shuffle_param', 'idx', 'log_plots_param'}
2023-04-19 11:48:52,223:INFO:Checking environment
2023-04-19 11:48:52,223:INFO:python_version: 3.10.9
2023-04-19 11:48:52,223:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-04-19 11:48:52,223:INFO:machine: AMD64
2023-04-19 11:48:52,223:INFO:platform: Windows-10-10.0.19044-SP0
2023-04-19 11:48:52,223:INFO:Memory: svmem(total=8483184640, available=3395112960, percent=60.0, used=5088071680, free=3395112960)
2023-04-19 11:48:52,223:INFO:Physical Core: 2
2023-04-19 11:48:52,223:INFO:Logical Core: 4
2023-04-19 11:48:52,223:INFO:Checking libraries
2023-04-19 11:48:52,223:INFO:System:
2023-04-19 11:48:52,223:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-04-19 11:48:52,223:INFO:executable: C:\Users\User\.conda\envs\My_envI\python.exe
2023-04-19 11:48:52,223:INFO:   machine: Windows-10-10.0.19044-SP0
2023-04-19 11:48:52,223:INFO:PyCaret required dependencies:
2023-04-19 11:48:52,223:INFO:                 pip: 22.3.1
2023-04-19 11:48:52,223:INFO:          setuptools: 66.0.0
2023-04-19 11:48:52,223:INFO:             pycaret: 3.0.0
2023-04-19 11:48:52,223:INFO:             IPython: 8.12.0
2023-04-19 11:48:52,223:INFO:          ipywidgets: 7.6.5
2023-04-19 11:48:52,223:INFO:                tqdm: 4.64.1
2023-04-19 11:48:52,223:INFO:               numpy: 1.23.5
2023-04-19 11:48:52,223:INFO:              pandas: 1.5.3
2023-04-19 11:48:52,223:INFO:              jinja2: 3.1.2
2023-04-19 11:48:52,223:INFO:               scipy: 1.10.1
2023-04-19 11:48:52,223:INFO:              joblib: 1.2.0
2023-04-19 11:48:52,223:INFO:             sklearn: 1.2.1
2023-04-19 11:48:52,223:INFO:                pyod: 1.0.9
2023-04-19 11:48:52,223:INFO:            imblearn: 0.10.1
2023-04-19 11:48:52,223:INFO:   category_encoders: 2.6.0
2023-04-19 11:48:52,223:INFO:            lightgbm: 3.3.5
2023-04-19 11:48:52,223:INFO:               numba: 0.56.4
2023-04-19 11:48:52,223:INFO:            requests: 2.28.1
2023-04-19 11:48:52,223:INFO:          matplotlib: 3.7.0
2023-04-19 11:48:52,223:INFO:          scikitplot: 0.3.7
2023-04-19 11:48:52,223:INFO:         yellowbrick: 1.5
2023-04-19 11:48:52,223:INFO:              plotly: 5.14.1
2023-04-19 11:48:52,223:INFO:             kaleido: 0.2.1
2023-04-19 11:48:52,223:INFO:         statsmodels: 0.13.5
2023-04-19 11:48:52,223:INFO:              sktime: 0.17.0
2023-04-19 11:48:52,223:INFO:               tbats: 1.1.2
2023-04-19 11:48:52,223:INFO:            pmdarima: 2.0.3
2023-04-19 11:48:52,223:INFO:              psutil: 5.9.0
2023-04-19 11:48:52,223:INFO:PyCaret optional dependencies:
2023-04-19 11:48:52,223:INFO:                shap: 0.41.0
2023-04-19 11:48:52,223:INFO:           interpret: 0.3.2
2023-04-19 11:48:52,223:INFO:                umap: 0.5.3
2023-04-19 11:48:52,223:INFO:    pandas_profiling: 4.1.2
2023-04-19 11:48:52,223:INFO:  explainerdashboard: 0.4.2.1
2023-04-19 11:48:52,223:INFO:             autoviz: 0.1.58
2023-04-19 11:48:52,223:INFO:           fairlearn: 0.7.0
2023-04-19 11:48:52,223:INFO:             xgboost: 1.7.5
2023-04-19 11:48:52,223:INFO:            catboost: 1.1.1
2023-04-19 11:48:52,223:INFO:              kmodes: 0.12.2
2023-04-19 11:48:52,223:INFO:             mlxtend: 0.22.0
2023-04-19 11:48:52,223:INFO:       statsforecast: 1.5.0
2023-04-19 11:48:52,223:INFO:        tune_sklearn: 0.4.5
2023-04-19 11:48:52,223:INFO:                 ray: 2.3.1
2023-04-19 11:48:52,223:INFO:            hyperopt: 0.2.7
2023-04-19 11:48:52,223:INFO:              optuna: 3.1.0
2023-04-19 11:48:52,223:INFO:               skopt: 0.9.0
2023-04-19 11:48:52,223:INFO:              mlflow: 1.30.1
2023-04-19 11:48:52,223:INFO:              gradio: Not installed
2023-04-19 11:48:52,223:INFO:             fastapi: 0.89.1
2023-04-19 11:48:52,223:INFO:             uvicorn: 0.21.1
2023-04-19 11:48:52,223:INFO:              m2cgen: 0.10.0
2023-04-19 11:48:52,223:INFO:           evidently: 0.2.8
2023-04-19 11:48:52,233:INFO:               fugue: 0.8.3
2023-04-19 11:48:52,233:INFO:           streamlit: Not installed
2023-04-19 11:48:52,233:INFO:             prophet: Not installed
2023-04-19 11:48:52,233:INFO:None
2023-04-19 11:48:52,233:INFO:Set up data.
2023-04-19 11:48:52,248:INFO:Set up train/test split.
2023-04-19 11:48:52,263:INFO:Set up index.
2023-04-19 11:48:52,263:INFO:Set up folding strategy.
2023-04-19 11:48:52,263:INFO:Assigning column types.
2023-04-19 11:48:52,269:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-19 11:48:52,348:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 11:48:52,348:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:48:52,393:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:48:52,393:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:48:52,473:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 11:48:52,473:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:48:52,513:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:48:52,524:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:48:52,524:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-19 11:48:52,600:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:48:52,643:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:48:52,648:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:48:52,725:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:48:52,798:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:48:52,798:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:48:52,803:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-19 11:48:52,969:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:48:52,973:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:48:53,133:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:48:53,138:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:48:53,138:INFO:Preparing preprocessing pipeline...
2023-04-19 11:48:53,143:INFO:Set up label encoding.
2023-04-19 11:48:53,143:INFO:Set up simple imputation.
2023-04-19 11:48:53,148:INFO:Set up encoding of ordinal features.
2023-04-19 11:48:53,158:INFO:Set up encoding of categorical features.
2023-04-19 11:48:53,158:INFO:Set up imbalanced handling.
2023-04-19 11:48:53,158:INFO:Set up feature selection.
2023-04-19 11:48:53,313:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:48:53,318:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:48:54,044:INFO:Finished creating preprocessing pipeline.
2023-04-19 11:48:54,173:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=14,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2023-04-19 11:48:54,173:INFO:Creating final display dataframe.
2023-04-19 11:48:55,593:INFO:Setup _display_container:                     Description                      Value
0                    Session id                        123
1                        Target                      class
2                   Target type                     Binary
3                Target mapping  Aprovado: 0, Reprovado: 1
4           Original data shape                  (950, 22)
5        Transformed data shape                 (1217, 15)
6   Transformed train set shape                  (932, 15)
7    Transformed test set shape                  (285, 15)
8              Ordinal features                          3
9              Numeric features                         10
10         Categorical features                         11
11                   Preprocess                       True
12              Imputation type                     simple
13           Numeric imputation                       mean
14       Categorical imputation                       mode
15     Maximum one-hot encoding                         25
16              Encoding method                       None
17                Fix imbalance                       True
18         Fix imbalance method                      SMOTE
19            Feature selection                       True
20     Feature selection method                    classic
21  Feature selection estimator                   lightgbm
22  Number of features selected                        0.7
23               Fold Generator            StratifiedKFold
24                  Fold Number                         10
25                     CPU Jobs                         -1
26                      Use GPU                      False
27               Log Experiment                      False
28              Experiment Name           clf-default-name
29                          USI                       0e9b
2023-04-19 11:48:55,753:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:48:55,763:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:48:55,889:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:48:55,894:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:48:55,895:INFO:setup() successfully completed in 4.92s...............
2023-04-19 11:49:01,981:INFO:Initializing get_config()
2023-04-19 11:49:01,982:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55FAE470>, variable=X_transformed)
2023-04-19 11:49:02,258:INFO:Variable: X returned as      checking_status  duration  credit_history_existing paid  \
266              1.0      24.0                           1.0   
400              2.0       9.0                           1.0   
395              1.0       6.0                           0.0   
553              0.0      30.0                           0.0   
560              1.0      12.0                           1.0   
..               ...       ...                           ...   
290              1.0      24.0                           0.0   
770              0.0      15.0                           1.0   
257              2.0       9.0                           1.0   
878              2.0      18.0                           0.0   
278              2.0      16.0                           0.0   

     credit_history_critical/other existing credit  purpose_new car  \
266                                            0.0              1.0   
400                                            0.0              1.0   
395                                            1.0              0.0   
553                                            0.0              0.0   
560                                            0.0              1.0   
..                                             ...              ...   
290                                            1.0              0.0   
770                                            0.0              0.0   
257                                            0.0              0.0   
878                                            0.0              1.0   
278                                            1.0              1.0   

     credit_amount  savings_status  employment  installment_commitment  \
266         1285.0             0.0         3.0                     4.0   
400         3195.0             0.0         2.0                     1.0   
395         1957.0             1.0         3.0                     1.0   
553         4272.0             2.0         2.0                     2.0   
560         1228.0             1.0         2.0                     4.0   
..             ...             ...         ...                     ...   
290         6419.0             1.0         4.0                     2.0   
770         1979.0             0.0         4.0                     4.0   
257         1199.0             1.0         3.0                     4.0   
878         2899.0             0.0         4.0                     4.0   
278         1175.0             1.0         0.0                     2.0   

     residence_since   age  existing_credits  job_skilled  own_telephone  
266              4.0  32.0               1.0          1.0            0.0  
400              2.0  33.0               1.0          0.0            0.0  
395              4.0  31.0               1.0          1.0            0.0  
553              2.0  26.0               2.0          0.0            0.0  
560              2.0  24.0               1.0          0.0            0.0  
..               ...   ...               ...          ...            ...  
290              4.0  44.0               2.0          0.0            1.0  
770              2.0  35.0               1.0          1.0            0.0  
257              4.0  67.0               2.0          0.0            1.0  
878              4.0  43.0               1.0          1.0            0.0  
278              3.0  68.0               3.0          0.0            1.0  

[1217 rows x 14 columns]
2023-04-19 11:49:02,259:INFO:get_config() successfully completed......................................
2023-04-19 11:50:18,641:INFO:PyCaret ClassificationExperiment
2023-04-19 11:50:18,641:INFO:Logging name: clf-default-name
2023-04-19 11:50:18,641:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-19 11:50:18,641:INFO:version 3.0.0
2023-04-19 11:50:18,641:INFO:Initializing setup()
2023-04-19 11:50:18,641:INFO:self.USI: 7e25
2023-04-19 11:50:18,641:INFO:self._variable_keys: {'exp_id', 'gpu_param', 'X_train', 'X', 'logging_param', 'fix_imbalance', 'y', 'pipeline', 'target_param', 'fold_groups_param', 'seed', 'n_jobs_param', 'memory', 'y_test', 'y_train', 'X_test', 'is_multiclass', 'data', 'fold_generator', '_available_plots', 'html_param', 'gpu_n_jobs_param', '_ml_usecase', 'USI', 'exp_name_log', 'fold_shuffle_param', 'idx', 'log_plots_param'}
2023-04-19 11:50:18,641:INFO:Checking environment
2023-04-19 11:50:18,642:INFO:python_version: 3.10.9
2023-04-19 11:50:18,642:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-04-19 11:50:18,642:INFO:machine: AMD64
2023-04-19 11:50:18,642:INFO:platform: Windows-10-10.0.19044-SP0
2023-04-19 11:50:18,642:INFO:Memory: svmem(total=8483184640, available=3547492352, percent=58.2, used=4935692288, free=3547492352)
2023-04-19 11:50:18,642:INFO:Physical Core: 2
2023-04-19 11:50:18,642:INFO:Logical Core: 4
2023-04-19 11:50:18,642:INFO:Checking libraries
2023-04-19 11:50:18,642:INFO:System:
2023-04-19 11:50:18,643:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-04-19 11:50:18,643:INFO:executable: C:\Users\User\.conda\envs\My_envI\python.exe
2023-04-19 11:50:18,643:INFO:   machine: Windows-10-10.0.19044-SP0
2023-04-19 11:50:18,643:INFO:PyCaret required dependencies:
2023-04-19 11:50:18,643:INFO:                 pip: 22.3.1
2023-04-19 11:50:18,643:INFO:          setuptools: 66.0.0
2023-04-19 11:50:18,643:INFO:             pycaret: 3.0.0
2023-04-19 11:50:18,643:INFO:             IPython: 8.12.0
2023-04-19 11:50:18,643:INFO:          ipywidgets: 7.6.5
2023-04-19 11:50:18,643:INFO:                tqdm: 4.64.1
2023-04-19 11:50:18,643:INFO:               numpy: 1.23.5
2023-04-19 11:50:18,643:INFO:              pandas: 1.5.3
2023-04-19 11:50:18,644:INFO:              jinja2: 3.1.2
2023-04-19 11:50:18,644:INFO:               scipy: 1.10.1
2023-04-19 11:50:18,644:INFO:              joblib: 1.2.0
2023-04-19 11:50:18,644:INFO:             sklearn: 1.2.1
2023-04-19 11:50:18,644:INFO:                pyod: 1.0.9
2023-04-19 11:50:18,644:INFO:            imblearn: 0.10.1
2023-04-19 11:50:18,644:INFO:   category_encoders: 2.6.0
2023-04-19 11:50:18,644:INFO:            lightgbm: 3.3.5
2023-04-19 11:50:18,644:INFO:               numba: 0.56.4
2023-04-19 11:50:18,644:INFO:            requests: 2.28.1
2023-04-19 11:50:18,645:INFO:          matplotlib: 3.7.0
2023-04-19 11:50:18,645:INFO:          scikitplot: 0.3.7
2023-04-19 11:50:18,645:INFO:         yellowbrick: 1.5
2023-04-19 11:50:18,645:INFO:              plotly: 5.14.1
2023-04-19 11:50:18,645:INFO:             kaleido: 0.2.1
2023-04-19 11:50:18,645:INFO:         statsmodels: 0.13.5
2023-04-19 11:50:18,645:INFO:              sktime: 0.17.0
2023-04-19 11:50:18,645:INFO:               tbats: 1.1.2
2023-04-19 11:50:18,645:INFO:            pmdarima: 2.0.3
2023-04-19 11:50:18,645:INFO:              psutil: 5.9.0
2023-04-19 11:50:18,645:INFO:PyCaret optional dependencies:
2023-04-19 11:50:18,645:INFO:                shap: 0.41.0
2023-04-19 11:50:18,646:INFO:           interpret: 0.3.2
2023-04-19 11:50:18,646:INFO:                umap: 0.5.3
2023-04-19 11:50:18,646:INFO:    pandas_profiling: 4.1.2
2023-04-19 11:50:18,646:INFO:  explainerdashboard: 0.4.2.1
2023-04-19 11:50:18,646:INFO:             autoviz: 0.1.58
2023-04-19 11:50:18,646:INFO:           fairlearn: 0.7.0
2023-04-19 11:50:18,646:INFO:             xgboost: 1.7.5
2023-04-19 11:50:18,646:INFO:            catboost: 1.1.1
2023-04-19 11:50:18,646:INFO:              kmodes: 0.12.2
2023-04-19 11:50:18,646:INFO:             mlxtend: 0.22.0
2023-04-19 11:50:18,646:INFO:       statsforecast: 1.5.0
2023-04-19 11:50:18,646:INFO:        tune_sklearn: 0.4.5
2023-04-19 11:50:18,647:INFO:                 ray: 2.3.1
2023-04-19 11:50:18,647:INFO:            hyperopt: 0.2.7
2023-04-19 11:50:18,647:INFO:              optuna: 3.1.0
2023-04-19 11:50:18,647:INFO:               skopt: 0.9.0
2023-04-19 11:50:18,647:INFO:              mlflow: 1.30.1
2023-04-19 11:50:18,647:INFO:              gradio: Not installed
2023-04-19 11:50:18,647:INFO:             fastapi: 0.89.1
2023-04-19 11:50:18,647:INFO:             uvicorn: 0.21.1
2023-04-19 11:50:18,647:INFO:              m2cgen: 0.10.0
2023-04-19 11:50:18,647:INFO:           evidently: 0.2.8
2023-04-19 11:50:18,647:INFO:               fugue: 0.8.3
2023-04-19 11:50:18,647:INFO:           streamlit: Not installed
2023-04-19 11:50:18,647:INFO:             prophet: Not installed
2023-04-19 11:50:18,647:INFO:None
2023-04-19 11:50:18,648:INFO:Set up data.
2023-04-19 11:50:18,663:INFO:Set up train/test split.
2023-04-19 11:50:18,683:INFO:Set up index.
2023-04-19 11:50:18,683:INFO:Set up folding strategy.
2023-04-19 11:50:18,683:INFO:Assigning column types.
2023-04-19 11:50:18,683:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-19 11:50:18,757:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 11:50:18,757:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:50:18,793:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:50:18,803:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:50:18,873:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 11:50:18,873:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:50:18,915:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:50:18,915:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:50:18,915:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-19 11:50:18,993:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:50:19,038:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:50:19,043:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:50:19,116:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:50:19,158:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:50:19,163:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:50:19,163:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-19 11:50:19,284:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:50:19,284:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:50:19,394:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:50:19,394:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:50:19,394:INFO:Preparing preprocessing pipeline...
2023-04-19 11:50:19,404:INFO:Set up label encoding.
2023-04-19 11:50:19,404:INFO:Set up simple imputation.
2023-04-19 11:50:19,404:INFO:Set up encoding of ordinal features.
2023-04-19 11:50:19,417:INFO:Set up encoding of categorical features.
2023-04-19 11:50:19,417:INFO:Set up imbalanced handling.
2023-04-19 11:50:19,417:INFO:Set up feature selection.
2023-04-19 11:50:19,527:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:50:19,533:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:50:20,130:INFO:Finished creating preprocessing pipeline.
2023-04-19 11:50:20,253:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=12,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2023-04-19 11:50:20,253:INFO:Creating final display dataframe.
2023-04-19 11:50:21,673:INFO:Setup _display_container:                     Description                      Value
0                    Session id                        123
1                        Target                      class
2                   Target type                     Binary
3                Target mapping  Aprovado: 0, Reprovado: 1
4           Original data shape                  (950, 22)
5        Transformed data shape                 (1217, 13)
6   Transformed train set shape                  (932, 13)
7    Transformed test set shape                  (285, 13)
8              Ordinal features                          3
9              Numeric features                         10
10         Categorical features                         11
11                   Preprocess                       True
12              Imputation type                     simple
13           Numeric imputation                       mean
14       Categorical imputation                       mode
15     Maximum one-hot encoding                         25
16              Encoding method                       None
17                Fix imbalance                       True
18         Fix imbalance method                      SMOTE
19            Feature selection                       True
20     Feature selection method                    classic
21  Feature selection estimator                   lightgbm
22  Number of features selected                        0.6
23               Fold Generator            StratifiedKFold
24                  Fold Number                         10
25                     CPU Jobs                         -1
26                      Use GPU                      False
27               Log Experiment                      False
28              Experiment Name           clf-default-name
29                          USI                       7e25
2023-04-19 11:50:21,838:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:50:21,843:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:50:21,955:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:50:21,955:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:50:21,955:INFO:setup() successfully completed in 4.32s...............
2023-04-19 11:50:27,474:INFO:Initializing get_config()
2023-04-19 11:50:27,474:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55FAE4D0>, variable=X_transformed)
2023-04-19 11:50:27,768:INFO:Variable: X returned as      checking_status  duration  credit_history_existing paid  credit_amount  \
266              1.0      24.0                           1.0         1285.0   
400              2.0       9.0                           1.0         3195.0   
395              1.0       6.0                           0.0         1957.0   
553              0.0      30.0                           0.0         4272.0   
560              1.0      12.0                           1.0         1228.0   
..               ...       ...                           ...            ...   
290              1.0      24.0                           0.0         6419.0   
770              0.0      15.0                           1.0         1979.0   
257              2.0       9.0                           1.0         1199.0   
878              2.0      18.0                           0.0         2899.0   
278              2.0      16.0                           0.0         1175.0   

     savings_status  employment  installment_commitment  residence_since  \
266             0.0         3.0                     4.0              4.0   
400             0.0         2.0                     1.0              2.0   
395             1.0         3.0                     1.0              4.0   
553             2.0         2.0                     2.0              2.0   
560             1.0         2.0                     4.0              2.0   
..              ...         ...                     ...              ...   
290             1.0         4.0                     2.0              4.0   
770             0.0         4.0                     4.0              2.0   
257             1.0         3.0                     4.0              4.0   
878             0.0         4.0                     4.0              4.0   
278             1.0         0.0                     2.0              3.0   

      age  existing_credits  job_skilled  own_telephone  
266  32.0               1.0          1.0            0.0  
400  33.0               1.0          0.0            0.0  
395  31.0               1.0          1.0            0.0  
553  26.0               2.0          0.0            0.0  
560  24.0               1.0          0.0            0.0  
..    ...               ...          ...            ...  
290  44.0               2.0          0.0            1.0  
770  35.0               1.0          1.0            0.0  
257  67.0               2.0          0.0            1.0  
878  43.0               1.0          1.0            0.0  
278  68.0               3.0          0.0            1.0  

[1217 rows x 12 columns]
2023-04-19 11:50:27,768:INFO:get_config() successfully completed......................................
2023-04-19 11:56:01,763:INFO:PyCaret ClassificationExperiment
2023-04-19 11:56:01,763:INFO:Logging name: clf-default-name
2023-04-19 11:56:01,763:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-19 11:56:01,763:INFO:version 3.0.0
2023-04-19 11:56:01,763:INFO:Initializing setup()
2023-04-19 11:56:01,763:INFO:self.USI: bf1d
2023-04-19 11:56:01,763:INFO:self._variable_keys: {'exp_id', 'gpu_param', 'X_train', 'X', 'logging_param', 'fix_imbalance', 'y', 'pipeline', 'target_param', 'fold_groups_param', 'seed', 'n_jobs_param', 'memory', 'y_test', 'y_train', 'X_test', 'is_multiclass', 'data', 'fold_generator', '_available_plots', 'html_param', 'gpu_n_jobs_param', '_ml_usecase', 'USI', 'exp_name_log', 'fold_shuffle_param', 'idx', 'log_plots_param'}
2023-04-19 11:56:01,763:INFO:Checking environment
2023-04-19 11:56:01,763:INFO:python_version: 3.10.9
2023-04-19 11:56:01,763:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-04-19 11:56:01,763:INFO:machine: AMD64
2023-04-19 11:56:01,763:INFO:platform: Windows-10-10.0.19044-SP0
2023-04-19 11:56:01,763:INFO:Memory: svmem(total=8483184640, available=3474702336, percent=59.0, used=5008482304, free=3474702336)
2023-04-19 11:56:01,763:INFO:Physical Core: 2
2023-04-19 11:56:01,763:INFO:Logical Core: 4
2023-04-19 11:56:01,763:INFO:Checking libraries
2023-04-19 11:56:01,763:INFO:System:
2023-04-19 11:56:01,763:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-04-19 11:56:01,763:INFO:executable: C:\Users\User\.conda\envs\My_envI\python.exe
2023-04-19 11:56:01,763:INFO:   machine: Windows-10-10.0.19044-SP0
2023-04-19 11:56:01,763:INFO:PyCaret required dependencies:
2023-04-19 11:56:01,763:INFO:                 pip: 22.3.1
2023-04-19 11:56:01,768:INFO:          setuptools: 66.0.0
2023-04-19 11:56:01,768:INFO:             pycaret: 3.0.0
2023-04-19 11:56:01,768:INFO:             IPython: 8.12.0
2023-04-19 11:56:01,768:INFO:          ipywidgets: 7.6.5
2023-04-19 11:56:01,768:INFO:                tqdm: 4.64.1
2023-04-19 11:56:01,768:INFO:               numpy: 1.23.5
2023-04-19 11:56:01,768:INFO:              pandas: 1.5.3
2023-04-19 11:56:01,768:INFO:              jinja2: 3.1.2
2023-04-19 11:56:01,768:INFO:               scipy: 1.10.1
2023-04-19 11:56:01,768:INFO:              joblib: 1.2.0
2023-04-19 11:56:01,768:INFO:             sklearn: 1.2.1
2023-04-19 11:56:01,768:INFO:                pyod: 1.0.9
2023-04-19 11:56:01,768:INFO:            imblearn: 0.10.1
2023-04-19 11:56:01,768:INFO:   category_encoders: 2.6.0
2023-04-19 11:56:01,768:INFO:            lightgbm: 3.3.5
2023-04-19 11:56:01,768:INFO:               numba: 0.56.4
2023-04-19 11:56:01,768:INFO:            requests: 2.28.1
2023-04-19 11:56:01,768:INFO:          matplotlib: 3.7.0
2023-04-19 11:56:01,768:INFO:          scikitplot: 0.3.7
2023-04-19 11:56:01,768:INFO:         yellowbrick: 1.5
2023-04-19 11:56:01,768:INFO:              plotly: 5.14.1
2023-04-19 11:56:01,768:INFO:             kaleido: 0.2.1
2023-04-19 11:56:01,768:INFO:         statsmodels: 0.13.5
2023-04-19 11:56:01,768:INFO:              sktime: 0.17.0
2023-04-19 11:56:01,768:INFO:               tbats: 1.1.2
2023-04-19 11:56:01,768:INFO:            pmdarima: 2.0.3
2023-04-19 11:56:01,768:INFO:              psutil: 5.9.0
2023-04-19 11:56:01,768:INFO:PyCaret optional dependencies:
2023-04-19 11:56:01,773:INFO:                shap: 0.41.0
2023-04-19 11:56:01,773:INFO:           interpret: 0.3.2
2023-04-19 11:56:01,773:INFO:                umap: 0.5.3
2023-04-19 11:56:01,773:INFO:    pandas_profiling: 4.1.2
2023-04-19 11:56:01,773:INFO:  explainerdashboard: 0.4.2.1
2023-04-19 11:56:01,773:INFO:             autoviz: 0.1.58
2023-04-19 11:56:01,773:INFO:           fairlearn: 0.7.0
2023-04-19 11:56:01,773:INFO:             xgboost: 1.7.5
2023-04-19 11:56:01,773:INFO:            catboost: 1.1.1
2023-04-19 11:56:01,773:INFO:              kmodes: 0.12.2
2023-04-19 11:56:01,773:INFO:             mlxtend: 0.22.0
2023-04-19 11:56:01,773:INFO:       statsforecast: 1.5.0
2023-04-19 11:56:01,773:INFO:        tune_sklearn: 0.4.5
2023-04-19 11:56:01,773:INFO:                 ray: 2.3.1
2023-04-19 11:56:01,773:INFO:            hyperopt: 0.2.7
2023-04-19 11:56:01,773:INFO:              optuna: 3.1.0
2023-04-19 11:56:01,773:INFO:               skopt: 0.9.0
2023-04-19 11:56:01,773:INFO:              mlflow: 1.30.1
2023-04-19 11:56:01,778:INFO:              gradio: Not installed
2023-04-19 11:56:01,778:INFO:             fastapi: 0.89.1
2023-04-19 11:56:01,778:INFO:             uvicorn: 0.21.1
2023-04-19 11:56:01,778:INFO:              m2cgen: 0.10.0
2023-04-19 11:56:01,778:INFO:           evidently: 0.2.8
2023-04-19 11:56:01,778:INFO:               fugue: 0.8.3
2023-04-19 11:56:01,778:INFO:           streamlit: Not installed
2023-04-19 11:56:01,778:INFO:             prophet: Not installed
2023-04-19 11:56:01,778:INFO:None
2023-04-19 11:56:01,778:INFO:Set up data.
2023-04-19 11:56:01,823:INFO:Set up train/test split.
2023-04-19 11:56:01,838:INFO:Set up index.
2023-04-19 11:56:01,838:INFO:Set up folding strategy.
2023-04-19 11:56:01,838:INFO:Assigning column types.
2023-04-19 11:56:01,848:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-19 11:56:01,968:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 11:56:01,973:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:56:02,038:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:56:02,048:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:56:02,163:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 11:56:02,168:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:56:02,238:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:56:02,244:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:56:02,245:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-19 11:56:02,343:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:56:02,408:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:56:02,413:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:56:02,513:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:56:02,583:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:56:02,583:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:56:02,583:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-19 11:56:02,763:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:56:02,773:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:56:02,928:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:56:02,933:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:56:02,933:INFO:Preparing preprocessing pipeline...
2023-04-19 11:56:02,943:INFO:Set up label encoding.
2023-04-19 11:56:02,943:INFO:Set up simple imputation.
2023-04-19 11:56:02,958:INFO:Set up encoding of ordinal features.
2023-04-19 11:56:02,968:INFO:Set up encoding of categorical features.
2023-04-19 11:56:02,968:INFO:Set up imbalanced handling.
2023-04-19 11:56:02,968:INFO:Set up feature normalization.
2023-04-19 11:56:02,968:INFO:Set up feature selection.
2023-04-19 11:56:03,133:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:56:03,133:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:56:04,016:INFO:Finished creating preprocessing pipeline.
2023-04-19 11:56:04,163:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=12,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2023-04-19 11:56:04,163:INFO:Creating final display dataframe.
2023-04-19 11:56:05,857:INFO:Setup _display_container:                     Description                      Value
0                    Session id                        123
1                        Target                      class
2                   Target type                     Binary
3                Target mapping  Aprovado: 0, Reprovado: 1
4           Original data shape                  (950, 22)
5        Transformed data shape                 (1217, 13)
6   Transformed train set shape                  (932, 13)
7    Transformed test set shape                  (285, 13)
8              Ordinal features                          3
9              Numeric features                         10
10         Categorical features                         11
11                   Preprocess                       True
12              Imputation type                     simple
13           Numeric imputation                       mean
14       Categorical imputation                       mode
15     Maximum one-hot encoding                         25
16              Encoding method                       None
17                Fix imbalance                       True
18         Fix imbalance method                      SMOTE
19                    Normalize                       True
20             Normalize method                     zscore
21            Feature selection                       True
22     Feature selection method                    classic
23  Feature selection estimator                   lightgbm
24  Number of features selected                        0.6
25               Fold Generator            StratifiedKFold
26                  Fold Number                         10
27                     CPU Jobs                         -1
28                      Use GPU                      False
29               Log Experiment                      False
30              Experiment Name           clf-default-name
31                          USI                       bf1d
2023-04-19 11:56:06,073:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:56:06,078:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:56:06,293:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:56:06,308:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:56:06,308:INFO:setup() successfully completed in 5.81s...............
2023-04-19 11:56:23,542:INFO:Initializing get_config()
2023-04-19 11:56:23,542:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55E6F460>, variable=X_transformed)
2023-04-19 11:56:23,828:INFO:Variable: X returned as      checking_status  duration  credit_history_existing paid  credit_amount  \
266        -0.053981  0.125761                      0.982481      -0.718957   
400         1.103171 -1.058204                      0.982481      -0.097589   
395        -0.053981 -1.294997                     -1.139648      -0.500340   
553        -1.211133  0.599347                     -1.139648       0.252785   
560        -0.053981 -0.821411                      0.982481      -0.737501   
..               ...       ...                           ...            ...   
290        -0.053981  0.125761                     -1.139648       0.951255   
770        -1.211133 -0.584618                      0.982481      -0.493183   
257         1.103171 -1.058204                      0.982481      -0.746935   
878         1.103171 -0.347825                     -1.139648      -0.193885   
278         1.103171 -0.505687                     -1.139648      -0.754743   

     savings_status  employment  installment_commitment  residence_since  \
266       -1.325900    0.565950                0.905883         1.106884   
400       -1.325900   -0.334262               -1.921811        -0.825338   
395       -0.194245    0.565950               -1.921811         1.106884   
553        0.937409   -0.334262               -0.979246        -0.825338   
560       -0.194245   -0.334262                0.905883        -0.825338   
..              ...         ...                     ...              ...   
290       -0.194245    1.466161               -0.979246         1.106884   
770       -1.325900    1.466161                0.905883        -0.825338   
257       -0.194245    0.565950                0.905883         1.106884   
878       -1.325900    1.466161                0.905883         1.106884   
278       -0.194245   -2.134685               -0.979246         0.140773   

          age  job_skilled  own_telephone  marital_status_single  
266 -0.262527     0.808087      -0.858986              -1.105950  
400 -0.169268    -1.385769      -0.858986              -1.105950  
395 -0.355787     0.808087      -0.858986              -1.105950  
553 -0.822085    -1.385769      -0.858986               1.010603  
560 -1.008604    -1.385769      -0.858986              -1.105950  
..        ...          ...            ...                    ...  
290  0.856587    -1.385769       1.254460              -1.105950  
770  0.017251     0.808087      -0.858986               1.010603  
257  3.001557    -1.385769       1.254460              -1.105950  
878  0.763328     0.808087      -0.858986               1.010603  
278  3.094817    -1.385769       1.254460               1.010603  

[1217 rows x 12 columns]
2023-04-19 11:56:23,828:INFO:get_config() successfully completed......................................
2023-04-19 11:57:51,628:INFO:PyCaret ClassificationExperiment
2023-04-19 11:57:51,628:INFO:Logging name: clf-default-name
2023-04-19 11:57:51,628:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-19 11:57:51,628:INFO:version 3.0.0
2023-04-19 11:57:51,628:INFO:Initializing setup()
2023-04-19 11:57:51,628:INFO:self.USI: a13b
2023-04-19 11:57:51,628:INFO:self._variable_keys: {'exp_id', 'gpu_param', 'X_train', 'X', 'logging_param', 'fix_imbalance', 'y', 'pipeline', 'target_param', 'fold_groups_param', 'seed', 'n_jobs_param', 'memory', 'y_test', 'y_train', 'X_test', 'is_multiclass', 'data', 'fold_generator', '_available_plots', 'html_param', 'gpu_n_jobs_param', '_ml_usecase', 'USI', 'exp_name_log', 'fold_shuffle_param', 'idx', 'log_plots_param'}
2023-04-19 11:57:51,628:INFO:Checking environment
2023-04-19 11:57:51,628:INFO:python_version: 3.10.9
2023-04-19 11:57:51,628:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-04-19 11:57:51,628:INFO:machine: AMD64
2023-04-19 11:57:51,628:INFO:platform: Windows-10-10.0.19044-SP0
2023-04-19 11:57:51,628:INFO:Memory: svmem(total=8483184640, available=3516067840, percent=58.6, used=4967116800, free=3516067840)
2023-04-19 11:57:51,628:INFO:Physical Core: 2
2023-04-19 11:57:51,628:INFO:Logical Core: 4
2023-04-19 11:57:51,628:INFO:Checking libraries
2023-04-19 11:57:51,628:INFO:System:
2023-04-19 11:57:51,628:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-04-19 11:57:51,628:INFO:executable: C:\Users\User\.conda\envs\My_envI\python.exe
2023-04-19 11:57:51,628:INFO:   machine: Windows-10-10.0.19044-SP0
2023-04-19 11:57:51,628:INFO:PyCaret required dependencies:
2023-04-19 11:57:51,633:INFO:                 pip: 22.3.1
2023-04-19 11:57:51,633:INFO:          setuptools: 66.0.0
2023-04-19 11:57:51,633:INFO:             pycaret: 3.0.0
2023-04-19 11:57:51,633:INFO:             IPython: 8.12.0
2023-04-19 11:57:51,633:INFO:          ipywidgets: 7.6.5
2023-04-19 11:57:51,633:INFO:                tqdm: 4.64.1
2023-04-19 11:57:51,633:INFO:               numpy: 1.23.5
2023-04-19 11:57:51,633:INFO:              pandas: 1.5.3
2023-04-19 11:57:51,633:INFO:              jinja2: 3.1.2
2023-04-19 11:57:51,633:INFO:               scipy: 1.10.1
2023-04-19 11:57:51,633:INFO:              joblib: 1.2.0
2023-04-19 11:57:51,633:INFO:             sklearn: 1.2.1
2023-04-19 11:57:51,633:INFO:                pyod: 1.0.9
2023-04-19 11:57:51,633:INFO:            imblearn: 0.10.1
2023-04-19 11:57:51,633:INFO:   category_encoders: 2.6.0
2023-04-19 11:57:51,633:INFO:            lightgbm: 3.3.5
2023-04-19 11:57:51,633:INFO:               numba: 0.56.4
2023-04-19 11:57:51,633:INFO:            requests: 2.28.1
2023-04-19 11:57:51,633:INFO:          matplotlib: 3.7.0
2023-04-19 11:57:51,633:INFO:          scikitplot: 0.3.7
2023-04-19 11:57:51,633:INFO:         yellowbrick: 1.5
2023-04-19 11:57:51,633:INFO:              plotly: 5.14.1
2023-04-19 11:57:51,633:INFO:             kaleido: 0.2.1
2023-04-19 11:57:51,633:INFO:         statsmodels: 0.13.5
2023-04-19 11:57:51,633:INFO:              sktime: 0.17.0
2023-04-19 11:57:51,633:INFO:               tbats: 1.1.2
2023-04-19 11:57:51,633:INFO:            pmdarima: 2.0.3
2023-04-19 11:57:51,633:INFO:              psutil: 5.9.0
2023-04-19 11:57:51,633:INFO:PyCaret optional dependencies:
2023-04-19 11:57:51,633:INFO:                shap: 0.41.0
2023-04-19 11:57:51,633:INFO:           interpret: 0.3.2
2023-04-19 11:57:51,633:INFO:                umap: 0.5.3
2023-04-19 11:57:51,633:INFO:    pandas_profiling: 4.1.2
2023-04-19 11:57:51,633:INFO:  explainerdashboard: 0.4.2.1
2023-04-19 11:57:51,633:INFO:             autoviz: 0.1.58
2023-04-19 11:57:51,633:INFO:           fairlearn: 0.7.0
2023-04-19 11:57:51,633:INFO:             xgboost: 1.7.5
2023-04-19 11:57:51,633:INFO:            catboost: 1.1.1
2023-04-19 11:57:51,633:INFO:              kmodes: 0.12.2
2023-04-19 11:57:51,633:INFO:             mlxtend: 0.22.0
2023-04-19 11:57:51,633:INFO:       statsforecast: 1.5.0
2023-04-19 11:57:51,633:INFO:        tune_sklearn: 0.4.5
2023-04-19 11:57:51,633:INFO:                 ray: 2.3.1
2023-04-19 11:57:51,633:INFO:            hyperopt: 0.2.7
2023-04-19 11:57:51,633:INFO:              optuna: 3.1.0
2023-04-19 11:57:51,633:INFO:               skopt: 0.9.0
2023-04-19 11:57:51,633:INFO:              mlflow: 1.30.1
2023-04-19 11:57:51,633:INFO:              gradio: Not installed
2023-04-19 11:57:51,633:INFO:             fastapi: 0.89.1
2023-04-19 11:57:51,633:INFO:             uvicorn: 0.21.1
2023-04-19 11:57:51,633:INFO:              m2cgen: 0.10.0
2023-04-19 11:57:51,639:INFO:           evidently: 0.2.8
2023-04-19 11:57:51,639:INFO:               fugue: 0.8.3
2023-04-19 11:57:51,639:INFO:           streamlit: Not installed
2023-04-19 11:57:51,639:INFO:             prophet: Not installed
2023-04-19 11:57:51,639:INFO:None
2023-04-19 11:57:51,639:INFO:Set up data.
2023-04-19 11:57:51,663:INFO:Set up train/test split.
2023-04-19 11:57:51,678:INFO:Set up index.
2023-04-19 11:57:51,678:INFO:Set up folding strategy.
2023-04-19 11:57:51,684:INFO:Assigning column types.
2023-04-19 11:57:51,688:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-19 11:57:51,774:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 11:57:51,779:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:57:51,843:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:57:51,848:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:57:51,933:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 11:57:51,933:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:57:52,003:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:57:52,008:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:57:52,008:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-19 11:57:52,113:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:57:52,167:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:57:52,179:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:57:52,273:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-19 11:57:52,328:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:57:52,333:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:57:52,333:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-19 11:57:52,493:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:57:52,493:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:57:52,638:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:57:52,643:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:57:52,643:INFO:Preparing preprocessing pipeline...
2023-04-19 11:57:52,643:INFO:Set up label encoding.
2023-04-19 11:57:52,643:INFO:Set up simple imputation.
2023-04-19 11:57:52,654:INFO:Set up encoding of ordinal features.
2023-04-19 11:57:52,664:INFO:Set up encoding of categorical features.
2023-04-19 11:57:52,664:INFO:Set up imbalanced handling.
2023-04-19 11:57:52,664:INFO:Set up feature normalization.
2023-04-19 11:57:52,664:INFO:Set up feature selection.
2023-04-19 11:57:52,813:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:57:52,833:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:57:53,358:INFO:Finished creating preprocessing pipeline.
2023-04-19 11:57:53,520:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=12,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2023-04-19 11:57:53,520:INFO:Creating final display dataframe.
2023-04-19 11:57:54,044:INFO:Setup _display_container:                     Description                      Value
0                    Session id                        123
1                        Target                      class
2                   Target type                     Binary
3                Target mapping  Aprovado: 0, Reprovado: 1
4           Original data shape                  (950, 22)
5        Transformed data shape                 (1217, 13)
6   Transformed train set shape                  (932, 13)
7    Transformed test set shape                  (285, 13)
8              Ordinal features                          3
9              Numeric features                         10
10         Categorical features                         11
11                   Preprocess                       True
12              Imputation type                     simple
13           Numeric imputation                       mean
14       Categorical imputation                       mode
15     Maximum one-hot encoding                         25
16              Encoding method                       None
17                Fix imbalance                       True
18         Fix imbalance method                      SMOTE
19                    Normalize                       True
20             Normalize method                     zscore
21            Feature selection                       True
22     Feature selection method                    classic
23  Feature selection estimator                   lightgbm
24  Number of features selected                        0.6
25               Fold Generator            StratifiedKFold
26                  Fold Number                         10
27                     CPU Jobs                         -1
28                      Use GPU                      False
29               Log Experiment                      False
30              Experiment Name           clf-default-name
31                          USI                       a13b
2023-04-19 11:57:54,268:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:57:54,273:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:57:54,428:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-19 11:57:54,438:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-19 11:57:54,438:INFO:setup() successfully completed in 3.84s...............
2023-04-19 11:57:58,755:INFO:Initializing get_config()
2023-04-19 11:57:58,756:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, variable=X_transformed)
2023-04-19 11:57:59,023:INFO:Variable: X returned as      checking_status  duration  credit_history_existing paid  credit_amount  \
266        -0.053981  0.125761                      0.982481      -0.718957   
400         1.103171 -1.058204                      0.982481      -0.097589   
395        -0.053981 -1.294997                     -1.139648      -0.500340   
553        -1.211133  0.599347                     -1.139648       0.252785   
560        -0.053981 -0.821411                      0.982481      -0.737501   
..               ...       ...                           ...            ...   
290        -0.053981  0.125761                     -1.139648       0.951255   
770        -1.211133 -0.584618                      0.982481      -0.493183   
257         1.103171 -1.058204                      0.982481      -0.746935   
878         1.103171 -0.347825                     -1.139648      -0.193885   
278         1.103171 -0.505687                     -1.139648      -0.754743   

     savings_status  employment  installment_commitment  residence_since  \
266       -1.325900    0.565950                0.905883         1.106884   
400       -1.325900   -0.334262               -1.921811        -0.825338   
395       -0.194245    0.565950               -1.921811         1.106884   
553        0.937409   -0.334262               -0.979246        -0.825338   
560       -0.194245   -0.334262                0.905883        -0.825338   
..              ...         ...                     ...              ...   
290       -0.194245    1.466161               -0.979246         1.106884   
770       -1.325900    1.466161                0.905883        -0.825338   
257       -0.194245    0.565950                0.905883         1.106884   
878       -1.325900    1.466161                0.905883         1.106884   
278       -0.194245   -2.134685               -0.979246         0.140773   

          age  job_skilled  own_telephone  marital_status_single  
266 -0.262527     0.808087      -0.858986              -1.105950  
400 -0.169268    -1.385769      -0.858986              -1.105950  
395 -0.355787     0.808087      -0.858986              -1.105950  
553 -0.822085    -1.385769      -0.858986               1.010603  
560 -1.008604    -1.385769      -0.858986              -1.105950  
..        ...          ...            ...                    ...  
290  0.856587    -1.385769       1.254460              -1.105950  
770  0.017251     0.808087      -0.858986               1.010603  
257  3.001557    -1.385769       1.254460              -1.105950  
878  0.763328     0.808087      -0.858986               1.010603  
278  3.094817    -1.385769       1.254460               1.010603  

[1217 rows x 12 columns]
2023-04-19 11:57:59,023:INFO:get_config() successfully completed......................................
2023-04-19 14:39:49,891:INFO:Initializing compare_models()
2023-04-19 14:39:49,891:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-19 14:39:49,892:INFO:Checking exceptions
2023-04-19 14:39:49,907:INFO:Preparing display monitor
2023-04-19 14:39:49,999:INFO:Initializing Logistic Regression
2023-04-19 14:39:49,999:INFO:Total runtime is 1.672506332397461e-05 minutes
2023-04-19 14:39:50,022:INFO:SubProcess create_model() called ==================================
2023-04-19 14:39:50,023:INFO:Initializing create_model()
2023-04-19 14:39:50,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D55CBB8E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:39:50,023:INFO:Checking exceptions
2023-04-19 14:39:50,024:INFO:Importing libraries
2023-04-19 14:39:50,024:INFO:Copying training dataset
2023-04-19 14:39:50,052:INFO:Defining folds
2023-04-19 14:39:50,053:INFO:Declaring metric variables
2023-04-19 14:39:50,066:INFO:Importing untrained model
2023-04-19 14:39:50,076:INFO:Logistic Regression Imported successfully
2023-04-19 14:39:50,102:INFO:Starting cross validation
2023-04-19 14:39:50,152:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 14:40:33,525:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:40:34,008:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:40:34,173:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:40:34,220:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:40:40,842:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:40:45,535:INFO:Calculating mean and std
2023-04-19 14:40:45,551:INFO:Creating metrics dataframe
2023-04-19 14:40:47,159:INFO:Uploading results into container
2023-04-19 14:40:47,159:INFO:Uploading model into container now
2023-04-19 14:40:47,159:INFO:_master_model_container: 1
2023-04-19 14:40:47,159:INFO:_display_container: 2
2023-04-19 14:40:47,159:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-19 14:40:47,159:INFO:create_model() successfully completed......................................
2023-04-19 14:40:47,402:INFO:SubProcess create_model() end ==================================
2023-04-19 14:40:47,402:INFO:Creating metrics dataframe
2023-04-19 14:40:47,417:INFO:Initializing K Neighbors Classifier
2023-04-19 14:40:47,417:INFO:Total runtime is 0.9569814046223958 minutes
2023-04-19 14:40:47,437:INFO:SubProcess create_model() called ==================================
2023-04-19 14:40:47,438:INFO:Initializing create_model()
2023-04-19 14:40:47,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D55CBB8E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:40:47,439:INFO:Checking exceptions
2023-04-19 14:40:47,439:INFO:Importing libraries
2023-04-19 14:40:47,439:INFO:Copying training dataset
2023-04-19 14:40:47,447:INFO:Defining folds
2023-04-19 14:40:47,447:INFO:Declaring metric variables
2023-04-19 14:40:47,466:INFO:Importing untrained model
2023-04-19 14:40:47,479:INFO:K Neighbors Classifier Imported successfully
2023-04-19 14:40:47,498:INFO:Starting cross validation
2023-04-19 14:40:47,529:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 14:40:50,099:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:40:51,537:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:40:56,878:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:40:56,925:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:40:57,232:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:40:57,471:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:40:58,429:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:40:58,476:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:40:58,820:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:41:04,755:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:41:11,195:INFO:Calculating mean and std
2023-04-19 14:41:11,211:INFO:Creating metrics dataframe
2023-04-19 14:41:13,493:INFO:Uploading results into container
2023-04-19 14:41:13,493:INFO:Uploading model into container now
2023-04-19 14:41:13,493:INFO:_master_model_container: 2
2023-04-19 14:41:13,493:INFO:_display_container: 2
2023-04-19 14:41:13,498:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-19 14:41:13,498:INFO:create_model() successfully completed......................................
2023-04-19 14:41:13,703:INFO:SubProcess create_model() end ==================================
2023-04-19 14:41:13,703:INFO:Creating metrics dataframe
2023-04-19 14:41:13,722:INFO:Initializing Naive Bayes
2023-04-19 14:41:13,723:INFO:Total runtime is 1.3954168518384298 minutes
2023-04-19 14:41:13,731:INFO:SubProcess create_model() called ==================================
2023-04-19 14:41:13,732:INFO:Initializing create_model()
2023-04-19 14:41:13,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D55CBB8E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:41:13,733:INFO:Checking exceptions
2023-04-19 14:41:13,733:INFO:Importing libraries
2023-04-19 14:41:13,734:INFO:Copying training dataset
2023-04-19 14:41:13,751:INFO:Defining folds
2023-04-19 14:41:13,752:INFO:Declaring metric variables
2023-04-19 14:41:13,767:INFO:Importing untrained model
2023-04-19 14:41:13,767:INFO:Naive Bayes Imported successfully
2023-04-19 14:41:13,800:INFO:Starting cross validation
2023-04-19 14:41:13,830:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 14:41:20,231:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:41:20,247:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:41:20,372:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:41:20,596:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:41:32,635:INFO:Calculating mean and std
2023-04-19 14:41:32,651:INFO:Creating metrics dataframe
2023-04-19 14:41:34,206:INFO:Uploading results into container
2023-04-19 14:41:34,206:INFO:Uploading model into container now
2023-04-19 14:41:34,206:INFO:_master_model_container: 3
2023-04-19 14:41:34,206:INFO:_display_container: 2
2023-04-19 14:41:34,222:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-19 14:41:34,222:INFO:create_model() successfully completed......................................
2023-04-19 14:41:34,420:INFO:SubProcess create_model() end ==================================
2023-04-19 14:41:34,420:INFO:Creating metrics dataframe
2023-04-19 14:41:34,436:INFO:Initializing Decision Tree Classifier
2023-04-19 14:41:34,436:INFO:Total runtime is 1.7406253655751547 minutes
2023-04-19 14:41:34,452:INFO:SubProcess create_model() called ==================================
2023-04-19 14:41:34,453:INFO:Initializing create_model()
2023-04-19 14:41:34,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D55CBB8E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:41:34,454:INFO:Checking exceptions
2023-04-19 14:41:34,454:INFO:Importing libraries
2023-04-19 14:41:34,455:INFO:Copying training dataset
2023-04-19 14:41:34,473:INFO:Defining folds
2023-04-19 14:41:34,474:INFO:Declaring metric variables
2023-04-19 14:41:34,482:INFO:Importing untrained model
2023-04-19 14:41:34,495:INFO:Decision Tree Classifier Imported successfully
2023-04-19 14:41:34,514:INFO:Starting cross validation
2023-04-19 14:41:34,550:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 14:41:36,566:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:41:41,344:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:41:41,438:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:41:41,611:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:41:41,822:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:41:53,622:INFO:Calculating mean and std
2023-04-19 14:41:53,638:INFO:Creating metrics dataframe
2023-04-19 14:41:56,050:INFO:Uploading results into container
2023-04-19 14:41:56,050:INFO:Uploading model into container now
2023-04-19 14:41:56,050:INFO:_master_model_container: 4
2023-04-19 14:41:56,050:INFO:_display_container: 2
2023-04-19 14:41:56,050:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-04-19 14:41:56,050:INFO:create_model() successfully completed......................................
2023-04-19 14:41:56,286:INFO:SubProcess create_model() end ==================================
2023-04-19 14:41:56,286:INFO:Creating metrics dataframe
2023-04-19 14:41:56,302:INFO:Initializing SVM - Linear Kernel
2023-04-19 14:41:56,302:INFO:Total runtime is 2.105052447319031 minutes
2023-04-19 14:41:56,325:INFO:SubProcess create_model() called ==================================
2023-04-19 14:41:56,326:INFO:Initializing create_model()
2023-04-19 14:41:56,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D55CBB8E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:41:56,327:INFO:Checking exceptions
2023-04-19 14:41:56,328:INFO:Importing libraries
2023-04-19 14:41:56,328:INFO:Copying training dataset
2023-04-19 14:41:56,348:INFO:Defining folds
2023-04-19 14:41:56,349:INFO:Declaring metric variables
2023-04-19 14:41:56,365:INFO:Importing untrained model
2023-04-19 14:41:56,380:INFO:SVM - Linear Kernel Imported successfully
2023-04-19 14:41:56,404:INFO:Starting cross validation
2023-04-19 14:41:56,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 14:41:58,463:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-19 14:41:58,463:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-19 14:41:58,463:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-19 14:42:03,198:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:42:03,214:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-19 14:42:03,308:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:42:03,308:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-19 14:42:03,402:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:42:03,417:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-19 14:42:03,495:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:42:03,523:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-19 14:42:07,562:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-19 14:42:07,609:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-19 14:42:15,437:INFO:Calculating mean and std
2023-04-19 14:42:15,437:INFO:Creating metrics dataframe
2023-04-19 14:42:17,168:INFO:Uploading results into container
2023-04-19 14:42:17,168:INFO:Uploading model into container now
2023-04-19 14:42:17,168:INFO:_master_model_container: 5
2023-04-19 14:42:17,168:INFO:_display_container: 2
2023-04-19 14:42:17,168:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-19 14:42:17,168:INFO:create_model() successfully completed......................................
2023-04-19 14:42:17,369:INFO:SubProcess create_model() end ==================================
2023-04-19 14:42:17,369:INFO:Creating metrics dataframe
2023-04-19 14:42:17,391:INFO:Initializing Ridge Classifier
2023-04-19 14:42:17,391:INFO:Total runtime is 2.456537973880768 minutes
2023-04-19 14:42:17,404:INFO:SubProcess create_model() called ==================================
2023-04-19 14:42:17,404:INFO:Initializing create_model()
2023-04-19 14:42:17,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D55CBB8E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:42:17,404:INFO:Checking exceptions
2023-04-19 14:42:17,404:INFO:Importing libraries
2023-04-19 14:42:17,404:INFO:Copying training dataset
2023-04-19 14:42:17,424:INFO:Defining folds
2023-04-19 14:42:17,427:INFO:Declaring metric variables
2023-04-19 14:42:17,442:INFO:Importing untrained model
2023-04-19 14:42:17,454:INFO:Ridge Classifier Imported successfully
2023-04-19 14:42:17,473:INFO:Starting cross validation
2023-04-19 14:42:17,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 14:42:19,212:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-19 14:42:19,212:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-19 14:42:19,227:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-19 14:42:19,274:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-19 14:42:23,698:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:42:23,698:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-19 14:42:23,719:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:42:23,726:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-19 14:42:23,745:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:42:23,745:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-19 14:42:23,760:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:42:23,760:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-19 14:42:28,118:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-19 14:42:28,171:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-19 14:42:35,756:INFO:Calculating mean and std
2023-04-19 14:42:35,756:INFO:Creating metrics dataframe
2023-04-19 14:42:37,316:INFO:Uploading results into container
2023-04-19 14:42:37,316:INFO:Uploading model into container now
2023-04-19 14:42:37,316:INFO:_master_model_container: 6
2023-04-19 14:42:37,325:INFO:_display_container: 2
2023-04-19 14:42:37,327:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-04-19 14:42:37,327:INFO:create_model() successfully completed......................................
2023-04-19 14:42:37,511:INFO:SubProcess create_model() end ==================================
2023-04-19 14:42:37,511:INFO:Creating metrics dataframe
2023-04-19 14:42:37,527:INFO:Initializing Random Forest Classifier
2023-04-19 14:42:37,527:INFO:Total runtime is 2.792144628365835 minutes
2023-04-19 14:42:37,546:INFO:SubProcess create_model() called ==================================
2023-04-19 14:42:37,546:INFO:Initializing create_model()
2023-04-19 14:42:37,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D55CBB8E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:42:37,546:INFO:Checking exceptions
2023-04-19 14:42:37,546:INFO:Importing libraries
2023-04-19 14:42:37,546:INFO:Copying training dataset
2023-04-19 14:42:37,562:INFO:Defining folds
2023-04-19 14:42:37,562:INFO:Declaring metric variables
2023-04-19 14:42:37,581:INFO:Importing untrained model
2023-04-19 14:42:37,590:INFO:Random Forest Classifier Imported successfully
2023-04-19 14:42:37,610:INFO:Starting cross validation
2023-04-19 14:42:37,636:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 14:42:41,018:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:42:41,018:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:42:41,049:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:42:41,175:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:42:48,724:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:42:48,724:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:42:48,927:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:42:49,946:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:42:55,883:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:42:55,898:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:03,478:INFO:Calculating mean and std
2023-04-19 14:43:03,478:INFO:Creating metrics dataframe
2023-04-19 14:43:05,765:INFO:Uploading results into container
2023-04-19 14:43:05,765:INFO:Uploading model into container now
2023-04-19 14:43:05,765:INFO:_master_model_container: 7
2023-04-19 14:43:05,765:INFO:_display_container: 2
2023-04-19 14:43:05,765:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-19 14:43:05,765:INFO:create_model() successfully completed......................................
2023-04-19 14:43:05,971:INFO:SubProcess create_model() end ==================================
2023-04-19 14:43:05,971:INFO:Creating metrics dataframe
2023-04-19 14:43:05,987:INFO:Initializing Quadratic Discriminant Analysis
2023-04-19 14:43:05,987:INFO:Total runtime is 3.266475808620453 minutes
2023-04-19 14:43:06,007:INFO:SubProcess create_model() called ==================================
2023-04-19 14:43:06,007:INFO:Initializing create_model()
2023-04-19 14:43:06,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D55CBB8E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:43:06,008:INFO:Checking exceptions
2023-04-19 14:43:06,008:INFO:Importing libraries
2023-04-19 14:43:06,009:INFO:Copying training dataset
2023-04-19 14:43:06,026:INFO:Defining folds
2023-04-19 14:43:06,026:INFO:Declaring metric variables
2023-04-19 14:43:06,041:INFO:Importing untrained model
2023-04-19 14:43:06,054:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-19 14:43:06,073:INFO:Starting cross validation
2023-04-19 14:43:06,099:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 14:43:12,388:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:12,579:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:12,598:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:12,792:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:25,329:INFO:Calculating mean and std
2023-04-19 14:43:25,329:INFO:Creating metrics dataframe
2023-04-19 14:43:26,941:INFO:Uploading results into container
2023-04-19 14:43:26,941:INFO:Uploading model into container now
2023-04-19 14:43:26,941:INFO:_master_model_container: 8
2023-04-19 14:43:26,941:INFO:_display_container: 2
2023-04-19 14:43:26,941:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-19 14:43:26,941:INFO:create_model() successfully completed......................................
2023-04-19 14:43:27,120:INFO:SubProcess create_model() end ==================================
2023-04-19 14:43:27,135:INFO:Creating metrics dataframe
2023-04-19 14:43:27,157:INFO:Initializing Ada Boost Classifier
2023-04-19 14:43:27,157:INFO:Total runtime is 3.6193082769711813 minutes
2023-04-19 14:43:27,174:INFO:SubProcess create_model() called ==================================
2023-04-19 14:43:27,174:INFO:Initializing create_model()
2023-04-19 14:43:27,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D55CBB8E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:43:27,174:INFO:Checking exceptions
2023-04-19 14:43:27,174:INFO:Importing libraries
2023-04-19 14:43:27,174:INFO:Copying training dataset
2023-04-19 14:43:27,193:INFO:Defining folds
2023-04-19 14:43:27,193:INFO:Declaring metric variables
2023-04-19 14:43:27,203:INFO:Importing untrained model
2023-04-19 14:43:27,220:INFO:Ada Boost Classifier Imported successfully
2023-04-19 14:43:27,234:INFO:Starting cross validation
2023-04-19 14:43:27,258:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 14:43:29,965:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:29,965:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:29,965:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:29,981:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:36,402:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:36,527:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:36,573:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:36,730:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:42,307:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:42,385:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:50,157:INFO:Calculating mean and std
2023-04-19 14:43:50,172:INFO:Creating metrics dataframe
2023-04-19 14:43:52,832:INFO:Uploading results into container
2023-04-19 14:43:52,832:INFO:Uploading model into container now
2023-04-19 14:43:52,847:INFO:_master_model_container: 9
2023-04-19 14:43:52,847:INFO:_display_container: 2
2023-04-19 14:43:52,847:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-04-19 14:43:52,847:INFO:create_model() successfully completed......................................
2023-04-19 14:43:53,081:INFO:SubProcess create_model() end ==================================
2023-04-19 14:43:53,082:INFO:Creating metrics dataframe
2023-04-19 14:43:53,105:INFO:Initializing Gradient Boosting Classifier
2023-04-19 14:43:53,105:INFO:Total runtime is 4.051782091458638 minutes
2023-04-19 14:43:53,105:INFO:SubProcess create_model() called ==================================
2023-04-19 14:43:53,105:INFO:Initializing create_model()
2023-04-19 14:43:53,121:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D55CBB8E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:43:53,121:INFO:Checking exceptions
2023-04-19 14:43:53,121:INFO:Importing libraries
2023-04-19 14:43:53,121:INFO:Copying training dataset
2023-04-19 14:43:53,155:INFO:Defining folds
2023-04-19 14:43:53,155:INFO:Declaring metric variables
2023-04-19 14:43:53,174:INFO:Importing untrained model
2023-04-19 14:43:53,185:INFO:Gradient Boosting Classifier Imported successfully
2023-04-19 14:43:53,211:INFO:Starting cross validation
2023-04-19 14:43:53,248:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 14:43:56,213:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:56,213:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:56,260:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:43:56,276:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:02,794:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:02,794:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:02,810:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:02,810:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:09,168:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:09,215:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:15,456:INFO:Calculating mean and std
2023-04-19 14:44:15,456:INFO:Creating metrics dataframe
2023-04-19 14:44:17,630:INFO:Uploading results into container
2023-04-19 14:44:17,632:INFO:Uploading model into container now
2023-04-19 14:44:17,633:INFO:_master_model_container: 10
2023-04-19 14:44:17,633:INFO:_display_container: 2
2023-04-19 14:44:17,634:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-19 14:44:17,635:INFO:create_model() successfully completed......................................
2023-04-19 14:44:17,864:INFO:SubProcess create_model() end ==================================
2023-04-19 14:44:17,864:INFO:Creating metrics dataframe
2023-04-19 14:44:17,907:INFO:Initializing Linear Discriminant Analysis
2023-04-19 14:44:17,908:INFO:Total runtime is 4.4651662309964495 minutes
2023-04-19 14:44:17,909:INFO:SubProcess create_model() called ==================================
2023-04-19 14:44:17,909:INFO:Initializing create_model()
2023-04-19 14:44:17,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D55CBB8E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:44:17,909:INFO:Checking exceptions
2023-04-19 14:44:17,909:INFO:Importing libraries
2023-04-19 14:44:17,909:INFO:Copying training dataset
2023-04-19 14:44:17,940:INFO:Defining folds
2023-04-19 14:44:17,941:INFO:Declaring metric variables
2023-04-19 14:44:17,945:INFO:Importing untrained model
2023-04-19 14:44:17,969:INFO:Linear Discriminant Analysis Imported successfully
2023-04-19 14:44:17,994:INFO:Starting cross validation
2023-04-19 14:44:18,030:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 14:44:25,166:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:25,182:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:25,322:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:25,648:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:39,242:INFO:Calculating mean and std
2023-04-19 14:44:39,258:INFO:Creating metrics dataframe
2023-04-19 14:44:41,162:INFO:Uploading results into container
2023-04-19 14:44:41,162:INFO:Uploading model into container now
2023-04-19 14:44:41,162:INFO:_master_model_container: 11
2023-04-19 14:44:41,162:INFO:_display_container: 2
2023-04-19 14:44:41,162:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-19 14:44:41,162:INFO:create_model() successfully completed......................................
2023-04-19 14:44:41,356:INFO:SubProcess create_model() end ==================================
2023-04-19 14:44:41,356:INFO:Creating metrics dataframe
2023-04-19 14:44:41,398:INFO:Initializing Extra Trees Classifier
2023-04-19 14:44:41,398:INFO:Total runtime is 4.8566549499829605 minutes
2023-04-19 14:44:41,398:INFO:SubProcess create_model() called ==================================
2023-04-19 14:44:41,398:INFO:Initializing create_model()
2023-04-19 14:44:41,398:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D55CBB8E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:44:41,398:INFO:Checking exceptions
2023-04-19 14:44:41,398:INFO:Importing libraries
2023-04-19 14:44:41,398:INFO:Copying training dataset
2023-04-19 14:44:41,433:INFO:Defining folds
2023-04-19 14:44:41,433:INFO:Declaring metric variables
2023-04-19 14:44:41,451:INFO:Importing untrained model
2023-04-19 14:44:41,464:INFO:Extra Trees Classifier Imported successfully
2023-04-19 14:44:41,482:INFO:Starting cross validation
2023-04-19 14:44:41,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 14:44:44,708:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:44,740:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:44,740:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:44,943:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:52,038:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:52,275:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:52,291:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:52,338:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:59,391:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:44:59,476:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:45:06,273:INFO:Calculating mean and std
2023-04-19 14:45:06,273:INFO:Creating metrics dataframe
2023-04-19 14:45:08,783:INFO:Uploading results into container
2023-04-19 14:45:08,783:INFO:Uploading model into container now
2023-04-19 14:45:08,783:INFO:_master_model_container: 12
2023-04-19 14:45:08,783:INFO:_display_container: 2
2023-04-19 14:45:08,783:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-04-19 14:45:08,783:INFO:create_model() successfully completed......................................
2023-04-19 14:45:09,015:INFO:SubProcess create_model() end ==================================
2023-04-19 14:45:09,015:INFO:Creating metrics dataframe
2023-04-19 14:45:09,054:INFO:Initializing Extreme Gradient Boosting
2023-04-19 14:45:09,055:INFO:Total runtime is 5.317606699466705 minutes
2023-04-19 14:45:09,066:INFO:SubProcess create_model() called ==================================
2023-04-19 14:45:09,067:INFO:Initializing create_model()
2023-04-19 14:45:09,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D55CBB8E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:45:09,068:INFO:Checking exceptions
2023-04-19 14:45:09,068:INFO:Importing libraries
2023-04-19 14:45:09,069:INFO:Copying training dataset
2023-04-19 14:45:09,081:INFO:Defining folds
2023-04-19 14:45:09,082:INFO:Declaring metric variables
2023-04-19 14:45:09,092:INFO:Importing untrained model
2023-04-19 14:45:09,099:INFO:Extreme Gradient Boosting Imported successfully
2023-04-19 14:45:09,132:INFO:Starting cross validation
2023-04-19 14:45:09,166:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 14:45:11,679:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:45:11,679:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:45:11,679:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:45:11,698:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:45:17,644:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:45:17,710:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:45:17,788:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:45:17,803:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:45:31,044:INFO:Calculating mean and std
2023-04-19 14:45:31,044:INFO:Creating metrics dataframe
2023-04-19 14:45:32,714:INFO:Uploading results into container
2023-04-19 14:45:32,714:INFO:Uploading model into container now
2023-04-19 14:45:32,714:INFO:_master_model_container: 13
2023-04-19 14:45:32,714:INFO:_display_container: 2
2023-04-19 14:45:32,714:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-19 14:45:32,714:INFO:create_model() successfully completed......................................
2023-04-19 14:45:32,901:INFO:SubProcess create_model() end ==================================
2023-04-19 14:45:32,901:INFO:Creating metrics dataframe
2023-04-19 14:45:32,941:INFO:Initializing Light Gradient Boosting Machine
2023-04-19 14:45:32,941:INFO:Total runtime is 5.715716461340586 minutes
2023-04-19 14:45:32,956:INFO:SubProcess create_model() called ==================================
2023-04-19 14:45:32,957:INFO:Initializing create_model()
2023-04-19 14:45:32,958:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D55CBB8E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:45:32,958:INFO:Checking exceptions
2023-04-19 14:45:32,959:INFO:Importing libraries
2023-04-19 14:45:32,959:INFO:Copying training dataset
2023-04-19 14:45:32,971:INFO:Defining folds
2023-04-19 14:45:32,972:INFO:Declaring metric variables
2023-04-19 14:45:32,985:INFO:Importing untrained model
2023-04-19 14:45:32,997:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-19 14:45:33,021:INFO:Starting cross validation
2023-04-19 14:45:33,051:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 14:45:40,832:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:45:40,878:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:45:40,894:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:45:40,894:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:45:53,966:INFO:Calculating mean and std
2023-04-19 14:45:53,966:INFO:Creating metrics dataframe
2023-04-19 14:45:56,515:INFO:Uploading results into container
2023-04-19 14:45:56,515:INFO:Uploading model into container now
2023-04-19 14:45:56,515:INFO:_master_model_container: 14
2023-04-19 14:45:56,515:INFO:_display_container: 2
2023-04-19 14:45:56,515:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-19 14:45:56,531:INFO:create_model() successfully completed......................................
2023-04-19 14:45:56,766:INFO:SubProcess create_model() end ==================================
2023-04-19 14:45:56,766:INFO:Creating metrics dataframe
2023-04-19 14:45:56,797:INFO:Initializing CatBoost Classifier
2023-04-19 14:45:56,797:INFO:Total runtime is 6.1133073449134825 minutes
2023-04-19 14:45:56,819:INFO:SubProcess create_model() called ==================================
2023-04-19 14:45:56,821:INFO:Initializing create_model()
2023-04-19 14:45:56,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D55CBB8E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:45:56,822:INFO:Checking exceptions
2023-04-19 14:45:56,822:INFO:Importing libraries
2023-04-19 14:45:56,822:INFO:Copying training dataset
2023-04-19 14:45:56,837:INFO:Defining folds
2023-04-19 14:45:56,837:INFO:Declaring metric variables
2023-04-19 14:45:56,846:INFO:Importing untrained model
2023-04-19 14:45:56,868:INFO:CatBoost Classifier Imported successfully
2023-04-19 14:45:56,892:INFO:Starting cross validation
2023-04-19 14:45:56,925:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 14:46:12,592:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:46:12,952:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:46:29,996:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:46:30,181:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:46:32,336:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:46:49,019:INFO:Calculating mean and std
2023-04-19 14:46:49,019:INFO:Creating metrics dataframe
2023-04-19 14:46:51,235:INFO:Uploading results into container
2023-04-19 14:46:51,235:INFO:Uploading model into container now
2023-04-19 14:46:51,235:INFO:_master_model_container: 15
2023-04-19 14:46:51,235:INFO:_display_container: 2
2023-04-19 14:46:51,235:INFO:<catboost.core.CatBoostClassifier object at 0x0000020D54A80220>
2023-04-19 14:46:51,235:INFO:create_model() successfully completed......................................
2023-04-19 14:46:51,452:INFO:SubProcess create_model() end ==================================
2023-04-19 14:46:51,452:INFO:Creating metrics dataframe
2023-04-19 14:46:51,483:INFO:Initializing Dummy Classifier
2023-04-19 14:46:51,483:INFO:Total runtime is 7.024743620554606 minutes
2023-04-19 14:46:51,499:INFO:SubProcess create_model() called ==================================
2023-04-19 14:46:51,499:INFO:Initializing create_model()
2023-04-19 14:46:51,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D55CBB8E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:46:51,499:INFO:Checking exceptions
2023-04-19 14:46:51,499:INFO:Importing libraries
2023-04-19 14:46:51,499:INFO:Copying training dataset
2023-04-19 14:46:51,516:INFO:Defining folds
2023-04-19 14:46:51,516:INFO:Declaring metric variables
2023-04-19 14:46:51,526:INFO:Importing untrained model
2023-04-19 14:46:51,544:INFO:Dummy Classifier Imported successfully
2023-04-19 14:46:51,560:INFO:Starting cross validation
2023-04-19 14:46:51,595:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 14:46:53,484:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-19 14:46:53,484:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-19 14:46:53,484:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-19 14:46:53,499:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-19 14:46:58,134:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:46:58,150:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:46:58,322:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:46:58,353:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-19 14:46:58,417:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-19 14:46:58,448:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:46:58,651:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-19 14:46:58,714:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-19 14:47:03,442:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-19 14:47:03,504:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-19 14:47:11,290:INFO:Calculating mean and std
2023-04-19 14:47:11,290:INFO:Creating metrics dataframe
2023-04-19 14:47:13,444:INFO:Uploading results into container
2023-04-19 14:47:13,444:INFO:Uploading model into container now
2023-04-19 14:47:13,444:INFO:_master_model_container: 16
2023-04-19 14:47:13,444:INFO:_display_container: 2
2023-04-19 14:47:13,444:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-04-19 14:47:13,444:INFO:create_model() successfully completed......................................
2023-04-19 14:47:13,658:INFO:SubProcess create_model() end ==================================
2023-04-19 14:47:13,674:INFO:Creating metrics dataframe
2023-04-19 14:47:13,735:INFO:Initializing create_model()
2023-04-19 14:47:13,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:47:13,737:INFO:Checking exceptions
2023-04-19 14:47:13,743:INFO:Importing libraries
2023-04-19 14:47:13,744:INFO:Copying training dataset
2023-04-19 14:47:13,755:INFO:Defining folds
2023-04-19 14:47:13,755:INFO:Declaring metric variables
2023-04-19 14:47:13,755:INFO:Importing untrained model
2023-04-19 14:47:13,755:INFO:Declaring custom model
2023-04-19 14:47:13,755:INFO:Random Forest Classifier Imported successfully
2023-04-19 14:47:13,801:INFO:Cross validation set to False
2023-04-19 14:47:13,801:INFO:Fitting Model
2023-04-19 14:47:16,600:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-19 14:47:16,600:INFO:create_model() successfully completed......................................
2023-04-19 14:47:16,929:INFO:_master_model_container: 16
2023-04-19 14:47:16,929:INFO:_display_container: 2
2023-04-19 14:47:16,932:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-19 14:47:16,932:INFO:compare_models() successfully completed......................................
2023-04-19 14:52:33,417:INFO:Initializing create_model()
2023-04-19 14:52:33,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-19 14:52:33,419:INFO:Checking exceptions
2023-04-19 14:52:33,478:INFO:Importing libraries
2023-04-19 14:52:33,478:INFO:Copying training dataset
2023-04-19 14:52:33,530:INFO:Defining folds
2023-04-19 14:52:33,531:INFO:Declaring metric variables
2023-04-19 14:52:33,543:INFO:Importing untrained model
2023-04-19 14:52:33,544:INFO:Declaring custom model
2023-04-19 14:52:33,557:INFO:Random Forest Classifier Imported successfully
2023-04-19 14:52:33,584:INFO:Starting cross validation
2023-04-19 14:52:33,619:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 14:53:14,836:INFO:Calculating mean and std
2023-04-19 14:53:14,839:INFO:Creating metrics dataframe
2023-04-19 14:53:14,859:INFO:Finalizing model
2023-04-19 14:53:17,231:INFO:Uploading results into container
2023-04-19 14:53:17,233:INFO:Uploading model into container now
2023-04-19 14:53:17,259:INFO:_master_model_container: 17
2023-04-19 14:53:17,259:INFO:_display_container: 3
2023-04-19 14:53:17,259:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-19 14:53:17,259:INFO:create_model() successfully completed......................................
2023-04-19 14:56:11,585:INFO:Initializing tune_model()
2023-04-19 14:56:11,585:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>)
2023-04-19 14:56:11,586:INFO:Checking exceptions
2023-04-19 14:56:11,642:INFO:Copying training dataset
2023-04-19 14:56:11,660:INFO:Checking base model
2023-04-19 14:56:11,660:INFO:Base model : Random Forest Classifier
2023-04-19 14:56:11,674:INFO:Declaring metric variables
2023-04-19 14:56:11,685:INFO:Defining Hyperparameters
2023-04-19 14:56:11,968:INFO:Tuning with n_jobs=-1
2023-04-19 14:56:11,968:INFO:Initializing RandomizedSearchCV
2023-04-19 14:56:14,940:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:56:14,942:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:56:15,008:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:56:15,025:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:56:16,878:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:16,893:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:16,944:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:17,089:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:23,777:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:56:23,889:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:56:24,174:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:56:24,659:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:56:26,281:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:26,375:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:26,617:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:27,169:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:31,932:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-19 14:56:33,089:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:56:33,159:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:56:33,199:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:34,748:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:35,684:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:35,709:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:40,136:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:41,194:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:43,429:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:45,936:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:48,987:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:51,799:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:54,354:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:56:56,944:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:01,057:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:03,547:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:06,164:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:08,895:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:11,499:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:14,015:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:16,564:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:19,138:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:21,324:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:23,806:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:27,090:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:29,736:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:32,634:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:35,799:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:38,643:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:41,384:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:44,313:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:47,199:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:50,084:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:53,324:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:54,812:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:57:57,125:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:57:58,057:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:58:00,230:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:58:03,055:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:58:03,978:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:58:06,179:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:58:07,332:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:58:09,516:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:58:10,640:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:58:13,539:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:58:14,382:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:58:17,453:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:58:19,870:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:58:22,880:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:58:25,859:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:58:29,009:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:58:31,359:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:58:34,339:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:58:34,472:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:58:37,589:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:58:38,157:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:58:41,490:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:58:41,668:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:58:44,822:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:58:45,175:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:58:48,539:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:58:48,856:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:58:52,275:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:58:52,625:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:58:55,879:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:58:56,068:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:58:59,642:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:58:59,938:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:59:03,314:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:59:03,319:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:59:06,594:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:59:07,929:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:59:11,243:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:59:14,813:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:59:18,557:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:59:22,270:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:59:25,322:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:59:29,170:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:59:32,606:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:59:35,466:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:59:38,789:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:59:40,963:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:59:43,769:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:59:44,109:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:59:47,144:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:59:47,969:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:59:51,114:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:59:51,612:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:59:54,856:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:59:55,539:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 14:59:58,219:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 14:59:58,726:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:00:01,575:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:00:02,267:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:00:05,463:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:00:06,170:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:00:09,147:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:00:09,570:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:00:12,499:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:00:13,353:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:00:16,214:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:00:18,599:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:00:21,917:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:00:25,340:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:00:28,569:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:00:31,959:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:00:35,124:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:00:38,203:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:00:42,015:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:00:45,059:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:00:48,369:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:00:49,483:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:00:51,923:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:00:55,244:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:00:56,750:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:00:59,101:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:01:01,806:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:01:05,624:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:01:06,429:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:01:09,315:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:01:10,064:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:01:12,984:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:01:15,999:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:01:19,110:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:01:22,581:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:01:35,119:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-04-19 15:01:35,129:INFO:Hyperparameter search completed
2023-04-19 15:01:35,129:INFO:SubProcess create_model() called ==================================
2023-04-19 15:01:35,129:INFO:Initializing create_model()
2023-04-19 15:01:35,129:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D55E25180>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 6, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-04-19 15:01:35,129:INFO:Checking exceptions
2023-04-19 15:01:35,129:INFO:Importing libraries
2023-04-19 15:01:35,129:INFO:Copying training dataset
2023-04-19 15:01:35,154:INFO:Defining folds
2023-04-19 15:01:35,157:INFO:Declaring metric variables
2023-04-19 15:01:35,159:INFO:Importing untrained model
2023-04-19 15:01:35,159:INFO:Declaring custom model
2023-04-19 15:01:35,176:INFO:Random Forest Classifier Imported successfully
2023-04-19 15:01:35,203:INFO:Starting cross validation
2023-04-19 15:01:35,238:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 15:01:38,347:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:01:38,380:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:01:38,414:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:01:38,533:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:01:48,020:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:01:48,228:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:01:48,278:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:01:48,923:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:01:56,399:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:01:56,638:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:02:06,423:INFO:Calculating mean and std
2023-04-19 15:02:06,423:INFO:Creating metrics dataframe
2023-04-19 15:02:06,443:INFO:Finalizing model
2023-04-19 15:02:10,363:INFO:Uploading results into container
2023-04-19 15:02:10,366:INFO:Uploading model into container now
2023-04-19 15:02:10,368:INFO:_master_model_container: 18
2023-04-19 15:02:10,368:INFO:_display_container: 4
2023-04-19 15:02:10,371:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-04-19 15:02:10,373:INFO:create_model() successfully completed......................................
2023-04-19 15:02:10,653:INFO:SubProcess create_model() end ==================================
2023-04-19 15:02:10,653:INFO:choose_better activated
2023-04-19 15:02:10,663:INFO:SubProcess create_model() called ==================================
2023-04-19 15:02:10,663:INFO:Initializing create_model()
2023-04-19 15:02:10,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-19 15:02:10,663:INFO:Checking exceptions
2023-04-19 15:02:10,674:INFO:Importing libraries
2023-04-19 15:02:10,674:INFO:Copying training dataset
2023-04-19 15:02:10,688:INFO:Defining folds
2023-04-19 15:02:10,688:INFO:Declaring metric variables
2023-04-19 15:02:10,692:INFO:Importing untrained model
2023-04-19 15:02:10,693:INFO:Declaring custom model
2023-04-19 15:02:10,695:INFO:Random Forest Classifier Imported successfully
2023-04-19 15:02:10,695:INFO:Starting cross validation
2023-04-19 15:02:10,719:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 15:02:35,546:INFO:Calculating mean and std
2023-04-19 15:02:35,546:INFO:Creating metrics dataframe
2023-04-19 15:02:35,553:INFO:Finalizing model
2023-04-19 15:02:38,137:INFO:Uploading results into container
2023-04-19 15:02:38,138:INFO:Uploading model into container now
2023-04-19 15:02:38,139:INFO:_master_model_container: 19
2023-04-19 15:02:38,139:INFO:_display_container: 5
2023-04-19 15:02:38,140:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-19 15:02:38,140:INFO:create_model() successfully completed......................................
2023-04-19 15:02:38,345:INFO:SubProcess create_model() end ==================================
2023-04-19 15:02:38,346:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.7397
2023-04-19 15:02:38,347:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.72
2023-04-19 15:02:38,348:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) is best model
2023-04-19 15:02:38,348:INFO:choose_better completed
2023-04-19 15:02:38,348:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-19 15:02:38,387:INFO:_master_model_container: 19
2023-04-19 15:02:38,388:INFO:_display_container: 4
2023-04-19 15:02:38,391:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-19 15:02:38,391:INFO:tune_model() successfully completed......................................
2023-04-19 15:23:30,727:INFO:Initializing tune_model()
2023-04-19 15:23:30,727:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={'n_iters': 15}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>)
2023-04-19 15:23:30,728:INFO:Checking exceptions
2023-04-19 15:23:30,813:INFO:Copying training dataset
2023-04-19 15:23:30,828:INFO:Checking base model
2023-04-19 15:23:30,829:INFO:Base model : Random Forest Classifier
2023-04-19 15:23:30,844:INFO:Declaring metric variables
2023-04-19 15:23:30,862:INFO:Defining Hyperparameters
2023-04-19 15:23:31,198:INFO:Tuning with n_jobs=-1
2023-04-19 15:23:31,198:INFO:Initializing RandomizedSearchCV
2023-04-19 15:24:56,148:INFO:Initializing tune_model()
2023-04-19 15:24:56,148:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=15, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>)
2023-04-19 15:24:56,149:INFO:Checking exceptions
2023-04-19 15:24:56,201:INFO:Copying training dataset
2023-04-19 15:24:56,218:INFO:Checking base model
2023-04-19 15:24:56,223:INFO:Base model : Random Forest Classifier
2023-04-19 15:24:56,237:INFO:Declaring metric variables
2023-04-19 15:24:56,248:INFO:Defining Hyperparameters
2023-04-19 15:24:56,584:INFO:Tuning with n_jobs=-1
2023-04-19 15:24:56,584:INFO:Initializing RandomizedSearchCV
2023-04-19 15:25:15,791:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:25:15,842:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:25:15,964:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:25:16,703:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:25:17,899:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:25:17,944:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:25:18,024:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:25:19,067:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:25:25,769:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:25:25,889:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:25:26,139:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:25:27,609:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:25:28,694:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:25:28,728:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:25:28,910:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:25:30,491:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:25:36,682:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:25:36,719:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:25:36,744:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:25:38,134:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:25:39,316:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:25:39,407:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:25:43,898:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:25:45,114:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:25:48,276:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:25:51,302:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:25:54,184:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:25:57,304:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:26:00,149:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:26:02,967:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:26:30,239:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:26:33,006:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:26:33,180:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:26:36,340:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:26:36,949:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:26:40,192:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:26:40,359:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:26:44,014:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:26:44,366:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:26:47,632:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:26:48,014:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:26:51,344:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:26:51,604:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:26:55,859:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:26:55,884:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:26:59,389:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:26:59,894:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:27:03,269:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:27:03,809:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:27:07,116:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:27:57,755:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:28:00,079:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:28:02,464:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:28:05,149:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:28:08,189:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:28:11,059:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:28:14,052:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:28:16,518:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:28:19,259:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:28:47,812:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:28:50,386:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:28:53,407:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:28:56,449:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:29:00,043:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:29:01,759:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 15:29:03,799:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:29:07,423:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:29:11,256:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:29:13,910:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:29:17,075:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:31:40,714:INFO:best_params: {'actual_estimator__n_estimators': 20, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.01, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-04-19 15:31:40,714:INFO:Hyperparameter search completed
2023-04-19 15:31:40,714:INFO:SubProcess create_model() called ==================================
2023-04-19 15:31:40,714:INFO:Initializing create_model()
2023-04-19 15:31:40,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D5354C8E0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 20, 'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.01, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-04-19 15:31:40,714:INFO:Checking exceptions
2023-04-19 15:31:40,714:INFO:Importing libraries
2023-04-19 15:31:40,730:INFO:Copying training dataset
2023-04-19 15:31:40,750:INFO:Defining folds
2023-04-19 15:31:40,750:INFO:Declaring metric variables
2023-04-19 15:31:40,759:INFO:Importing untrained model
2023-04-19 15:31:40,759:INFO:Declaring custom model
2023-04-19 15:31:40,768:INFO:Random Forest Classifier Imported successfully
2023-04-19 15:31:40,779:INFO:Starting cross validation
2023-04-19 15:31:40,817:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 15:31:48,408:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:31:48,439:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:31:48,486:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:31:48,642:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:31:54,090:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:31:54,403:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 15:32:03,967:INFO:Calculating mean and std
2023-04-19 15:32:03,967:INFO:Creating metrics dataframe
2023-04-19 15:32:03,984:INFO:Finalizing model
2023-04-19 15:32:07,703:INFO:Uploading results into container
2023-04-19 15:32:07,706:INFO:Uploading model into container now
2023-04-19 15:32:07,711:INFO:_master_model_container: 20
2023-04-19 15:32:07,711:INFO:_display_container: 5
2023-04-19 15:32:07,712:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=10, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.01,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-04-19 15:32:07,713:INFO:create_model() successfully completed......................................
2023-04-19 15:32:07,983:INFO:SubProcess create_model() end ==================================
2023-04-19 15:32:07,983:INFO:choose_better activated
2023-04-19 15:32:07,983:INFO:SubProcess create_model() called ==================================
2023-04-19 15:32:07,983:INFO:Initializing create_model()
2023-04-19 15:32:07,983:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-19 15:32:07,983:INFO:Checking exceptions
2023-04-19 15:32:07,983:INFO:Importing libraries
2023-04-19 15:32:07,983:INFO:Copying training dataset
2023-04-19 15:32:08,009:INFO:Defining folds
2023-04-19 15:32:08,009:INFO:Declaring metric variables
2023-04-19 15:32:08,010:INFO:Importing untrained model
2023-04-19 15:32:08,010:INFO:Declaring custom model
2023-04-19 15:32:08,011:INFO:Random Forest Classifier Imported successfully
2023-04-19 15:32:08,011:INFO:Starting cross validation
2023-04-19 15:32:08,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 15:32:30,440:INFO:Calculating mean and std
2023-04-19 15:32:30,440:INFO:Creating metrics dataframe
2023-04-19 15:32:30,440:INFO:Finalizing model
2023-04-19 15:32:32,887:INFO:Uploading results into container
2023-04-19 15:32:32,887:INFO:Uploading model into container now
2023-04-19 15:32:32,887:INFO:_master_model_container: 21
2023-04-19 15:32:32,887:INFO:_display_container: 6
2023-04-19 15:32:32,887:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-19 15:32:32,887:INFO:create_model() successfully completed......................................
2023-04-19 15:32:33,137:INFO:SubProcess create_model() end ==================================
2023-04-19 15:32:33,137:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.7397
2023-04-19 15:32:33,153:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=10, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.01,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.7217
2023-04-19 15:32:33,153:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) is best model
2023-04-19 15:32:33,153:INFO:choose_better completed
2023-04-19 15:32:33,153:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-19 15:32:33,176:INFO:_master_model_container: 21
2023-04-19 15:32:33,176:INFO:_display_container: 5
2023-04-19 15:32:33,179:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-19 15:32:33,180:INFO:tune_model() successfully completed......................................
2023-04-19 15:48:43,086:INFO:Initializing evaluate_model()
2023-04-19 15:48:43,087:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-04-19 15:48:43,134:INFO:Initializing plot_model()
2023-04-19 15:48:43,136:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, system=True)
2023-04-19 15:48:43,136:INFO:Checking exceptions
2023-04-19 15:48:43,199:INFO:Preloading libraries
2023-04-19 15:48:43,225:INFO:Copying training dataset
2023-04-19 15:48:43,225:INFO:Plot type: pipeline
2023-04-19 15:48:43,743:INFO:Visual Rendered Successfully
2023-04-19 15:48:44,031:INFO:plot_model() successfully completed......................................
2023-04-19 15:48:55,157:INFO:Initializing plot_model()
2023-04-19 15:48:55,157:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, system=True)
2023-04-19 15:48:55,158:INFO:Checking exceptions
2023-04-19 15:48:55,213:INFO:Preloading libraries
2023-04-19 15:48:55,235:INFO:Copying training dataset
2023-04-19 15:48:55,235:INFO:Plot type: feature
2023-04-19 15:48:55,236:WARNING:No coef_ found. Trying feature_importances_
2023-04-19 15:48:55,722:INFO:Visual Rendered Successfully
2023-04-19 15:48:56,022:INFO:plot_model() successfully completed......................................
2023-04-19 15:49:18,128:INFO:Initializing plot_model()
2023-04-19 15:49:18,129:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, system=True)
2023-04-19 15:49:18,129:INFO:Checking exceptions
2023-04-19 15:49:18,174:INFO:Preloading libraries
2023-04-19 15:49:18,190:INFO:Copying training dataset
2023-04-19 15:49:18,190:INFO:Plot type: parameter
2023-04-19 15:49:18,196:INFO:Visual Rendered Successfully
2023-04-19 15:49:18,441:INFO:plot_model() successfully completed......................................
2023-04-19 15:49:24,334:INFO:Initializing plot_model()
2023-04-19 15:49:24,334:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, system=True)
2023-04-19 15:49:24,335:INFO:Checking exceptions
2023-04-19 15:49:24,387:INFO:Preloading libraries
2023-04-19 15:49:24,405:INFO:Copying training dataset
2023-04-19 15:49:24,406:INFO:Plot type: auc
2023-04-19 15:49:24,925:INFO:Fitting Model
2023-04-19 15:49:24,943:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-04-19 15:49:24,945:INFO:Scoring test/hold-out set
2023-04-19 15:49:25,733:INFO:Visual Rendered Successfully
2023-04-19 15:49:26,082:INFO:plot_model() successfully completed......................................
2023-04-19 15:49:51,072:INFO:Initializing plot_model()
2023-04-19 15:49:51,073:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, system=True)
2023-04-19 15:49:51,073:INFO:Checking exceptions
2023-04-19 15:49:51,117:INFO:Preloading libraries
2023-04-19 15:49:51,134:INFO:Copying training dataset
2023-04-19 15:49:51,134:INFO:Plot type: confusion_matrix
2023-04-19 15:49:51,581:INFO:Fitting Model
2023-04-19 15:49:51,581:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-04-19 15:49:51,581:INFO:Scoring test/hold-out set
2023-04-19 15:49:51,911:INFO:Visual Rendered Successfully
2023-04-19 15:49:52,151:INFO:plot_model() successfully completed......................................
2023-04-19 15:51:12,432:INFO:Initializing plot_model()
2023-04-19 15:51:12,432:INFO:plot_model(plot=tree, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, system=True)
2023-04-19 15:51:12,433:INFO:Checking exceptions
2023-04-19 15:51:12,478:INFO:Preloading libraries
2023-04-19 15:51:12,495:INFO:Copying training dataset
2023-04-19 15:51:12,495:INFO:Plot type: tree
2023-04-19 15:51:15,341:INFO:Plotting decision trees
2023-04-19 15:51:15,442:INFO:Plotting tree 0
2023-04-19 15:51:18,342:INFO:Plotting tree 1
2023-04-19 15:51:20,459:INFO:Plotting tree 2
2023-04-19 15:51:21,907:INFO:Plotting tree 3
2023-04-19 15:51:23,182:INFO:Plotting tree 4
2023-04-19 15:51:24,497:INFO:Plotting tree 5
2023-04-19 15:51:25,972:INFO:Plotting tree 6
2023-04-19 15:51:27,227:INFO:Plotting tree 7
2023-04-19 15:51:28,302:INFO:Plotting tree 8
2023-04-19 15:51:29,642:INFO:Plotting tree 9
2023-04-19 15:51:31,311:INFO:Plotting tree 10
2023-04-19 15:51:33,732:INFO:Plotting tree 11
2023-04-19 15:51:35,756:INFO:Plotting tree 12
2023-04-19 15:51:37,497:INFO:Plotting tree 13
2023-04-19 15:51:38,926:INFO:Plotting tree 14
2023-04-19 15:51:40,138:INFO:Plotting tree 15
2023-04-19 15:51:41,489:INFO:Plotting tree 16
2023-04-19 15:51:42,816:INFO:Plotting tree 17
2023-04-19 15:51:44,072:INFO:Plotting tree 18
2023-04-19 15:51:45,202:INFO:Plotting tree 19
2023-04-19 15:51:46,647:INFO:Plotting tree 20
2023-04-19 15:51:48,746:INFO:Plotting tree 21
2023-04-19 15:51:50,676:INFO:Plotting tree 22
2023-04-19 15:51:52,641:INFO:Plotting tree 23
2023-04-19 15:51:54,336:INFO:Plotting tree 24
2023-04-19 15:51:55,862:INFO:Plotting tree 25
2023-04-19 15:51:57,046:INFO:Plotting tree 26
2023-04-19 15:51:58,372:INFO:Plotting tree 27
2023-04-19 15:51:59,484:INFO:Plotting tree 28
2023-04-19 15:52:00,847:INFO:Plotting tree 29
2023-04-19 15:52:02,078:INFO:Plotting tree 30
2023-04-19 15:52:03,935:INFO:Plotting tree 31
2023-04-19 15:52:05,722:INFO:Plotting tree 32
2023-04-19 15:52:07,902:INFO:Plotting tree 33
2023-04-19 15:52:09,712:INFO:Plotting tree 34
2023-04-19 15:52:11,092:INFO:Plotting tree 35
2023-04-19 15:52:12,281:INFO:Plotting tree 36
2023-04-19 15:52:13,412:INFO:Plotting tree 37
2023-04-19 15:52:14,682:INFO:Plotting tree 38
2023-04-19 15:52:15,911:INFO:Plotting tree 39
2023-04-19 15:52:17,152:INFO:Plotting tree 40
2023-04-19 15:52:18,355:INFO:Plotting tree 41
2023-04-19 15:52:21,317:INFO:Plotting tree 42
2023-04-19 15:52:23,271:INFO:Plotting tree 43
2023-04-19 15:52:25,002:INFO:Plotting tree 44
2023-04-19 15:52:26,791:INFO:Plotting tree 45
2023-04-19 15:52:28,041:INFO:Plotting tree 46
2023-04-19 15:52:29,282:INFO:Plotting tree 47
2023-04-19 15:52:30,631:INFO:Plotting tree 48
2023-04-19 15:52:31,832:INFO:Plotting tree 49
2023-04-19 15:52:33,001:INFO:Plotting tree 50
2023-04-19 15:52:34,105:INFO:Plotting tree 51
2023-04-19 15:52:36,041:INFO:Plotting tree 52
2023-04-19 15:52:38,158:INFO:Plotting tree 53
2023-04-19 15:52:40,252:INFO:Plotting tree 54
2023-04-19 15:52:41,942:INFO:Plotting tree 55
2023-04-19 15:52:43,416:INFO:Plotting tree 56
2023-04-19 15:52:44,692:INFO:Plotting tree 57
2023-04-19 15:52:45,791:INFO:Plotting tree 58
2023-04-19 15:52:47,042:INFO:Plotting tree 59
2023-04-19 15:52:48,322:INFO:Plotting tree 60
2023-04-19 15:52:49,425:INFO:Plotting tree 61
2023-04-19 15:52:50,812:INFO:Plotting tree 62
2023-04-19 15:52:53,342:INFO:Plotting tree 63
2023-04-19 15:52:55,372:INFO:Plotting tree 64
2023-04-19 15:52:57,331:INFO:Plotting tree 65
2023-04-19 15:52:58,922:INFO:Plotting tree 66
2023-04-19 15:55:24,646:INFO:Initializing evaluate_model()
2023-04-19 15:55:24,647:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-04-19 15:55:24,700:INFO:Initializing plot_model()
2023-04-19 15:55:24,700:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, system=True)
2023-04-19 15:55:24,701:INFO:Checking exceptions
2023-04-19 15:55:24,768:INFO:Preloading libraries
2023-04-19 15:55:24,801:INFO:Copying training dataset
2023-04-19 15:55:24,801:INFO:Plot type: pipeline
2023-04-19 15:55:25,317:INFO:Visual Rendered Successfully
2023-04-19 15:55:26,349:INFO:plot_model() successfully completed......................................
2023-04-19 15:55:26,379:INFO:Initializing plot_model()
2023-04-19 15:55:26,379:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, system=True)
2023-04-19 15:55:26,380:INFO:Checking exceptions
2023-04-19 15:55:26,428:INFO:Preloading libraries
2023-04-19 15:55:26,447:INFO:Copying training dataset
2023-04-19 15:55:26,447:INFO:Plot type: rfe
2023-04-19 15:55:26,953:INFO:Fitting Model
2023-04-19 16:04:16,332:INFO:Visual Rendered Successfully
2023-04-19 16:04:17,446:INFO:plot_model() successfully completed......................................
2023-04-19 16:08:53,459:INFO:Initializing predict_model()
2023-04-19 16:08:53,459:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000020DC47ED900>)
2023-04-19 16:08:53,460:INFO:Checking exceptions
2023-04-19 16:08:53,460:INFO:Preloading libraries
2023-04-19 16:21:06,532:INFO:Initializing predict_model()
2023-04-19 16:21:06,533:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000020DC47EE440>)
2023-04-19 16:21:06,534:INFO:Checking exceptions
2023-04-19 16:21:06,534:INFO:Preloading libraries
2023-04-19 16:21:06,540:INFO:Set up data.
2023-04-19 16:21:06,579:INFO:Set up index.
2023-04-19 16:28:46,152:INFO:Initializing finalize_model()
2023-04-19 16:28:46,153:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-19 16:28:46,155:INFO:Finalizing RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-19 16:28:46,167:INFO:Initializing create_model()
2023-04-19 16:28:46,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-19 16:28:46,167:INFO:Checking exceptions
2023-04-19 16:28:46,172:INFO:Importing libraries
2023-04-19 16:28:46,172:INFO:Copying training dataset
2023-04-19 16:28:46,173:INFO:Defining folds
2023-04-19 16:28:46,173:INFO:Declaring metric variables
2023-04-19 16:28:46,173:INFO:Importing untrained model
2023-04-19 16:28:46,173:INFO:Declaring custom model
2023-04-19 16:28:46,175:INFO:Random Forest Classifier Imported successfully
2023-04-19 16:28:46,196:INFO:Cross validation set to False
2023-04-19 16:28:46,196:INFO:Fitting Model
2023-04-19 16:28:48,092:INFO:Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=123,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-04-19 16:28:48,092:INFO:create_model() successfully completed......................................
2023-04-19 16:28:49,918:INFO:_master_model_container: 21
2023-04-19 16:28:49,918:INFO:_display_container: 7
2023-04-19 16:28:49,999:INFO:Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=123,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-04-19 16:28:49,999:INFO:finalize_model() successfully completed......................................
2023-04-19 16:31:13,163:INFO:Initializing save_model()
2023-04-19 16:31:13,163:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=123,
                                        verbose=0, warm_start=False))],
         verbose=False), model_name=Final RF Model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=12,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-19 16:31:13,163:INFO:Adding model into prep_pipe
2023-04-19 16:31:13,228:WARNING:Only Model saved as it was a pipeline.
2023-04-19 16:31:13,428:INFO:Final RF Model.pkl saved in current working directory
2023-04-19 16:31:13,503:INFO:Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=123,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-04-19 16:31:13,503:INFO:save_model() successfully completed......................................
2023-04-19 17:03:06,358:INFO:Initializing tune_model()
2023-04-19 17:03:06,359:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>)
2023-04-19 17:03:06,359:INFO:Checking exceptions
2023-04-19 17:03:06,438:INFO:Copying training dataset
2023-04-19 17:03:06,475:INFO:Checking base model
2023-04-19 17:03:06,475:INFO:Base model : Random Forest Classifier
2023-04-19 17:03:06,489:INFO:Declaring metric variables
2023-04-19 17:03:06,513:INFO:Defining Hyperparameters
2023-04-19 17:03:07,144:INFO:Tuning with n_jobs=-1
2023-04-19 17:03:07,144:INFO:Initializing RandomizedSearchCV
2023-04-19 17:03:25,648:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:03:27,259:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:03:27,259:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:03:27,709:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:03:28,073:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:03:34,882:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:03:35,535:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:03:36,118:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:03:36,193:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:03:36,939:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:03:37,628:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:03:46,463:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:03:46,491:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:03:46,554:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:03:48,638:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:03:49,416:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:03:51,461:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:03:54,126:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:03:56,457:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:03:56,777:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:03:59,066:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:04:00,166:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:04:02,941:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:04:03,618:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:04:06,599:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:04:07,626:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:04:10,410:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:04:11,346:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:04:13,925:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:04:14,648:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:04:17,381:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:04:18,433:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:04:20,786:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:04:49,316:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:04:51,988:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:04:54,818:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:04:57,839:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:05:01,051:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:05:04,141:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:05:07,514:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:05:10,731:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:05:13,694:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:05:17,081:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:05:18,551:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:05:21,441:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:05:26,173:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:05:28,908:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:05:31,866:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:05:41,416:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:05:46,018:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:05:49,371:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:05:52,826:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:05:56,011:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:05:59,046:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:06:02,416:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:06:05,576:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:06:09,091:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:06:12,262:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:06:15,756:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:06:17,086:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:06:20,060:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:06:22,861:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:06:25,516:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:06:30,083:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:06:32,741:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:06:35,602:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:06:38,258:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:07:10,191:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:07:12,503:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:07:13,342:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:07:15,741:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:07:16,432:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:07:19,183:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:07:19,861:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:07:22,652:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:07:23,557:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:07:26,278:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:07:26,921:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:07:29,536:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:07:30,823:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:07:34,604:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:07:35,801:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:07:38,941:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:07:39,186:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:07:42,111:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:07:43,456:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:07:46,400:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:07:47,527:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:07:50,803:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:07:51,707:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:07:55,196:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:07:55,890:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:07:59,241:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:07:59,939:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:08:03,270:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:08:04,011:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:08:07,330:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:08:08,246:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:08:11,902:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:08:12,711:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:08:16,016:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:08:16,720:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:08:20,262:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:08:21,129:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:08:24,727:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:08:25,503:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:08:29,001:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:08:29,382:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:08:32,640:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:08:33,436:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:08:36,478:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:08:37,450:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:08:41,173:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:08:41,806:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:08:45,401:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:08:46,277:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:08:49,415:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:08:50,026:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:08:53,675:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:08:54,347:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:08:57,721:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:08:58,575:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:09:02,077:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:09:02,637:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:09:05,823:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:09:06,741:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:09:10,266:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:09:10,550:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:09:13,870:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:09:14,936:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:09:18,057:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:09:19,026:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:09:22,046:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:09:22,834:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:09:26,051:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:09:26,912:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:09:30,308:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:09:31,358:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:09:34,550:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:09:35,284:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:09:38,452:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:09:39,521:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:09:43,089:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:09:43,731:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:09:47,121:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:09:48,511:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:09:51,392:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:09:52,037:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:09:55,047:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:09:56,007:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:09:58,992:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:10:00,297:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:10:03,517:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:10:04,142:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:10:07,158:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:10:08,100:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:10:11,155:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:10:12,326:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:10:15,332:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:10:16,219:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:10:19,257:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:10:20,227:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:10:23,253:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:10:24,365:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:10:27,127:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:10:27,792:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:10:30,649:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:10:32,740:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:10:36,052:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:10:36,977:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:10:40,424:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:10:41,099:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:10:44,532:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:10:44,707:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:10:48,288:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:10:48,987:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:10:52,622:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:10:53,408:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:10:56,857:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:10:57,525:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:11:00,957:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:11:01,598:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:11:05,092:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:11:05,637:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:11:09,237:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:11:10,061:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:11:13,182:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:11:13,562:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:11:17,707:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:11:21,397:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:11:25,218:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:11:28,482:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:11:32,014:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:11:35,545:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:11:38,838:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:11:42,132:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:11:45,535:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:12:19,359:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:12:22,272:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:12:25,475:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:12:28,748:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:12:32,008:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:12:35,007:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:12:37,957:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:12:40,847:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:12:44,360:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:12:47,102:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:12:50,307:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:12:53,018:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:12:55,982:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:12:59,340:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:13:02,496:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:13:05,538:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:13:07,987:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:13:10,685:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:13:14,059:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:13:17,450:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:13:20,932:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:13:24,192:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:13:27,269:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:13:30,711:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:13:33,947:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:13:37,599:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:13:40,567:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:13:43,642:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:13:47,176:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:14:20,802:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:14:22,027:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:14:24,303:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:14:25,897:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:14:27,962:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:14:31,392:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:14:32,423:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:14:34,762:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:14:36,128:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:14:39,042:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:14:39,853:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:14:42,297:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:14:43,457:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:14:46,162:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:14:47,211:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:14:49,577:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:14:51,088:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:14:53,452:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:14:55,687:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:14:58,927:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:14:59,704:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:15:03,337:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:15:04,590:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:15:08,387:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:15:08,588:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:15:11,907:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:15:12,758:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:15:16,092:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:15:16,830:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:15:20,447:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:15:21,210:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:15:24,628:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:15:25,720:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:15:30,231:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:15:31,225:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:15:34,390:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:15:35,105:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:15:38,315:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:15:39,404:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:15:43,139:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:15:46,906:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:15:50,496:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:15:53,939:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:15:57,570:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:01,025:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:04,429:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:07,837:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:11,360:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:14,015:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:17,365:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:22,982:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:26,203:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:29,458:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:32,460:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:37,540:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:40,782:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:44,233:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:47,416:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:50,455:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:52,992:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:55,930:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:16:59,365:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:17:02,727:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:17:11,943:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:17:15,540:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:17:17,780:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:17:19,025:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:17:21,485:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:17:22,889:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:17:25,210:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:17:26,315:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:17:28,870:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:17:30,279:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:17:32,701:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:17:33,770:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:17:36,478:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:17:37,700:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:17:40,034:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:17:41,605:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:17:44,230:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:17:45,210:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:17:47,689:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:17:49,185:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:17:51,505:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:18:26,137:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:18:27,120:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:18:29,795:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:18:30,650:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:18:33,492:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:18:35,155:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:18:38,172:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:18:38,925:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:18:41,902:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:18:43,065:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:18:45,940:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:18:47,868:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:18:51,596:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:18:52,608:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:18:55,445:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:18:56,355:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:18:59,248:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:19:00,463:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:19:03,697:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:19:03,879:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:19:06,208:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:19:08,176:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:19:10,278:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:19:14,235:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:19:18,110:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:19:22,282:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:19:26,185:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:19:29,925:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:19:33,877:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:19:37,799:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:19:41,604:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:20:39,643:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:20:43,140:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:20:46,941:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:20:50,480:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:20:53,880:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:20:57,316:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:21:01,432:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:21:04,935:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:21:08,640:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:21:12,575:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:21:15,755:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:21:18,090:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:21:19,751:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:21:22,175:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:21:23,895:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:21:26,357:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:21:28,131:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:21:30,656:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:21:32,441:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:21:34,740:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:21:36,410:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:21:38,648:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:21:40,700:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:21:43,087:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:21:45,218:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:21:47,524:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:21:49,126:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:21:51,301:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:21:53,395:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:21:55,590:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:23:26,324:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:23:29,085:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:23:29,865:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:23:32,780:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:23:33,465:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:23:36,571:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:23:37,839:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:23:41,196:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:23:42,514:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:23:46,117:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:23:47,017:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:23:50,157:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:23:51,087:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:23:54,837:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:23:56,049:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:23:59,367:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:24:00,233:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:24:03,666:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:24:04,809:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:24:07,317:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:24:08,155:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:24:09,462:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:24:11,697:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:24:13,750:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:24:15,758:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:24:17,589:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:24:21,173:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:24:23,376:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:24:25,765:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:24:29,482:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:24:33,113:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:24:36,808:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:24:40,187:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:24:44,142:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:24:47,058:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:24:49,743:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:24:50,804:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:24:53,480:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:24:54,637:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:24:57,394:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:24:59,037:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:25:01,815:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:25:02,959:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:25:05,783:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:25:07,062:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:25:09,939:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:25:11,353:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:25:14,332:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:25:15,507:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:25:18,202:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:25:19,497:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:25:22,492:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:25:23,788:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:25:26,414:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:26:27,725:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:26:28,830:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:26:31,913:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:26:32,823:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:26:35,900:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:26:37,406:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:26:40,410:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:26:41,621:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:26:45,112:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:26:46,340:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:26:49,698:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:26:51,223:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:26:54,710:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:26:55,960:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:26:59,094:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:27:00,164:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:27:03,515:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:27:04,880:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:27:07,935:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:27:08,410:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:27:12,133:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:27:15,597:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:27:19,090:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:27:22,360:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:27:26,550:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:27:29,830:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:27:35,453:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:27:39,051:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:28:12,727:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:28:15,254:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:28:16,452:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:28:19,241:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:28:20,489:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:28:23,469:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:28:24,457:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:28:27,537:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:28:28,689:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:28:31,696:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:28:33,059:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:28:36,125:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:28:37,159:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:28:40,321:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:28:41,950:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:28:45,073:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:28:46,290:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:28:49,284:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:28:50,582:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:28:53,492:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:29:28,601:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:29:32,014:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:29:35,122:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:29:43,531:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:29:46,930:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:29:50,197:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:29:57,250:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:30:00,944:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:30:05,024:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:30:08,750:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:30:11,819:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:30:13,784:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:30:17,154:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:30:21,131:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:30:25,171:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:30:28,588:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:30:32,409:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:30:35,689:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:30:39,111:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:30:39,954:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:30:43,484:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:30:44,692:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:30:48,939:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:30:50,225:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:30:53,894:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:30:54,794:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:30:58,149:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:30:59,040:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:31:02,935:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:31:04,054:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:31:07,799:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:31:09,367:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:31:13,234:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:31:14,006:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:31:17,302:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:31:18,564:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 17:31:21,920:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:32:05,574:INFO:best_params: {'actual_estimator__n_estimators': 220, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': False}
2023-04-19 17:32:05,576:INFO:Hyperparameter search completed
2023-04-19 17:32:05,577:INFO:SubProcess create_model() called ==================================
2023-04-19 17:32:05,579:INFO:Initializing create_model()
2023-04-19 17:32:05,579:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DBFBE8400>, model_only=True, return_train_score=False, kwargs={'n_estimators': 220, 'min_samples_split': 7, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'log2', 'max_depth': 9, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': False})
2023-04-19 17:32:05,580:INFO:Checking exceptions
2023-04-19 17:32:05,580:INFO:Importing libraries
2023-04-19 17:32:05,581:INFO:Copying training dataset
2023-04-19 17:32:05,583:INFO:Defining folds
2023-04-19 17:32:05,583:INFO:Declaring metric variables
2023-04-19 17:32:05,606:INFO:Importing untrained model
2023-04-19 17:32:05,606:INFO:Declaring custom model
2023-04-19 17:32:05,626:INFO:Random Forest Classifier Imported successfully
2023-04-19 17:32:05,650:INFO:Starting cross validation
2023-04-19 17:32:05,686:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 17:32:08,752:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:32:08,877:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:32:09,002:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:32:09,111:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:32:18,057:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:32:18,338:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:32:18,416:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:32:18,494:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:32:27,296:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:32:27,556:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 17:32:39,576:INFO:Calculating mean and std
2023-04-19 17:32:39,576:INFO:Creating metrics dataframe
2023-04-19 17:32:39,612:INFO:Finalizing model
2023-04-19 17:32:45,324:INFO:Uploading results into container
2023-04-19 17:32:45,326:INFO:Uploading model into container now
2023-04-19 17:32:45,327:INFO:_master_model_container: 22
2023-04-19 17:32:45,328:INFO:_display_container: 8
2023-04-19 17:32:45,330:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-19 17:32:45,331:INFO:create_model() successfully completed......................................
2023-04-19 17:32:45,757:INFO:SubProcess create_model() end ==================================
2023-04-19 17:32:45,757:INFO:choose_better activated
2023-04-19 17:32:45,772:INFO:SubProcess create_model() called ==================================
2023-04-19 17:32:45,772:INFO:Initializing create_model()
2023-04-19 17:32:45,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-19 17:32:45,772:INFO:Checking exceptions
2023-04-19 17:32:45,781:INFO:Importing libraries
2023-04-19 17:32:45,781:INFO:Copying training dataset
2023-04-19 17:32:45,792:INFO:Defining folds
2023-04-19 17:32:45,793:INFO:Declaring metric variables
2023-04-19 17:32:45,793:INFO:Importing untrained model
2023-04-19 17:32:45,793:INFO:Declaring custom model
2023-04-19 17:32:45,793:INFO:Random Forest Classifier Imported successfully
2023-04-19 17:32:45,793:INFO:Starting cross validation
2023-04-19 17:32:45,820:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 17:33:13,835:INFO:Calculating mean and std
2023-04-19 17:33:13,835:INFO:Creating metrics dataframe
2023-04-19 17:33:13,835:INFO:Finalizing model
2023-04-19 17:33:17,706:INFO:Uploading results into container
2023-04-19 17:33:17,706:INFO:Uploading model into container now
2023-04-19 17:33:17,706:INFO:_master_model_container: 23
2023-04-19 17:33:17,706:INFO:_display_container: 9
2023-04-19 17:33:17,706:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-19 17:33:17,706:INFO:create_model() successfully completed......................................
2023-04-19 17:33:18,217:INFO:SubProcess create_model() end ==================================
2023-04-19 17:33:18,232:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.7397
2023-04-19 17:33:18,232:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.7351
2023-04-19 17:33:18,232:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) is best model
2023-04-19 17:33:18,232:INFO:choose_better completed
2023-04-19 17:33:18,232:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-19 17:33:18,275:INFO:_master_model_container: 23
2023-04-19 17:33:18,276:INFO:_display_container: 8
2023-04-19 17:33:18,278:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-19 17:33:18,279:INFO:tune_model() successfully completed......................................
2023-04-19 17:35:59,182:INFO:Initializing tune_model()
2023-04-19 17:35:59,183:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>)
2023-04-19 17:35:59,183:INFO:Checking exceptions
2023-04-19 17:35:59,232:INFO:Copying training dataset
2023-04-19 17:35:59,247:INFO:Checking base model
2023-04-19 17:35:59,247:INFO:Base model : Random Forest Classifier
2023-04-19 17:35:59,264:INFO:Declaring metric variables
2023-04-19 17:35:59,275:INFO:Defining Hyperparameters
2023-04-19 17:35:59,745:INFO:Tuning with n_jobs=-1
2023-04-19 17:35:59,745:INFO:Initializing RandomizedSearchCV
2023-04-19 17:40:33,194:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-04-19 17:40:33,194:INFO:Hyperparameter search completed
2023-04-19 17:40:33,194:INFO:SubProcess create_model() called ==================================
2023-04-19 17:40:33,194:INFO:Initializing create_model()
2023-04-19 17:40:33,194:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D530FAF50>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 6, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-04-19 17:40:33,194:INFO:Checking exceptions
2023-04-19 17:40:33,194:INFO:Importing libraries
2023-04-19 17:40:33,194:INFO:Copying training dataset
2023-04-19 17:40:33,211:INFO:Defining folds
2023-04-19 17:40:33,211:INFO:Declaring metric variables
2023-04-19 17:40:33,211:INFO:Importing untrained model
2023-04-19 17:40:33,211:INFO:Declaring custom model
2023-04-19 17:40:33,234:INFO:Random Forest Classifier Imported successfully
2023-04-19 17:40:33,256:INFO:Starting cross validation
2023-04-19 17:40:33,295:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 17:41:03,238:INFO:Calculating mean and std
2023-04-19 17:41:03,238:INFO:Creating metrics dataframe
2023-04-19 17:41:03,254:INFO:Finalizing model
2023-04-19 17:41:06,461:INFO:Uploading results into container
2023-04-19 17:41:06,464:INFO:Uploading model into container now
2023-04-19 17:41:06,465:INFO:_master_model_container: 24
2023-04-19 17:41:06,466:INFO:_display_container: 9
2023-04-19 17:41:06,467:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-04-19 17:41:06,467:INFO:create_model() successfully completed......................................
2023-04-19 17:41:06,899:INFO:SubProcess create_model() end ==================================
2023-04-19 17:41:06,899:INFO:choose_better activated
2023-04-19 17:41:06,899:INFO:SubProcess create_model() called ==================================
2023-04-19 17:41:06,899:INFO:Initializing create_model()
2023-04-19 17:41:06,899:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D55D49240>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-19 17:41:06,899:INFO:Checking exceptions
2023-04-19 17:41:06,899:INFO:Importing libraries
2023-04-19 17:41:06,915:INFO:Copying training dataset
2023-04-19 17:41:06,929:INFO:Defining folds
2023-04-19 17:41:06,929:INFO:Declaring metric variables
2023-04-19 17:41:06,929:INFO:Importing untrained model
2023-04-19 17:41:06,930:INFO:Declaring custom model
2023-04-19 17:41:06,933:INFO:Random Forest Classifier Imported successfully
2023-04-19 17:41:06,933:INFO:Starting cross validation
2023-04-19 17:41:06,956:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 17:41:36,412:INFO:Calculating mean and std
2023-04-19 17:41:36,412:INFO:Creating metrics dataframe
2023-04-19 17:41:36,428:INFO:Finalizing model
2023-04-19 17:41:39,566:INFO:Uploading results into container
2023-04-19 17:41:39,566:INFO:Uploading model into container now
2023-04-19 17:41:39,566:INFO:_master_model_container: 25
2023-04-19 17:41:39,566:INFO:_display_container: 10
2023-04-19 17:41:39,566:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-19 17:41:39,566:INFO:create_model() successfully completed......................................
2023-04-19 17:41:39,972:INFO:SubProcess create_model() end ==================================
2023-04-19 17:41:39,973:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.7397
2023-04-19 17:41:39,974:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.72
2023-04-19 17:41:39,975:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) is best model
2023-04-19 17:41:39,975:INFO:choose_better completed
2023-04-19 17:41:39,975:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-19 17:41:39,998:INFO:_master_model_container: 25
2023-04-19 17:41:39,999:INFO:_display_container: 9
2023-04-19 17:41:40,001:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-19 17:41:40,002:INFO:tune_model() successfully completed......................................
2023-04-20 10:28:32,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-20 10:28:32,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-20 10:28:32,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-20 10:28:32,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-20 10:28:35,142:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-20 10:30:43,052:INFO:PyCaret ClassificationExperiment
2023-04-20 10:30:43,063:INFO:Logging name: clf-default-name
2023-04-20 10:30:43,063:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-20 10:30:43,063:INFO:version 3.0.0
2023-04-20 10:30:43,063:INFO:Initializing setup()
2023-04-20 10:30:43,063:INFO:self.USI: c03f
2023-04-20 10:30:43,063:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'memory', 'USI', 'X_train', 'seed', 'log_plots_param', 'gpu_param', 'html_param', 'exp_id', 'gpu_n_jobs_param', 'target_param', 'is_multiclass', 'data', 'y_train', 'y_test', 'X_test', 'y', '_ml_usecase', 'n_jobs_param', 'fix_imbalance', 'fold_groups_param', 'idx', 'exp_name_log', 'fold_generator', 'logging_param', 'X', '_available_plots'}
2023-04-20 10:30:43,063:INFO:Checking environment
2023-04-20 10:30:43,063:INFO:python_version: 3.10.9
2023-04-20 10:30:43,063:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-04-20 10:30:43,063:INFO:machine: AMD64
2023-04-20 10:30:43,063:INFO:platform: Windows-10-10.0.19044-SP0
2023-04-20 10:30:43,063:INFO:Memory: svmem(total=8483184640, available=3671883776, percent=56.7, used=4811300864, free=3671883776)
2023-04-20 10:30:43,063:INFO:Physical Core: 2
2023-04-20 10:30:43,063:INFO:Logical Core: 4
2023-04-20 10:30:43,063:INFO:Checking libraries
2023-04-20 10:30:43,063:INFO:System:
2023-04-20 10:30:43,063:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-04-20 10:30:43,063:INFO:executable: C:\Users\User\.conda\envs\My_envI\python.exe
2023-04-20 10:30:43,063:INFO:   machine: Windows-10-10.0.19044-SP0
2023-04-20 10:30:43,063:INFO:PyCaret required dependencies:
2023-04-20 10:30:43,063:INFO:                 pip: 22.3.1
2023-04-20 10:30:43,063:INFO:          setuptools: 66.0.0
2023-04-20 10:30:43,063:INFO:             pycaret: 3.0.0
2023-04-20 10:30:43,063:INFO:             IPython: 8.12.0
2023-04-20 10:30:43,063:INFO:          ipywidgets: 7.6.5
2023-04-20 10:30:43,063:INFO:                tqdm: 4.64.1
2023-04-20 10:30:43,063:INFO:               numpy: 1.23.5
2023-04-20 10:30:43,063:INFO:              pandas: 1.5.3
2023-04-20 10:30:43,063:INFO:              jinja2: 3.1.2
2023-04-20 10:30:43,063:INFO:               scipy: 1.10.1
2023-04-20 10:30:43,063:INFO:              joblib: 1.2.0
2023-04-20 10:30:43,063:INFO:             sklearn: 1.2.1
2023-04-20 10:30:43,063:INFO:                pyod: 1.0.9
2023-04-20 10:30:43,063:INFO:            imblearn: 0.10.1
2023-04-20 10:30:43,063:INFO:   category_encoders: 2.6.0
2023-04-20 10:30:43,063:INFO:            lightgbm: 3.3.5
2023-04-20 10:30:43,063:INFO:               numba: 0.56.4
2023-04-20 10:30:43,063:INFO:            requests: 2.28.1
2023-04-20 10:30:43,063:INFO:          matplotlib: 3.7.0
2023-04-20 10:30:43,063:INFO:          scikitplot: 0.3.7
2023-04-20 10:30:43,063:INFO:         yellowbrick: 1.5
2023-04-20 10:30:43,063:INFO:              plotly: 5.14.1
2023-04-20 10:30:43,063:INFO:             kaleido: 0.2.1
2023-04-20 10:30:43,063:INFO:         statsmodels: 0.13.5
2023-04-20 10:30:43,063:INFO:              sktime: 0.17.0
2023-04-20 10:30:43,063:INFO:               tbats: 1.1.2
2023-04-20 10:30:43,063:INFO:            pmdarima: 2.0.3
2023-04-20 10:30:43,063:INFO:              psutil: 5.9.0
2023-04-20 10:30:43,063:INFO:PyCaret optional dependencies:
2023-04-20 10:30:44,342:INFO:                shap: 0.41.0
2023-04-20 10:30:44,342:INFO:           interpret: 0.3.2
2023-04-20 10:30:44,342:INFO:                umap: 0.5.3
2023-04-20 10:30:44,342:INFO:    pandas_profiling: 4.1.2
2023-04-20 10:30:44,342:INFO:  explainerdashboard: 0.4.2.1
2023-04-20 10:30:44,342:INFO:             autoviz: 0.1.58
2023-04-20 10:30:44,342:INFO:           fairlearn: 0.7.0
2023-04-20 10:30:44,342:INFO:             xgboost: 1.7.5
2023-04-20 10:30:44,342:INFO:            catboost: 1.1.1
2023-04-20 10:30:44,342:INFO:              kmodes: 0.12.2
2023-04-20 10:30:44,342:INFO:             mlxtend: 0.22.0
2023-04-20 10:30:44,342:INFO:       statsforecast: 1.5.0
2023-04-20 10:30:44,342:INFO:        tune_sklearn: 0.4.5
2023-04-20 10:30:44,342:INFO:                 ray: 2.3.1
2023-04-20 10:30:44,342:INFO:            hyperopt: 0.2.7
2023-04-20 10:30:44,342:INFO:              optuna: 3.1.0
2023-04-20 10:30:44,342:INFO:               skopt: 0.9.0
2023-04-20 10:30:44,342:INFO:              mlflow: 1.30.1
2023-04-20 10:30:44,342:INFO:              gradio: Not installed
2023-04-20 10:30:44,342:INFO:             fastapi: 0.89.1
2023-04-20 10:30:44,342:INFO:             uvicorn: 0.21.1
2023-04-20 10:30:44,342:INFO:              m2cgen: 0.10.0
2023-04-20 10:30:44,342:INFO:           evidently: 0.2.8
2023-04-20 10:30:44,342:INFO:               fugue: 0.8.3
2023-04-20 10:30:44,342:INFO:           streamlit: Not installed
2023-04-20 10:30:44,342:INFO:             prophet: Not installed
2023-04-20 10:30:44,342:INFO:None
2023-04-20 10:30:44,342:INFO:Set up data.
2023-04-20 10:30:44,362:INFO:Set up train/test split.
2023-04-20 10:30:44,372:INFO:Set up index.
2023-04-20 10:30:44,372:INFO:Set up folding strategy.
2023-04-20 10:30:44,372:INFO:Assigning column types.
2023-04-20 10:30:44,382:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-20 10:30:44,462:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-20 10:30:44,477:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 10:30:44,542:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 10:30:45,252:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 10:30:45,562:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-20 10:30:45,562:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 10:30:45,612:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 10:30:45,617:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 10:30:45,617:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-20 10:30:45,697:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 10:30:45,757:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 10:30:45,762:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 10:30:45,837:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 10:30:45,888:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 10:30:45,893:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 10:30:45,893:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-20 10:30:46,027:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 10:30:46,031:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 10:30:46,163:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 10:30:46,168:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 10:30:46,183:INFO:Preparing preprocessing pipeline...
2023-04-20 10:30:46,183:INFO:Set up label encoding.
2023-04-20 10:30:46,183:INFO:Set up simple imputation.
2023-04-20 10:30:46,192:INFO:Set up encoding of ordinal features.
2023-04-20 10:30:46,192:INFO:Set up encoding of categorical features.
2023-04-20 10:30:46,192:INFO:Set up imbalanced handling.
2023-04-20 10:30:46,192:INFO:Set up feature normalization.
2023-04-20 10:30:46,552:INFO:Finished creating preprocessing pipeline.
2023-04-20 10:30:46,623:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-04-20 10:30:46,623:INFO:Creating final display dataframe.
2023-04-20 10:30:47,483:INFO:Setup _display_container:                     Description                      Value
0                    Session id                        123
1                        Target                      class
2                   Target type                     Binary
3                Target mapping  Aprovado: 0, Reprovado: 1
4           Original data shape                  (950, 22)
5        Transformed data shape                 (1217, 50)
6   Transformed train set shape                  (932, 50)
7    Transformed test set shape                  (285, 50)
8              Ordinal features                          3
9              Numeric features                         10
10         Categorical features                         11
11                   Preprocess                       True
12              Imputation type                     simple
13           Numeric imputation                       mean
14       Categorical imputation                       mode
15     Maximum one-hot encoding                         25
16              Encoding method                       None
17                Fix imbalance                       True
18         Fix imbalance method                      SMOTE
19                    Normalize                       True
20             Normalize method                     zscore
21               Fold Generator            StratifiedKFold
22                  Fold Number                         10
23                     CPU Jobs                         -1
24                      Use GPU                      False
25               Log Experiment                      False
26              Experiment Name           clf-default-name
27                          USI                       c03f
2023-04-20 10:30:47,717:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 10:30:47,722:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 10:30:47,898:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 10:30:47,903:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 10:30:47,908:INFO:setup() successfully completed in 7.01s...............
2023-04-20 10:31:39,884:INFO:Initializing get_config()
2023-04-20 10:31:39,885:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, variable=X_transformed)
2023-04-20 10:31:40,108:INFO:Variable: X returned as      checking_status  duration  credit_history_existing paid  \
266        -0.053981  0.125761                      0.982481   
400         1.103171 -1.058204                      0.982481   
395        -0.053981 -1.294997                     -1.139648   
553        -1.211133  0.599347                     -1.139648   
560        -0.053981 -0.821411                      0.982481   
..               ...       ...                           ...   
290        -0.053981  0.125761                     -1.139648   
770        -1.211133 -0.584618                      0.982481   
257         1.103171 -1.058204                      0.982481   
878         1.103171 -0.347825                     -1.139648   
278         1.103171 -0.505687                     -1.139648   

     credit_history_critical/other existing credit  \
266                                      -0.635305   
400                                      -0.635305   
395                                       1.731909   
553                                      -0.635305   
560                                      -0.635305   
..                                             ...   
290                                       1.731909   
770                                      -0.635305   
257                                      -0.635305   
878                                      -0.635305   
278                                       1.731909   

     credit_history_delayed previously  credit_history_no credits/all paid  \
266                          -0.340777                           -0.229129   
400                          -0.340777                           -0.229129   
395                          -0.340777                           -0.229129   
553                           3.300420                           -0.229129   
560                          -0.340777                           -0.229129   
..                                 ...                                 ...   
290                          -0.340777                           -0.229129   
770                          -0.340777                           -0.229129   
257                          -0.340777                           -0.229129   
878                           3.300420                           -0.229129   
278                          -0.340777                           -0.229129   

     credit_history_all paid  purpose_new car  purpose_radio/tv  \
266                -0.261683         1.827931         -0.607587   
400                -0.261683         1.827931         -0.607587   
395                -0.261683        -0.609839          1.799290   
553                -0.261683        -0.609839         -0.607587   
560                -0.261683         1.827931         -0.607587   
..                       ...              ...               ...   
290                -0.261683        -0.609839         -0.607587   
770                -0.261683        -0.609839          1.799290   
257                -0.261683        -0.609839         -0.607587   
878                -0.261683         1.827931         -0.607587   
278                -0.261683         1.827931         -0.607587   

     purpose_business  ...  job_high qualif/self emp/mgmt  \
266         -0.359298  ...                      -0.442125   
400         -0.359298  ...                      -0.442125   
395         -0.359298  ...                      -0.442125   
553          3.189403  ...                      -0.442125   
560         -0.359298  ...                      -0.442125   
..                ...  ...                            ...   
290         -0.359298  ...                       2.498640   
770         -0.359298  ...                      -0.442125   
257         -0.359298  ...                       2.498640   
878         -0.359298  ...                      -0.442125   
278         -0.359298  ...                      -0.442125   

     job_unemp/unskilled non res  num_dependents  own_telephone  \
266                    -0.164778       -0.425856      -0.858986   
400                    -0.164778       -0.425856      -0.858986   
395                    -0.164778       -0.425856      -0.858986   
553                    -0.164778       -0.425856      -0.858986   
560                    -0.164778       -0.425856      -0.858986   
..                           ...             ...            ...   
290                    -0.164778        2.540026       1.254460   
770                    -0.164778       -0.425856      -0.858986   
257                    -0.164778       -0.425856       1.254460   
878                    -0.164778        2.540026      -0.858986   
278                     6.933740       -0.425856       1.254460   

     foreign_worker       sex  marital_status_div/dep/mar  \
266         0.18537 -1.499047                    1.499047   
400         0.18537 -1.499047                    1.499047   
395         0.18537 -1.499047                    1.499047   
553         0.18537  0.731445                   -0.731445   
560         0.18537 -1.499047                    1.499047   
..              ...       ...                         ...   
290         0.18537 -1.499047                    1.499047   
770         0.18537  0.731445                   -0.731445   
257         0.18537 -1.499047                    1.499047   
878         0.18537  0.731445                   -0.731445   
278         0.18537  0.731445                   -0.731445   

     marital_status_single  marital_status_mar/wid  marital_status_div/sep  
266              -1.105950               -0.319238               -0.285766  
400              -1.105950               -0.319238               -0.285766  
395              -1.105950               -0.319238               -0.285766  
553               1.010603               -0.319238               -0.285766  
560              -1.105950               -0.319238               -0.285766  
..                     ...                     ...                     ...  
290              -1.105950               -0.319238               -0.285766  
770               1.010603               -0.319238               -0.285766  
257              -1.105950               -0.319238               -0.285766  
878               1.010603               -0.319238               -0.285766  
278               1.010603               -0.319238               -0.285766  

[1217 rows x 49 columns]
2023-04-20 10:31:40,108:INFO:get_config() successfully completed......................................
2023-04-20 10:32:03,247:INFO:Initializing compare_models()
2023-04-20 10:32:03,247:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-20 10:32:03,248:INFO:Checking exceptions
2023-04-20 10:32:03,262:INFO:Preparing display monitor
2023-04-20 10:32:03,338:INFO:Initializing Logistic Regression
2023-04-20 10:32:03,338:INFO:Total runtime is 0.0 minutes
2023-04-20 10:32:03,352:INFO:SubProcess create_model() called ==================================
2023-04-20 10:32:03,353:INFO:Initializing create_model()
2023-04-20 10:32:03,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CD900>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:32:03,355:INFO:Checking exceptions
2023-04-20 10:32:03,356:INFO:Importing libraries
2023-04-20 10:32:03,356:INFO:Copying training dataset
2023-04-20 10:32:03,385:INFO:Defining folds
2023-04-20 10:32:03,385:INFO:Declaring metric variables
2023-04-20 10:32:03,398:INFO:Importing untrained model
2023-04-20 10:32:03,410:INFO:Logistic Regression Imported successfully
2023-04-20 10:32:03,433:INFO:Starting cross validation
2023-04-20 10:32:03,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:32:27,313:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:32:27,404:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:32:27,588:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:32:27,733:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:32:48,772:INFO:Calculating mean and std
2023-04-20 10:32:48,772:INFO:Creating metrics dataframe
2023-04-20 10:32:51,322:INFO:Uploading results into container
2023-04-20 10:32:51,327:INFO:Uploading model into container now
2023-04-20 10:32:51,327:INFO:_master_model_container: 1
2023-04-20 10:32:51,327:INFO:_display_container: 2
2023-04-20 10:32:51,331:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-20 10:32:51,332:INFO:create_model() successfully completed......................................
2023-04-20 10:32:51,482:INFO:SubProcess create_model() end ==================================
2023-04-20 10:32:51,482:INFO:Creating metrics dataframe
2023-04-20 10:32:51,492:INFO:Initializing K Neighbors Classifier
2023-04-20 10:32:51,492:INFO:Total runtime is 0.802582859992981 minutes
2023-04-20 10:32:51,502:INFO:SubProcess create_model() called ==================================
2023-04-20 10:32:51,502:INFO:Initializing create_model()
2023-04-20 10:32:51,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CD900>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:32:51,502:INFO:Checking exceptions
2023-04-20 10:32:51,502:INFO:Importing libraries
2023-04-20 10:32:51,502:INFO:Copying training dataset
2023-04-20 10:32:51,525:INFO:Defining folds
2023-04-20 10:32:51,526:INFO:Declaring metric variables
2023-04-20 10:32:51,535:INFO:Importing untrained model
2023-04-20 10:32:51,545:INFO:K Neighbors Classifier Imported successfully
2023-04-20 10:32:51,573:INFO:Starting cross validation
2023-04-20 10:32:51,588:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:32:59,507:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:32:59,557:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:32:59,652:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:32:59,939:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:33:20,442:INFO:Calculating mean and std
2023-04-20 10:33:20,444:INFO:Creating metrics dataframe
2023-04-20 10:33:22,857:INFO:Uploading results into container
2023-04-20 10:33:22,857:INFO:Uploading model into container now
2023-04-20 10:33:22,862:INFO:_master_model_container: 2
2023-04-20 10:33:22,862:INFO:_display_container: 2
2023-04-20 10:33:22,862:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-20 10:33:22,862:INFO:create_model() successfully completed......................................
2023-04-20 10:33:23,007:INFO:SubProcess create_model() end ==================================
2023-04-20 10:33:23,007:INFO:Creating metrics dataframe
2023-04-20 10:33:23,035:INFO:Initializing Naive Bayes
2023-04-20 10:33:23,035:INFO:Total runtime is 1.3282963673273722 minutes
2023-04-20 10:33:23,043:INFO:SubProcess create_model() called ==================================
2023-04-20 10:33:23,044:INFO:Initializing create_model()
2023-04-20 10:33:23,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CD900>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:33:23,045:INFO:Checking exceptions
2023-04-20 10:33:23,045:INFO:Importing libraries
2023-04-20 10:33:23,045:INFO:Copying training dataset
2023-04-20 10:33:23,059:INFO:Defining folds
2023-04-20 10:33:23,059:INFO:Declaring metric variables
2023-04-20 10:33:23,072:INFO:Importing untrained model
2023-04-20 10:33:23,081:INFO:Naive Bayes Imported successfully
2023-04-20 10:33:23,107:INFO:Starting cross validation
2023-04-20 10:33:23,118:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:33:24,878:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:33:24,883:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:33:24,934:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:33:31,020:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:33:31,102:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:33:31,130:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:33:31,207:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:33:51,080:INFO:Calculating mean and std
2023-04-20 10:33:51,080:INFO:Creating metrics dataframe
2023-04-20 10:33:53,482:INFO:Uploading results into container
2023-04-20 10:33:53,482:INFO:Uploading model into container now
2023-04-20 10:33:53,487:INFO:_master_model_container: 3
2023-04-20 10:33:53,487:INFO:_display_container: 2
2023-04-20 10:33:53,487:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-20 10:33:53,487:INFO:create_model() successfully completed......................................
2023-04-20 10:33:53,643:INFO:SubProcess create_model() end ==================================
2023-04-20 10:33:53,643:INFO:Creating metrics dataframe
2023-04-20 10:33:53,663:INFO:Initializing Decision Tree Classifier
2023-04-20 10:33:53,663:INFO:Total runtime is 1.8387520790100096 minutes
2023-04-20 10:33:53,674:INFO:SubProcess create_model() called ==================================
2023-04-20 10:33:53,675:INFO:Initializing create_model()
2023-04-20 10:33:53,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CD900>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:33:53,676:INFO:Checking exceptions
2023-04-20 10:33:53,677:INFO:Importing libraries
2023-04-20 10:33:53,677:INFO:Copying training dataset
2023-04-20 10:33:53,690:INFO:Defining folds
2023-04-20 10:33:53,691:INFO:Declaring metric variables
2023-04-20 10:33:53,703:INFO:Importing untrained model
2023-04-20 10:33:53,721:INFO:Decision Tree Classifier Imported successfully
2023-04-20 10:33:53,744:INFO:Starting cross validation
2023-04-20 10:33:53,752:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:34:01,442:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:34:01,989:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:34:07,730:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:34:08,252:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:34:23,003:INFO:Calculating mean and std
2023-04-20 10:34:23,003:INFO:Creating metrics dataframe
2023-04-20 10:34:25,592:INFO:Uploading results into container
2023-04-20 10:34:25,592:INFO:Uploading model into container now
2023-04-20 10:34:25,592:INFO:_master_model_container: 4
2023-04-20 10:34:25,592:INFO:_display_container: 2
2023-04-20 10:34:25,592:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-04-20 10:34:25,592:INFO:create_model() successfully completed......................................
2023-04-20 10:34:25,737:INFO:SubProcess create_model() end ==================================
2023-04-20 10:34:25,737:INFO:Creating metrics dataframe
2023-04-20 10:34:25,768:INFO:Initializing SVM - Linear Kernel
2023-04-20 10:34:25,768:INFO:Total runtime is 2.3738442500432333 minutes
2023-04-20 10:34:25,779:INFO:SubProcess create_model() called ==================================
2023-04-20 10:34:25,780:INFO:Initializing create_model()
2023-04-20 10:34:25,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CD900>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:34:25,780:INFO:Checking exceptions
2023-04-20 10:34:25,781:INFO:Importing libraries
2023-04-20 10:34:25,781:INFO:Copying training dataset
2023-04-20 10:34:25,794:INFO:Defining folds
2023-04-20 10:34:25,795:INFO:Declaring metric variables
2023-04-20 10:34:25,805:INFO:Importing untrained model
2023-04-20 10:34:25,815:INFO:SVM - Linear Kernel Imported successfully
2023-04-20 10:34:25,844:INFO:Starting cross validation
2023-04-20 10:34:25,852:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:34:27,355:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:34:27,358:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:34:27,446:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:34:27,446:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:34:33,242:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:34:33,298:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:34:33,313:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:34:33,322:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:34:33,442:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:34:39,245:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:34:39,502:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:34:52,881:INFO:Calculating mean and std
2023-04-20 10:34:52,886:INFO:Creating metrics dataframe
2023-04-20 10:34:55,987:INFO:Uploading results into container
2023-04-20 10:34:55,992:INFO:Uploading model into container now
2023-04-20 10:34:55,992:INFO:_master_model_container: 5
2023-04-20 10:34:55,996:INFO:_display_container: 2
2023-04-20 10:34:55,997:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-20 10:34:55,997:INFO:create_model() successfully completed......................................
2023-04-20 10:34:56,148:INFO:SubProcess create_model() end ==================================
2023-04-20 10:34:56,148:INFO:Creating metrics dataframe
2023-04-20 10:34:56,172:INFO:Initializing Ridge Classifier
2023-04-20 10:34:56,172:INFO:Total runtime is 2.880576193332672 minutes
2023-04-20 10:34:56,172:INFO:SubProcess create_model() called ==================================
2023-04-20 10:34:56,172:INFO:Initializing create_model()
2023-04-20 10:34:56,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CD900>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:34:56,172:INFO:Checking exceptions
2023-04-20 10:34:56,182:INFO:Importing libraries
2023-04-20 10:34:56,182:INFO:Copying training dataset
2023-04-20 10:34:56,200:INFO:Defining folds
2023-04-20 10:34:56,200:INFO:Declaring metric variables
2023-04-20 10:34:56,212:INFO:Importing untrained model
2023-04-20 10:34:56,223:INFO:Ridge Classifier Imported successfully
2023-04-20 10:34:56,257:INFO:Starting cross validation
2023-04-20 10:34:56,265:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:34:57,762:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:34:57,784:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:34:57,797:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:34:57,827:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:35:03,500:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:35:03,522:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:35:03,552:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:35:03,682:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:35:03,692:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:35:09,437:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:35:09,662:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:35:23,740:INFO:Calculating mean and std
2023-04-20 10:35:23,743:INFO:Creating metrics dataframe
2023-04-20 10:35:27,931:INFO:Uploading results into container
2023-04-20 10:35:27,933:INFO:Uploading model into container now
2023-04-20 10:35:27,934:INFO:_master_model_container: 6
2023-04-20 10:35:27,936:INFO:_display_container: 2
2023-04-20 10:35:27,938:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-04-20 10:35:27,938:INFO:create_model() successfully completed......................................
2023-04-20 10:35:28,189:INFO:SubProcess create_model() end ==================================
2023-04-20 10:35:28,189:INFO:Creating metrics dataframe
2023-04-20 10:35:28,275:INFO:Initializing Random Forest Classifier
2023-04-20 10:35:28,276:INFO:Total runtime is 3.415649159749349 minutes
2023-04-20 10:35:28,292:INFO:SubProcess create_model() called ==================================
2023-04-20 10:35:28,294:INFO:Initializing create_model()
2023-04-20 10:35:28,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CD900>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:35:28,294:INFO:Checking exceptions
2023-04-20 10:35:28,295:INFO:Importing libraries
2023-04-20 10:35:28,295:INFO:Copying training dataset
2023-04-20 10:35:28,338:INFO:Defining folds
2023-04-20 10:35:28,338:INFO:Declaring metric variables
2023-04-20 10:35:28,351:INFO:Importing untrained model
2023-04-20 10:35:28,368:INFO:Random Forest Classifier Imported successfully
2023-04-20 10:35:28,420:INFO:Starting cross validation
2023-04-20 10:35:28,437:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:35:30,046:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-20 10:35:32,869:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:35:32,875:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:35:33,117:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:35:33,674:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:35:34,870:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:35:34,977:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:35:35,134:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:35:35,467:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:35:44,874:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:35:44,994:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:35:46,161:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:35:46,226:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:35:46,888:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:35:46,963:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:35:47,949:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:35:48,062:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:35:54,727:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:35:56,097:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:35:56,426:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:36:09,322:INFO:Calculating mean and std
2023-04-20 10:36:09,322:INFO:Creating metrics dataframe
2023-04-20 10:36:13,097:INFO:Uploading results into container
2023-04-20 10:36:13,097:INFO:Uploading model into container now
2023-04-20 10:36:13,097:INFO:_master_model_container: 7
2023-04-20 10:36:13,102:INFO:_display_container: 2
2023-04-20 10:36:13,102:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-20 10:36:13,102:INFO:create_model() successfully completed......................................
2023-04-20 10:36:13,276:INFO:SubProcess create_model() end ==================================
2023-04-20 10:36:13,276:INFO:Creating metrics dataframe
2023-04-20 10:36:13,312:INFO:Initializing Quadratic Discriminant Analysis
2023-04-20 10:36:13,312:INFO:Total runtime is 4.166248540083568 minutes
2023-04-20 10:36:13,324:INFO:SubProcess create_model() called ==================================
2023-04-20 10:36:13,325:INFO:Initializing create_model()
2023-04-20 10:36:13,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CD900>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:36:13,326:INFO:Checking exceptions
2023-04-20 10:36:13,327:INFO:Importing libraries
2023-04-20 10:36:13,327:INFO:Copying training dataset
2023-04-20 10:36:13,347:INFO:Defining folds
2023-04-20 10:36:13,348:INFO:Declaring metric variables
2023-04-20 10:36:13,358:INFO:Importing untrained model
2023-04-20 10:36:13,370:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-20 10:36:13,401:INFO:Starting cross validation
2023-04-20 10:36:13,415:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:36:14,232:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:36:14,237:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:36:14,237:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:36:20,446:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:36:20,476:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:36:20,622:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:36:20,702:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:36:21,442:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:36:26,486:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:36:26,762:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:36:40,737:INFO:Calculating mean and std
2023-04-20 10:36:40,742:INFO:Creating metrics dataframe
2023-04-20 10:36:44,459:INFO:Uploading results into container
2023-04-20 10:36:44,462:INFO:Uploading model into container now
2023-04-20 10:36:44,462:INFO:_master_model_container: 8
2023-04-20 10:36:44,462:INFO:_display_container: 2
2023-04-20 10:36:44,462:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-20 10:36:44,462:INFO:create_model() successfully completed......................................
2023-04-20 10:36:44,632:INFO:SubProcess create_model() end ==================================
2023-04-20 10:36:44,632:INFO:Creating metrics dataframe
2023-04-20 10:36:44,680:INFO:Initializing Ada Boost Classifier
2023-04-20 10:36:44,681:INFO:Total runtime is 4.689056579271953 minutes
2023-04-20 10:36:44,693:INFO:SubProcess create_model() called ==================================
2023-04-20 10:36:44,694:INFO:Initializing create_model()
2023-04-20 10:36:44,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CD900>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:36:44,695:INFO:Checking exceptions
2023-04-20 10:36:44,700:INFO:Importing libraries
2023-04-20 10:36:44,700:INFO:Copying training dataset
2023-04-20 10:36:44,719:INFO:Defining folds
2023-04-20 10:36:44,720:INFO:Declaring metric variables
2023-04-20 10:36:44,731:INFO:Importing untrained model
2023-04-20 10:36:44,745:INFO:Ada Boost Classifier Imported successfully
2023-04-20 10:36:44,774:INFO:Starting cross validation
2023-04-20 10:36:44,787:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:36:47,449:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:36:47,482:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:36:47,522:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:36:47,542:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:36:55,497:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:36:55,522:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:36:55,558:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:36:55,762:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:37:03,162:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:37:03,347:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:37:16,877:INFO:Calculating mean and std
2023-04-20 10:37:16,877:INFO:Creating metrics dataframe
2023-04-20 10:37:20,137:INFO:Uploading results into container
2023-04-20 10:37:20,137:INFO:Uploading model into container now
2023-04-20 10:37:20,137:INFO:_master_model_container: 9
2023-04-20 10:37:20,137:INFO:_display_container: 2
2023-04-20 10:37:20,137:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-04-20 10:37:20,142:INFO:create_model() successfully completed......................................
2023-04-20 10:37:20,287:INFO:SubProcess create_model() end ==================================
2023-04-20 10:37:20,287:INFO:Creating metrics dataframe
2023-04-20 10:37:20,317:INFO:Initializing Gradient Boosting Classifier
2023-04-20 10:37:20,317:INFO:Total runtime is 5.282990948359172 minutes
2023-04-20 10:37:20,327:INFO:SubProcess create_model() called ==================================
2023-04-20 10:37:20,329:INFO:Initializing create_model()
2023-04-20 10:37:20,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CD900>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:37:20,329:INFO:Checking exceptions
2023-04-20 10:37:20,330:INFO:Importing libraries
2023-04-20 10:37:20,330:INFO:Copying training dataset
2023-04-20 10:37:20,346:INFO:Defining folds
2023-04-20 10:37:20,346:INFO:Declaring metric variables
2023-04-20 10:37:20,354:INFO:Importing untrained model
2023-04-20 10:37:20,377:INFO:Gradient Boosting Classifier Imported successfully
2023-04-20 10:37:20,402:INFO:Starting cross validation
2023-04-20 10:37:20,408:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:37:23,447:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:37:23,457:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:37:23,472:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:37:23,502:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:37:32,148:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:37:32,222:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:37:32,383:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:37:32,544:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:37:40,532:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:37:40,662:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:37:53,302:INFO:Calculating mean and std
2023-04-20 10:37:53,302:INFO:Creating metrics dataframe
2023-04-20 10:37:55,922:INFO:Uploading results into container
2023-04-20 10:37:55,922:INFO:Uploading model into container now
2023-04-20 10:37:55,927:INFO:_master_model_container: 10
2023-04-20 10:37:55,927:INFO:_display_container: 2
2023-04-20 10:37:55,927:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-20 10:37:55,927:INFO:create_model() successfully completed......................................
2023-04-20 10:37:56,067:INFO:SubProcess create_model() end ==================================
2023-04-20 10:37:56,067:INFO:Creating metrics dataframe
2023-04-20 10:37:56,095:INFO:Initializing Linear Discriminant Analysis
2023-04-20 10:37:56,095:INFO:Total runtime is 5.879289460182191 minutes
2023-04-20 10:37:56,104:INFO:SubProcess create_model() called ==================================
2023-04-20 10:37:56,105:INFO:Initializing create_model()
2023-04-20 10:37:56,106:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CD900>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:37:56,106:INFO:Checking exceptions
2023-04-20 10:37:56,106:INFO:Importing libraries
2023-04-20 10:37:56,107:INFO:Copying training dataset
2023-04-20 10:37:56,122:INFO:Defining folds
2023-04-20 10:37:56,123:INFO:Declaring metric variables
2023-04-20 10:37:56,133:INFO:Importing untrained model
2023-04-20 10:37:56,147:INFO:Linear Discriminant Analysis Imported successfully
2023-04-20 10:37:56,171:INFO:Starting cross validation
2023-04-20 10:37:56,180:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:38:25,277:INFO:Calculating mean and std
2023-04-20 10:38:25,282:INFO:Creating metrics dataframe
2023-04-20 10:38:27,822:INFO:Uploading results into container
2023-04-20 10:38:27,827:INFO:Uploading model into container now
2023-04-20 10:38:27,827:INFO:_master_model_container: 11
2023-04-20 10:38:27,827:INFO:_display_container: 2
2023-04-20 10:38:27,827:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-20 10:38:27,827:INFO:create_model() successfully completed......................................
2023-04-20 10:38:27,982:INFO:SubProcess create_model() end ==================================
2023-04-20 10:38:27,982:INFO:Creating metrics dataframe
2023-04-20 10:38:28,002:INFO:Initializing Extra Trees Classifier
2023-04-20 10:38:28,002:INFO:Total runtime is 6.411074817180634 minutes
2023-04-20 10:38:28,012:INFO:SubProcess create_model() called ==================================
2023-04-20 10:38:28,012:INFO:Initializing create_model()
2023-04-20 10:38:28,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CD900>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:38:28,012:INFO:Checking exceptions
2023-04-20 10:38:28,012:INFO:Importing libraries
2023-04-20 10:38:28,022:INFO:Copying training dataset
2023-04-20 10:38:28,040:INFO:Defining folds
2023-04-20 10:38:28,041:INFO:Declaring metric variables
2023-04-20 10:38:28,054:INFO:Importing untrained model
2023-04-20 10:38:28,068:INFO:Extra Trees Classifier Imported successfully
2023-04-20 10:38:28,100:INFO:Starting cross validation
2023-04-20 10:38:28,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:38:31,155:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:38:31,163:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:38:31,225:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:38:31,268:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:38:38,868:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:38:38,912:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:38:38,929:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:38:39,012:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:38:40,456:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:38:40,482:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:38:40,532:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:38:40,685:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:38:47,527:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:38:49,032:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:38:49,322:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:39:02,154:INFO:Calculating mean and std
2023-04-20 10:39:02,154:INFO:Creating metrics dataframe
2023-04-20 10:39:05,177:INFO:Uploading results into container
2023-04-20 10:39:05,177:INFO:Uploading model into container now
2023-04-20 10:39:05,177:INFO:_master_model_container: 12
2023-04-20 10:39:05,177:INFO:_display_container: 2
2023-04-20 10:39:05,182:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-04-20 10:39:05,182:INFO:create_model() successfully completed......................................
2023-04-20 10:39:05,347:INFO:SubProcess create_model() end ==================================
2023-04-20 10:39:05,347:INFO:Creating metrics dataframe
2023-04-20 10:39:05,393:INFO:Initializing Extreme Gradient Boosting
2023-04-20 10:39:05,393:INFO:Total runtime is 7.034251228968303 minutes
2023-04-20 10:39:05,405:INFO:SubProcess create_model() called ==================================
2023-04-20 10:39:05,406:INFO:Initializing create_model()
2023-04-20 10:39:05,407:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CD900>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:39:05,407:INFO:Checking exceptions
2023-04-20 10:39:05,408:INFO:Importing libraries
2023-04-20 10:39:05,408:INFO:Copying training dataset
2023-04-20 10:39:05,431:INFO:Defining folds
2023-04-20 10:39:05,431:INFO:Declaring metric variables
2023-04-20 10:39:05,445:INFO:Importing untrained model
2023-04-20 10:39:05,462:INFO:Extreme Gradient Boosting Imported successfully
2023-04-20 10:39:05,491:INFO:Starting cross validation
2023-04-20 10:39:05,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:39:16,002:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:39:16,165:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:39:16,255:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:39:37,521:INFO:Calculating mean and std
2023-04-20 10:39:37,521:INFO:Creating metrics dataframe
2023-04-20 10:39:41,442:INFO:Uploading results into container
2023-04-20 10:39:41,445:INFO:Uploading model into container now
2023-04-20 10:39:41,446:INFO:_master_model_container: 13
2023-04-20 10:39:41,446:INFO:_display_container: 2
2023-04-20 10:39:41,449:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-20 10:39:41,450:INFO:create_model() successfully completed......................................
2023-04-20 10:39:41,617:INFO:SubProcess create_model() end ==================================
2023-04-20 10:39:41,617:INFO:Creating metrics dataframe
2023-04-20 10:39:41,652:INFO:Initializing Light Gradient Boosting Machine
2023-04-20 10:39:41,652:INFO:Total runtime is 7.638569939136506 minutes
2023-04-20 10:39:41,667:INFO:SubProcess create_model() called ==================================
2023-04-20 10:39:41,668:INFO:Initializing create_model()
2023-04-20 10:39:41,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CD900>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:39:41,669:INFO:Checking exceptions
2023-04-20 10:39:41,669:INFO:Importing libraries
2023-04-20 10:39:41,669:INFO:Copying training dataset
2023-04-20 10:39:41,686:INFO:Defining folds
2023-04-20 10:39:41,687:INFO:Declaring metric variables
2023-04-20 10:39:41,701:INFO:Importing untrained model
2023-04-20 10:39:41,714:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-20 10:39:41,749:INFO:Starting cross validation
2023-04-20 10:39:41,757:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:39:46,973:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:39:54,680:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:39:55,022:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:39:55,048:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:39:55,352:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:40:02,545:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:40:17,734:INFO:Calculating mean and std
2023-04-20 10:40:17,734:INFO:Creating metrics dataframe
2023-04-20 10:40:20,304:INFO:Uploading results into container
2023-04-20 10:40:20,304:INFO:Uploading model into container now
2023-04-20 10:40:20,309:INFO:_master_model_container: 14
2023-04-20 10:40:20,309:INFO:_display_container: 2
2023-04-20 10:40:20,309:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-20 10:40:20,309:INFO:create_model() successfully completed......................................
2023-04-20 10:40:20,457:INFO:SubProcess create_model() end ==================================
2023-04-20 10:40:20,457:INFO:Creating metrics dataframe
2023-04-20 10:40:20,484:INFO:Initializing CatBoost Classifier
2023-04-20 10:40:20,484:INFO:Total runtime is 8.285773289203645 minutes
2023-04-20 10:40:20,494:INFO:SubProcess create_model() called ==================================
2023-04-20 10:40:20,494:INFO:Initializing create_model()
2023-04-20 10:40:20,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CD900>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:40:20,494:INFO:Checking exceptions
2023-04-20 10:40:20,494:INFO:Importing libraries
2023-04-20 10:40:20,494:INFO:Copying training dataset
2023-04-20 10:40:20,515:INFO:Defining folds
2023-04-20 10:40:20,516:INFO:Declaring metric variables
2023-04-20 10:40:20,526:INFO:Importing untrained model
2023-04-20 10:40:20,538:INFO:CatBoost Classifier Imported successfully
2023-04-20 10:40:20,569:INFO:Starting cross validation
2023-04-20 10:40:20,575:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:40:55,243:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:41:27,604:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:41:30,608:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:41:53,659:INFO:Calculating mean and std
2023-04-20 10:41:53,664:INFO:Creating metrics dataframe
2023-04-20 10:41:57,304:INFO:Uploading results into container
2023-04-20 10:41:57,304:INFO:Uploading model into container now
2023-04-20 10:41:57,304:INFO:_master_model_container: 15
2023-04-20 10:41:57,304:INFO:_display_container: 2
2023-04-20 10:41:57,309:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DCAB4460>
2023-04-20 10:41:57,309:INFO:create_model() successfully completed......................................
2023-04-20 10:41:57,454:INFO:SubProcess create_model() end ==================================
2023-04-20 10:41:57,454:INFO:Creating metrics dataframe
2023-04-20 10:41:57,484:INFO:Initializing Dummy Classifier
2023-04-20 10:41:57,484:INFO:Total runtime is 9.902439391613008 minutes
2023-04-20 10:41:57,500:INFO:SubProcess create_model() called ==================================
2023-04-20 10:41:57,502:INFO:Initializing create_model()
2023-04-20 10:41:57,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CD900>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:41:57,502:INFO:Checking exceptions
2023-04-20 10:41:57,502:INFO:Importing libraries
2023-04-20 10:41:57,502:INFO:Copying training dataset
2023-04-20 10:41:57,520:INFO:Defining folds
2023-04-20 10:41:57,521:INFO:Declaring metric variables
2023-04-20 10:41:57,534:INFO:Importing untrained model
2023-04-20 10:41:57,546:INFO:Dummy Classifier Imported successfully
2023-04-20 10:41:57,576:INFO:Starting cross validation
2023-04-20 10:41:57,586:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:41:59,114:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 10:41:59,114:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 10:41:59,139:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 10:41:59,197:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 10:42:05,644:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:42:05,711:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:42:05,822:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:42:05,874:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 10:42:05,949:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 10:42:05,956:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:42:06,058:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 10:42:06,148:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 10:42:12,094:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 10:42:12,337:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 10:42:27,804:INFO:Calculating mean and std
2023-04-20 10:42:27,804:INFO:Creating metrics dataframe
2023-04-20 10:42:32,409:INFO:Uploading results into container
2023-04-20 10:42:32,411:INFO:Uploading model into container now
2023-04-20 10:42:32,411:INFO:_master_model_container: 16
2023-04-20 10:42:32,414:INFO:_display_container: 2
2023-04-20 10:42:32,414:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-04-20 10:42:32,414:INFO:create_model() successfully completed......................................
2023-04-20 10:42:32,642:INFO:SubProcess create_model() end ==================================
2023-04-20 10:42:32,642:INFO:Creating metrics dataframe
2023-04-20 10:42:32,743:INFO:Initializing create_model()
2023-04-20 10:42:32,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DA12EBC0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1DCAB4460>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:42:32,743:INFO:Checking exceptions
2023-04-20 10:42:32,749:INFO:Importing libraries
2023-04-20 10:42:32,750:INFO:Copying training dataset
2023-04-20 10:42:32,770:INFO:Defining folds
2023-04-20 10:42:32,770:INFO:Declaring metric variables
2023-04-20 10:42:32,771:INFO:Importing untrained model
2023-04-20 10:42:32,771:INFO:Declaring custom model
2023-04-20 10:42:32,772:INFO:CatBoost Classifier Imported successfully
2023-04-20 10:42:32,781:INFO:Cross validation set to False
2023-04-20 10:42:32,782:INFO:Fitting Model
2023-04-20 10:42:46,174:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DC7BF1C0>
2023-04-20 10:42:46,184:INFO:create_model() successfully completed......................................
2023-04-20 10:42:46,447:INFO:_master_model_container: 16
2023-04-20 10:42:46,448:INFO:_display_container: 2
2023-04-20 10:42:46,448:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DC7BF1C0>
2023-04-20 10:42:46,449:INFO:compare_models() successfully completed......................................
2023-04-20 10:48:40,400:INFO:PyCaret ClassificationExperiment
2023-04-20 10:48:40,400:INFO:Logging name: clf-default-name
2023-04-20 10:48:40,400:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-20 10:48:40,400:INFO:version 3.0.0
2023-04-20 10:48:40,400:INFO:Initializing setup()
2023-04-20 10:48:40,400:INFO:self.USI: 0354
2023-04-20 10:48:40,400:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'memory', 'USI', 'X_train', 'seed', 'log_plots_param', 'gpu_param', 'html_param', 'exp_id', 'gpu_n_jobs_param', 'target_param', 'is_multiclass', 'data', 'y_train', 'y_test', 'X_test', 'y', '_ml_usecase', 'n_jobs_param', 'fix_imbalance', 'fold_groups_param', 'idx', 'exp_name_log', 'fold_generator', 'logging_param', 'X', '_available_plots'}
2023-04-20 10:48:40,400:INFO:Checking environment
2023-04-20 10:48:40,400:INFO:python_version: 3.10.9
2023-04-20 10:48:40,400:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-04-20 10:48:40,400:INFO:machine: AMD64
2023-04-20 10:48:40,400:INFO:platform: Windows-10-10.0.19044-SP0
2023-04-20 10:48:40,400:INFO:Memory: svmem(total=8483184640, available=3772059648, percent=55.5, used=4711124992, free=3772059648)
2023-04-20 10:48:40,400:INFO:Physical Core: 2
2023-04-20 10:48:40,400:INFO:Logical Core: 4
2023-04-20 10:48:40,400:INFO:Checking libraries
2023-04-20 10:48:40,400:INFO:System:
2023-04-20 10:48:40,400:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-04-20 10:48:40,400:INFO:executable: C:\Users\User\.conda\envs\My_envI\python.exe
2023-04-20 10:48:40,400:INFO:   machine: Windows-10-10.0.19044-SP0
2023-04-20 10:48:40,400:INFO:PyCaret required dependencies:
2023-04-20 10:48:40,400:INFO:                 pip: 22.3.1
2023-04-20 10:48:40,400:INFO:          setuptools: 66.0.0
2023-04-20 10:48:40,400:INFO:             pycaret: 3.0.0
2023-04-20 10:48:40,400:INFO:             IPython: 8.12.0
2023-04-20 10:48:40,405:INFO:          ipywidgets: 7.6.5
2023-04-20 10:48:40,405:INFO:                tqdm: 4.64.1
2023-04-20 10:48:40,405:INFO:               numpy: 1.23.5
2023-04-20 10:48:40,405:INFO:              pandas: 1.5.3
2023-04-20 10:48:40,405:INFO:              jinja2: 3.1.2
2023-04-20 10:48:40,405:INFO:               scipy: 1.10.1
2023-04-20 10:48:40,405:INFO:              joblib: 1.2.0
2023-04-20 10:48:40,405:INFO:             sklearn: 1.2.1
2023-04-20 10:48:40,405:INFO:                pyod: 1.0.9
2023-04-20 10:48:40,405:INFO:            imblearn: 0.10.1
2023-04-20 10:48:40,405:INFO:   category_encoders: 2.6.0
2023-04-20 10:48:40,405:INFO:            lightgbm: 3.3.5
2023-04-20 10:48:40,405:INFO:               numba: 0.56.4
2023-04-20 10:48:40,405:INFO:            requests: 2.28.1
2023-04-20 10:48:40,405:INFO:          matplotlib: 3.7.0
2023-04-20 10:48:40,405:INFO:          scikitplot: 0.3.7
2023-04-20 10:48:40,405:INFO:         yellowbrick: 1.5
2023-04-20 10:48:40,405:INFO:              plotly: 5.14.1
2023-04-20 10:48:40,405:INFO:             kaleido: 0.2.1
2023-04-20 10:48:40,405:INFO:         statsmodels: 0.13.5
2023-04-20 10:48:40,405:INFO:              sktime: 0.17.0
2023-04-20 10:48:40,405:INFO:               tbats: 1.1.2
2023-04-20 10:48:40,405:INFO:            pmdarima: 2.0.3
2023-04-20 10:48:40,405:INFO:              psutil: 5.9.0
2023-04-20 10:48:40,405:INFO:PyCaret optional dependencies:
2023-04-20 10:48:40,405:INFO:                shap: 0.41.0
2023-04-20 10:48:40,405:INFO:           interpret: 0.3.2
2023-04-20 10:48:40,405:INFO:                umap: 0.5.3
2023-04-20 10:48:40,405:INFO:    pandas_profiling: 4.1.2
2023-04-20 10:48:40,405:INFO:  explainerdashboard: 0.4.2.1
2023-04-20 10:48:40,405:INFO:             autoviz: 0.1.58
2023-04-20 10:48:40,405:INFO:           fairlearn: 0.7.0
2023-04-20 10:48:40,405:INFO:             xgboost: 1.7.5
2023-04-20 10:48:40,405:INFO:            catboost: 1.1.1
2023-04-20 10:48:40,405:INFO:              kmodes: 0.12.2
2023-04-20 10:48:40,405:INFO:             mlxtend: 0.22.0
2023-04-20 10:48:40,405:INFO:       statsforecast: 1.5.0
2023-04-20 10:48:40,405:INFO:        tune_sklearn: 0.4.5
2023-04-20 10:48:40,405:INFO:                 ray: 2.3.1
2023-04-20 10:48:40,405:INFO:            hyperopt: 0.2.7
2023-04-20 10:48:40,405:INFO:              optuna: 3.1.0
2023-04-20 10:48:40,405:INFO:               skopt: 0.9.0
2023-04-20 10:48:40,405:INFO:              mlflow: 1.30.1
2023-04-20 10:48:40,405:INFO:              gradio: Not installed
2023-04-20 10:48:40,405:INFO:             fastapi: 0.89.1
2023-04-20 10:48:40,405:INFO:             uvicorn: 0.21.1
2023-04-20 10:48:40,405:INFO:              m2cgen: 0.10.0
2023-04-20 10:48:40,405:INFO:           evidently: 0.2.8
2023-04-20 10:48:40,409:INFO:               fugue: 0.8.3
2023-04-20 10:48:40,409:INFO:           streamlit: Not installed
2023-04-20 10:48:40,409:INFO:             prophet: Not installed
2023-04-20 10:48:40,409:INFO:None
2023-04-20 10:48:40,409:INFO:Set up data.
2023-04-20 10:48:40,434:INFO:Set up train/test split.
2023-04-20 10:48:40,449:INFO:Set up index.
2023-04-20 10:48:40,449:INFO:Set up folding strategy.
2023-04-20 10:48:40,449:INFO:Assigning column types.
2023-04-20 10:48:40,459:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-20 10:48:40,565:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-20 10:48:40,565:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 10:48:40,639:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 10:48:40,644:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 10:48:40,788:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-20 10:48:40,788:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 10:48:40,844:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 10:48:40,854:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 10:48:40,854:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-20 10:48:40,944:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 10:48:41,013:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 10:48:41,024:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 10:48:41,134:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 10:48:41,194:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 10:48:41,194:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 10:48:41,194:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-20 10:48:41,354:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 10:48:41,364:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 10:48:41,529:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 10:48:41,534:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 10:48:41,534:INFO:Preparing preprocessing pipeline...
2023-04-20 10:48:41,534:INFO:Set up label encoding.
2023-04-20 10:48:41,534:INFO:Set up simple imputation.
2023-04-20 10:48:41,545:INFO:Set up encoding of ordinal features.
2023-04-20 10:48:41,554:INFO:Set up encoding of categorical features.
2023-04-20 10:48:41,554:INFO:Set up imbalanced handling.
2023-04-20 10:48:41,554:INFO:Set up feature normalization.
2023-04-20 10:48:42,474:INFO:Finished creating preprocessing pipeline.
2023-04-20 10:48:42,575:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['credit_amount', 'checking_status',
                                             'duration'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-04-20 10:48:42,575:INFO:Creating final display dataframe.
2023-04-20 10:48:44,109:INFO:Setup _display_container:                     Description                      Value
0                    Session id                        123
1                        Target                      class
2                   Target type                     Binary
3                Target mapping  Aprovado: 0, Reprovado: 1
4           Original data shape                  (950, 22)
5        Transformed data shape                 (1217, 50)
6   Transformed train set shape                  (932, 50)
7    Transformed test set shape                  (285, 50)
8              Ordinal features                          3
9              Numeric features                          3
10         Categorical features                         11
11                   Preprocess                       True
12              Imputation type                     simple
13           Numeric imputation                       mean
14       Categorical imputation                       mode
15     Maximum one-hot encoding                         25
16              Encoding method                       None
17                Fix imbalance                       True
18         Fix imbalance method                      SMOTE
19                    Normalize                       True
20             Normalize method                     zscore
21               Fold Generator            StratifiedKFold
22                  Fold Number                         10
23                     CPU Jobs                         -1
24                      Use GPU                      False
25               Log Experiment                      False
26              Experiment Name           clf-default-name
27                          USI                       0354
2023-04-20 10:48:44,329:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 10:48:44,339:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 10:48:44,494:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 10:48:44,504:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 10:48:44,504:INFO:setup() successfully completed in 5.93s...............
2023-04-20 10:49:08,214:INFO:Initializing get_config()
2023-04-20 10:49:08,215:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, variable=X_transformed)
2023-04-20 10:49:08,404:INFO:Variable: X returned as      checking_status  duration  credit_history_existing paid  \
266        -0.053981  0.125761                      0.982481   
400         1.103171 -1.058204                      0.982481   
395        -0.053981 -1.294997                     -1.139648   
553        -1.211133  0.599347                     -1.139648   
560        -0.053981 -0.821411                      0.982481   
..               ...       ...                           ...   
290        -0.053981  0.125761                     -1.139648   
770        -1.211133 -0.584618                      0.982481   
257         1.103171 -1.058204                      0.982481   
878         1.103171 -0.347825                     -1.139648   
278         1.103171 -0.505687                     -1.139648   

     credit_history_critical/other existing credit  \
266                                      -0.635305   
400                                      -0.635305   
395                                       1.731909   
553                                      -0.635305   
560                                      -0.635305   
..                                             ...   
290                                       1.731909   
770                                      -0.635305   
257                                      -0.635305   
878                                      -0.635305   
278                                       1.731909   

     credit_history_delayed previously  credit_history_no credits/all paid  \
266                          -0.340777                           -0.229129   
400                          -0.340777                           -0.229129   
395                          -0.340777                           -0.229129   
553                           3.300420                           -0.229129   
560                          -0.340777                           -0.229129   
..                                 ...                                 ...   
290                          -0.340777                           -0.229129   
770                          -0.340777                           -0.229129   
257                          -0.340777                           -0.229129   
878                           3.300420                           -0.229129   
278                          -0.340777                           -0.229129   

     credit_history_all paid  purpose_new car  purpose_radio/tv  \
266                -0.261683         1.827931         -0.607587   
400                -0.261683         1.827931         -0.607587   
395                -0.261683        -0.609839          1.799290   
553                -0.261683        -0.609839         -0.607587   
560                -0.261683         1.827931         -0.607587   
..                       ...              ...               ...   
290                -0.261683        -0.609839         -0.607587   
770                -0.261683        -0.609839          1.799290   
257                -0.261683        -0.609839         -0.607587   
878                -0.261683         1.827931         -0.607587   
278                -0.261683         1.827931         -0.607587   

     purpose_business  ...  job_high qualif/self emp/mgmt  \
266         -0.359298  ...                      -0.442125   
400         -0.359298  ...                      -0.442125   
395         -0.359298  ...                      -0.442125   
553          3.189403  ...                      -0.442125   
560         -0.359298  ...                      -0.442125   
..                ...  ...                            ...   
290         -0.359298  ...                       2.498640   
770         -0.359298  ...                      -0.442125   
257         -0.359298  ...                       2.498640   
878         -0.359298  ...                      -0.442125   
278         -0.359298  ...                      -0.442125   

     job_unemp/unskilled non res  num_dependents  own_telephone  \
266                    -0.164778       -0.425856      -0.858986   
400                    -0.164778       -0.425856      -0.858986   
395                    -0.164778       -0.425856      -0.858986   
553                    -0.164778       -0.425856      -0.858986   
560                    -0.164778       -0.425856      -0.858986   
..                           ...             ...            ...   
290                    -0.164778        2.540026       1.254460   
770                    -0.164778       -0.425856      -0.858986   
257                    -0.164778       -0.425856       1.254460   
878                    -0.164778        2.540026      -0.858986   
278                     6.933740       -0.425856       1.254460   

     foreign_worker       sex  marital_status_div/dep/mar  \
266         0.18537 -1.499047                    1.499047   
400         0.18537 -1.499047                    1.499047   
395         0.18537 -1.499047                    1.499047   
553         0.18537  0.731445                   -0.731445   
560         0.18537 -1.499047                    1.499047   
..              ...       ...                         ...   
290         0.18537 -1.499047                    1.499047   
770         0.18537  0.731445                   -0.731445   
257         0.18537 -1.499047                    1.499047   
878         0.18537  0.731445                   -0.731445   
278         0.18537  0.731445                   -0.731445   

     marital_status_single  marital_status_mar/wid  marital_status_div/sep  
266              -1.105950               -0.319238               -0.285766  
400              -1.105950               -0.319238               -0.285766  
395              -1.105950               -0.319238               -0.285766  
553               1.010603               -0.319238               -0.285766  
560              -1.105950               -0.319238               -0.285766  
..                     ...                     ...                     ...  
290              -1.105950               -0.319238               -0.285766  
770               1.010603               -0.319238               -0.285766  
257              -1.105950               -0.319238               -0.285766  
878               1.010603               -0.319238               -0.285766  
278               1.010603               -0.319238               -0.285766  

[1217 rows x 49 columns]
2023-04-20 10:49:08,404:INFO:get_config() successfully completed......................................
2023-04-20 10:49:36,802:INFO:Initializing compare_models()
2023-04-20 10:49:36,802:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-20 10:49:36,802:INFO:Checking exceptions
2023-04-20 10:49:36,813:INFO:Preparing display monitor
2023-04-20 10:49:36,889:INFO:Initializing Logistic Regression
2023-04-20 10:49:36,890:INFO:Total runtime is 1.6657511393229165e-05 minutes
2023-04-20 10:49:36,901:INFO:SubProcess create_model() called ==================================
2023-04-20 10:49:36,902:INFO:Initializing create_model()
2023-04-20 10:49:36,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DBC250F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:49:36,903:INFO:Checking exceptions
2023-04-20 10:49:36,904:INFO:Importing libraries
2023-04-20 10:49:36,904:INFO:Copying training dataset
2023-04-20 10:49:36,924:INFO:Defining folds
2023-04-20 10:49:36,925:INFO:Declaring metric variables
2023-04-20 10:49:36,935:INFO:Importing untrained model
2023-04-20 10:49:36,948:INFO:Logistic Regression Imported successfully
2023-04-20 10:49:36,971:INFO:Starting cross validation
2023-04-20 10:49:36,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:50:02,456:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:50:02,510:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:50:02,550:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:50:03,037:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:50:11,808:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:50:11,972:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:50:27,738:INFO:Calculating mean and std
2023-04-20 10:50:27,738:INFO:Creating metrics dataframe
2023-04-20 10:50:30,558:INFO:Uploading results into container
2023-04-20 10:50:30,563:INFO:Uploading model into container now
2023-04-20 10:50:30,563:INFO:_master_model_container: 1
2023-04-20 10:50:30,563:INFO:_display_container: 2
2023-04-20 10:50:30,563:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-20 10:50:30,563:INFO:create_model() successfully completed......................................
2023-04-20 10:50:30,718:INFO:SubProcess create_model() end ==================================
2023-04-20 10:50:30,718:INFO:Creating metrics dataframe
2023-04-20 10:50:30,733:INFO:Initializing K Neighbors Classifier
2023-04-20 10:50:30,733:INFO:Total runtime is 0.8974081675211588 minutes
2023-04-20 10:50:30,748:INFO:SubProcess create_model() called ==================================
2023-04-20 10:50:30,749:INFO:Initializing create_model()
2023-04-20 10:50:30,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DBC250F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:50:30,750:INFO:Checking exceptions
2023-04-20 10:50:30,750:INFO:Importing libraries
2023-04-20 10:50:30,751:INFO:Copying training dataset
2023-04-20 10:50:30,767:INFO:Defining folds
2023-04-20 10:50:30,767:INFO:Declaring metric variables
2023-04-20 10:50:30,778:INFO:Importing untrained model
2023-04-20 10:50:30,792:INFO:K Neighbors Classifier Imported successfully
2023-04-20 10:50:30,813:INFO:Starting cross validation
2023-04-20 10:50:30,823:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:50:40,983:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:50:41,218:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:51:02,553:INFO:Calculating mean and std
2023-04-20 10:51:02,555:INFO:Creating metrics dataframe
2023-04-20 10:51:05,788:INFO:Uploading results into container
2023-04-20 10:51:05,788:INFO:Uploading model into container now
2023-04-20 10:51:05,788:INFO:_master_model_container: 2
2023-04-20 10:51:05,788:INFO:_display_container: 2
2023-04-20 10:51:05,793:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-20 10:51:05,793:INFO:create_model() successfully completed......................................
2023-04-20 10:51:05,958:INFO:SubProcess create_model() end ==================================
2023-04-20 10:51:05,958:INFO:Creating metrics dataframe
2023-04-20 10:51:05,983:INFO:Initializing Naive Bayes
2023-04-20 10:51:05,983:INFO:Total runtime is 1.4849115292231243 minutes
2023-04-20 10:51:05,995:INFO:SubProcess create_model() called ==================================
2023-04-20 10:51:05,996:INFO:Initializing create_model()
2023-04-20 10:51:05,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DBC250F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:51:05,997:INFO:Checking exceptions
2023-04-20 10:51:05,998:INFO:Importing libraries
2023-04-20 10:51:05,998:INFO:Copying training dataset
2023-04-20 10:51:06,017:INFO:Defining folds
2023-04-20 10:51:06,017:INFO:Declaring metric variables
2023-04-20 10:51:06,030:INFO:Importing untrained model
2023-04-20 10:51:06,049:INFO:Naive Bayes Imported successfully
2023-04-20 10:51:06,078:INFO:Starting cross validation
2023-04-20 10:51:06,088:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:51:14,569:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:51:14,788:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:51:14,808:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:51:36,028:INFO:Calculating mean and std
2023-04-20 10:51:36,028:INFO:Creating metrics dataframe
2023-04-20 10:51:40,033:INFO:Uploading results into container
2023-04-20 10:51:40,033:INFO:Uploading model into container now
2023-04-20 10:51:40,038:INFO:_master_model_container: 3
2023-04-20 10:51:40,038:INFO:_display_container: 2
2023-04-20 10:51:40,038:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-20 10:51:40,038:INFO:create_model() successfully completed......................................
2023-04-20 10:51:40,228:INFO:SubProcess create_model() end ==================================
2023-04-20 10:51:40,228:INFO:Creating metrics dataframe
2023-04-20 10:51:40,253:INFO:Initializing Decision Tree Classifier
2023-04-20 10:51:40,253:INFO:Total runtime is 2.0560813029607137 minutes
2023-04-20 10:51:40,264:INFO:SubProcess create_model() called ==================================
2023-04-20 10:51:40,266:INFO:Initializing create_model()
2023-04-20 10:51:40,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DBC250F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:51:40,267:INFO:Checking exceptions
2023-04-20 10:51:40,267:INFO:Importing libraries
2023-04-20 10:51:40,268:INFO:Copying training dataset
2023-04-20 10:51:40,287:INFO:Defining folds
2023-04-20 10:51:40,288:INFO:Declaring metric variables
2023-04-20 10:51:40,299:INFO:Importing untrained model
2023-04-20 10:51:40,325:INFO:Decision Tree Classifier Imported successfully
2023-04-20 10:51:40,351:INFO:Starting cross validation
2023-04-20 10:51:40,361:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:51:49,073:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:52:11,588:INFO:Calculating mean and std
2023-04-20 10:52:11,588:INFO:Creating metrics dataframe
2023-04-20 10:52:15,383:INFO:Uploading results into container
2023-04-20 10:52:15,388:INFO:Uploading model into container now
2023-04-20 10:52:15,388:INFO:_master_model_container: 4
2023-04-20 10:52:15,388:INFO:_display_container: 2
2023-04-20 10:52:15,388:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-04-20 10:52:15,388:INFO:create_model() successfully completed......................................
2023-04-20 10:52:15,579:INFO:SubProcess create_model() end ==================================
2023-04-20 10:52:15,579:INFO:Creating metrics dataframe
2023-04-20 10:52:15,604:INFO:Initializing SVM - Linear Kernel
2023-04-20 10:52:15,604:INFO:Total runtime is 2.6452507177988687 minutes
2023-04-20 10:52:15,618:INFO:SubProcess create_model() called ==================================
2023-04-20 10:52:15,618:INFO:Initializing create_model()
2023-04-20 10:52:15,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DBC250F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:52:15,618:INFO:Checking exceptions
2023-04-20 10:52:15,618:INFO:Importing libraries
2023-04-20 10:52:15,618:INFO:Copying training dataset
2023-04-20 10:52:15,634:INFO:Defining folds
2023-04-20 10:52:15,634:INFO:Declaring metric variables
2023-04-20 10:52:15,643:INFO:Importing untrained model
2023-04-20 10:52:15,653:INFO:SVM - Linear Kernel Imported successfully
2023-04-20 10:52:15,674:INFO:Starting cross validation
2023-04-20 10:52:15,684:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:52:17,158:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:52:17,193:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:52:17,195:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:52:17,209:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:52:23,548:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:52:23,550:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:52:23,561:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:52:23,635:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:52:23,646:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:52:23,668:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:52:30,038:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:52:30,117:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 10:52:45,607:INFO:Calculating mean and std
2023-04-20 10:52:45,610:INFO:Creating metrics dataframe
2023-04-20 10:52:49,251:INFO:Uploading results into container
2023-04-20 10:52:49,251:INFO:Uploading model into container now
2023-04-20 10:52:49,251:INFO:_master_model_container: 5
2023-04-20 10:52:49,251:INFO:_display_container: 2
2023-04-20 10:52:49,251:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-20 10:52:49,251:INFO:create_model() successfully completed......................................
2023-04-20 10:52:49,385:INFO:SubProcess create_model() end ==================================
2023-04-20 10:52:49,385:INFO:Creating metrics dataframe
2023-04-20 10:52:49,411:INFO:Initializing Ridge Classifier
2023-04-20 10:52:49,411:INFO:Total runtime is 3.208704078197479 minutes
2023-04-20 10:52:49,411:INFO:SubProcess create_model() called ==================================
2023-04-20 10:52:49,411:INFO:Initializing create_model()
2023-04-20 10:52:49,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DBC250F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:52:49,411:INFO:Checking exceptions
2023-04-20 10:52:49,411:INFO:Importing libraries
2023-04-20 10:52:49,411:INFO:Copying training dataset
2023-04-20 10:52:49,435:INFO:Defining folds
2023-04-20 10:52:49,435:INFO:Declaring metric variables
2023-04-20 10:52:49,455:INFO:Importing untrained model
2023-04-20 10:52:49,461:INFO:Ridge Classifier Imported successfully
2023-04-20 10:52:49,461:INFO:Starting cross validation
2023-04-20 10:52:49,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:52:50,963:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:52:50,968:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:52:50,989:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:52:51,059:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:52:57,238:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:52:57,253:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:52:57,338:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:52:57,348:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:52:57,348:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:52:57,526:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:52:57,537:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:53:03,842:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:53:03,934:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 10:53:19,448:INFO:Calculating mean and std
2023-04-20 10:53:19,448:INFO:Creating metrics dataframe
2023-04-20 10:53:23,483:INFO:Uploading results into container
2023-04-20 10:53:23,483:INFO:Uploading model into container now
2023-04-20 10:53:23,483:INFO:_master_model_container: 6
2023-04-20 10:53:23,483:INFO:_display_container: 2
2023-04-20 10:53:23,483:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-04-20 10:53:23,488:INFO:create_model() successfully completed......................................
2023-04-20 10:53:23,629:INFO:SubProcess create_model() end ==================================
2023-04-20 10:53:23,629:INFO:Creating metrics dataframe
2023-04-20 10:53:23,648:INFO:Initializing Random Forest Classifier
2023-04-20 10:53:23,648:INFO:Total runtime is 3.7793284177780153 minutes
2023-04-20 10:53:23,658:INFO:SubProcess create_model() called ==================================
2023-04-20 10:53:23,658:INFO:Initializing create_model()
2023-04-20 10:53:23,658:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DBC250F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:53:23,658:INFO:Checking exceptions
2023-04-20 10:53:23,658:INFO:Importing libraries
2023-04-20 10:53:23,658:INFO:Copying training dataset
2023-04-20 10:53:23,674:INFO:Defining folds
2023-04-20 10:53:23,674:INFO:Declaring metric variables
2023-04-20 10:53:23,679:INFO:Importing untrained model
2023-04-20 10:53:23,689:INFO:Random Forest Classifier Imported successfully
2023-04-20 10:53:23,708:INFO:Starting cross validation
2023-04-20 10:53:23,719:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:53:26,985:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:53:26,993:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:53:27,008:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:53:27,093:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:53:35,284:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:53:35,284:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:53:35,394:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:53:35,478:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:53:36,948:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:53:36,978:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:53:37,073:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:53:37,078:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:53:44,885:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:53:46,479:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:53:46,489:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:54:00,328:INFO:Calculating mean and std
2023-04-20 10:54:00,333:INFO:Creating metrics dataframe
2023-04-20 10:54:04,348:INFO:Uploading results into container
2023-04-20 10:54:04,353:INFO:Uploading model into container now
2023-04-20 10:54:04,353:INFO:_master_model_container: 7
2023-04-20 10:54:04,353:INFO:_display_container: 2
2023-04-20 10:54:04,353:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-20 10:54:04,353:INFO:create_model() successfully completed......................................
2023-04-20 10:54:04,518:INFO:SubProcess create_model() end ==================================
2023-04-20 10:54:04,518:INFO:Creating metrics dataframe
2023-04-20 10:54:04,553:INFO:Initializing Quadratic Discriminant Analysis
2023-04-20 10:54:04,553:INFO:Total runtime is 4.461080284913381 minutes
2023-04-20 10:54:04,563:INFO:SubProcess create_model() called ==================================
2023-04-20 10:54:04,569:INFO:Initializing create_model()
2023-04-20 10:54:04,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DBC250F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:54:04,569:INFO:Checking exceptions
2023-04-20 10:54:04,569:INFO:Importing libraries
2023-04-20 10:54:04,569:INFO:Copying training dataset
2023-04-20 10:54:04,588:INFO:Defining folds
2023-04-20 10:54:04,588:INFO:Declaring metric variables
2023-04-20 10:54:04,593:INFO:Importing untrained model
2023-04-20 10:54:04,603:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-20 10:54:04,628:INFO:Starting cross validation
2023-04-20 10:54:04,638:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:54:05,490:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:54:05,531:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:54:05,553:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:54:05,561:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:54:12,225:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:54:12,330:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:54:12,399:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:54:12,492:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:54:13,389:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:54:13,568:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:54:13,648:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:54:13,668:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:54:19,677:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:54:19,832:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 10:54:38,539:INFO:Calculating mean and std
2023-04-20 10:54:38,539:INFO:Creating metrics dataframe
2023-04-20 10:54:41,833:INFO:Uploading results into container
2023-04-20 10:54:41,833:INFO:Uploading model into container now
2023-04-20 10:54:41,833:INFO:_master_model_container: 8
2023-04-20 10:54:41,833:INFO:_display_container: 2
2023-04-20 10:54:41,839:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-20 10:54:41,839:INFO:create_model() successfully completed......................................
2023-04-20 10:54:41,989:INFO:SubProcess create_model() end ==================================
2023-04-20 10:54:41,989:INFO:Creating metrics dataframe
2023-04-20 10:54:42,018:INFO:Initializing Ada Boost Classifier
2023-04-20 10:54:42,018:INFO:Total runtime is 5.085495885213216 minutes
2023-04-20 10:54:42,018:INFO:SubProcess create_model() called ==================================
2023-04-20 10:54:42,028:INFO:Initializing create_model()
2023-04-20 10:54:42,028:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DBC250F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:54:42,028:INFO:Checking exceptions
2023-04-20 10:54:42,028:INFO:Importing libraries
2023-04-20 10:54:42,028:INFO:Copying training dataset
2023-04-20 10:54:42,050:INFO:Defining folds
2023-04-20 10:54:42,051:INFO:Declaring metric variables
2023-04-20 10:54:42,062:INFO:Importing untrained model
2023-04-20 10:54:42,072:INFO:Ada Boost Classifier Imported successfully
2023-04-20 10:54:42,103:INFO:Starting cross validation
2023-04-20 10:54:42,118:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:54:52,748:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:54:52,788:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:54:52,848:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:54:52,909:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:55:01,109:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:55:01,163:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:55:15,748:INFO:Calculating mean and std
2023-04-20 10:55:15,748:INFO:Creating metrics dataframe
2023-04-20 10:55:18,638:INFO:Uploading results into container
2023-04-20 10:55:18,638:INFO:Uploading model into container now
2023-04-20 10:55:18,643:INFO:_master_model_container: 9
2023-04-20 10:55:18,643:INFO:_display_container: 2
2023-04-20 10:55:18,643:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-04-20 10:55:18,643:INFO:create_model() successfully completed......................................
2023-04-20 10:55:18,788:INFO:SubProcess create_model() end ==================================
2023-04-20 10:55:18,788:INFO:Creating metrics dataframe
2023-04-20 10:55:18,818:INFO:Initializing Gradient Boosting Classifier
2023-04-20 10:55:18,826:INFO:Total runtime is 5.6989494601885475 minutes
2023-04-20 10:55:18,834:INFO:SubProcess create_model() called ==================================
2023-04-20 10:55:18,835:INFO:Initializing create_model()
2023-04-20 10:55:18,835:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DBC250F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:55:18,836:INFO:Checking exceptions
2023-04-20 10:55:18,836:INFO:Importing libraries
2023-04-20 10:55:18,837:INFO:Copying training dataset
2023-04-20 10:55:18,850:INFO:Defining folds
2023-04-20 10:55:18,851:INFO:Declaring metric variables
2023-04-20 10:55:18,861:INFO:Importing untrained model
2023-04-20 10:55:18,876:INFO:Gradient Boosting Classifier Imported successfully
2023-04-20 10:55:18,897:INFO:Starting cross validation
2023-04-20 10:55:18,907:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:55:22,275:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:55:22,288:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:55:22,299:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:55:22,379:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:55:30,786:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:55:30,818:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:55:30,828:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:55:32,023:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:55:32,256:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:55:32,348:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:55:32,358:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:55:42,554:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:55:42,593:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:55:57,698:INFO:Calculating mean and std
2023-04-20 10:55:57,698:INFO:Creating metrics dataframe
2023-04-20 10:56:01,048:INFO:Uploading results into container
2023-04-20 10:56:01,048:INFO:Uploading model into container now
2023-04-20 10:56:01,048:INFO:_master_model_container: 10
2023-04-20 10:56:01,048:INFO:_display_container: 2
2023-04-20 10:56:01,048:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-20 10:56:01,048:INFO:create_model() successfully completed......................................
2023-04-20 10:56:01,198:INFO:SubProcess create_model() end ==================================
2023-04-20 10:56:01,198:INFO:Creating metrics dataframe
2023-04-20 10:56:01,233:INFO:Initializing Linear Discriminant Analysis
2023-04-20 10:56:01,233:INFO:Total runtime is 6.405737034479777 minutes
2023-04-20 10:56:01,242:INFO:SubProcess create_model() called ==================================
2023-04-20 10:56:01,242:INFO:Initializing create_model()
2023-04-20 10:56:01,248:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DBC250F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:56:01,248:INFO:Checking exceptions
2023-04-20 10:56:01,248:INFO:Importing libraries
2023-04-20 10:56:01,248:INFO:Copying training dataset
2023-04-20 10:56:01,280:INFO:Defining folds
2023-04-20 10:56:01,280:INFO:Declaring metric variables
2023-04-20 10:56:01,290:INFO:Importing untrained model
2023-04-20 10:56:01,306:INFO:Linear Discriminant Analysis Imported successfully
2023-04-20 10:56:01,326:INFO:Starting cross validation
2023-04-20 10:56:01,333:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:56:09,313:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:56:09,373:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:56:32,379:INFO:Calculating mean and std
2023-04-20 10:56:32,389:INFO:Creating metrics dataframe
2023-04-20 10:56:35,298:INFO:Uploading results into container
2023-04-20 10:56:35,303:INFO:Uploading model into container now
2023-04-20 10:56:35,303:INFO:_master_model_container: 11
2023-04-20 10:56:35,303:INFO:_display_container: 2
2023-04-20 10:56:35,303:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-20 10:56:35,303:INFO:create_model() successfully completed......................................
2023-04-20 10:56:35,448:INFO:SubProcess create_model() end ==================================
2023-04-20 10:56:35,448:INFO:Creating metrics dataframe
2023-04-20 10:56:35,486:INFO:Initializing Extra Trees Classifier
2023-04-20 10:56:35,486:INFO:Total runtime is 6.976620944341024 minutes
2023-04-20 10:56:35,493:INFO:SubProcess create_model() called ==================================
2023-04-20 10:56:35,494:INFO:Initializing create_model()
2023-04-20 10:56:35,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DBC250F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:56:35,495:INFO:Checking exceptions
2023-04-20 10:56:35,496:INFO:Importing libraries
2023-04-20 10:56:35,496:INFO:Copying training dataset
2023-04-20 10:56:35,508:INFO:Defining folds
2023-04-20 10:56:35,508:INFO:Declaring metric variables
2023-04-20 10:56:35,522:INFO:Importing untrained model
2023-04-20 10:56:35,535:INFO:Extra Trees Classifier Imported successfully
2023-04-20 10:56:35,572:INFO:Starting cross validation
2023-04-20 10:56:35,578:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:56:37,633:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:56:38,783:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:56:38,808:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:56:38,818:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:56:38,948:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:56:47,130:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:56:47,160:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:56:47,212:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:56:47,980:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:56:49,024:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:56:49,046:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:56:49,074:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:56:49,724:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:56:57,323:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 10:56:58,792:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:56:58,893:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:57:16,638:INFO:Calculating mean and std
2023-04-20 10:57:16,638:INFO:Creating metrics dataframe
2023-04-20 10:57:20,869:INFO:Uploading results into container
2023-04-20 10:57:20,871:INFO:Uploading model into container now
2023-04-20 10:57:20,872:INFO:_master_model_container: 12
2023-04-20 10:57:20,872:INFO:_display_container: 2
2023-04-20 10:57:20,874:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-04-20 10:57:20,876:INFO:create_model() successfully completed......................................
2023-04-20 10:57:21,018:INFO:SubProcess create_model() end ==================================
2023-04-20 10:57:21,018:INFO:Creating metrics dataframe
2023-04-20 10:57:21,038:INFO:Initializing Extreme Gradient Boosting
2023-04-20 10:57:21,038:INFO:Total runtime is 7.735822681585947 minutes
2023-04-20 10:57:21,048:INFO:SubProcess create_model() called ==================================
2023-04-20 10:57:21,048:INFO:Initializing create_model()
2023-04-20 10:57:21,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DBC250F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:57:21,048:INFO:Checking exceptions
2023-04-20 10:57:21,048:INFO:Importing libraries
2023-04-20 10:57:21,048:INFO:Copying training dataset
2023-04-20 10:57:21,073:INFO:Defining folds
2023-04-20 10:57:21,073:INFO:Declaring metric variables
2023-04-20 10:57:21,086:INFO:Importing untrained model
2023-04-20 10:57:21,095:INFO:Extreme Gradient Boosting Imported successfully
2023-04-20 10:57:21,113:INFO:Starting cross validation
2023-04-20 10:57:21,122:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:57:32,738:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:57:32,854:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:57:33,012:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:57:33,014:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:57:41,722:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:57:58,673:INFO:Calculating mean and std
2023-04-20 10:57:58,673:INFO:Creating metrics dataframe
2023-04-20 10:58:02,138:INFO:Uploading results into container
2023-04-20 10:58:02,138:INFO:Uploading model into container now
2023-04-20 10:58:02,143:INFO:_master_model_container: 13
2023-04-20 10:58:02,143:INFO:_display_container: 2
2023-04-20 10:58:02,143:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-20 10:58:02,143:INFO:create_model() successfully completed......................................
2023-04-20 10:58:02,318:INFO:SubProcess create_model() end ==================================
2023-04-20 10:58:02,318:INFO:Creating metrics dataframe
2023-04-20 10:58:02,372:INFO:Initializing Light Gradient Boosting Machine
2023-04-20 10:58:02,373:INFO:Total runtime is 8.424743326505025 minutes
2023-04-20 10:58:02,383:INFO:SubProcess create_model() called ==================================
2023-04-20 10:58:02,383:INFO:Initializing create_model()
2023-04-20 10:58:02,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DBC250F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:58:02,384:INFO:Checking exceptions
2023-04-20 10:58:02,385:INFO:Importing libraries
2023-04-20 10:58:02,385:INFO:Copying training dataset
2023-04-20 10:58:02,398:INFO:Defining folds
2023-04-20 10:58:02,398:INFO:Declaring metric variables
2023-04-20 10:58:02,403:INFO:Importing untrained model
2023-04-20 10:58:02,418:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-20 10:58:02,443:INFO:Starting cross validation
2023-04-20 10:58:02,452:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:58:16,283:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:58:16,389:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:58:16,398:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:58:16,406:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:58:40,758:INFO:Calculating mean and std
2023-04-20 10:58:40,764:INFO:Creating metrics dataframe
2023-04-20 10:58:44,934:INFO:Uploading results into container
2023-04-20 10:58:44,934:INFO:Uploading model into container now
2023-04-20 10:58:44,934:INFO:_master_model_container: 14
2023-04-20 10:58:44,938:INFO:_display_container: 2
2023-04-20 10:58:44,938:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-20 10:58:44,938:INFO:create_model() successfully completed......................................
2023-04-20 10:58:45,083:INFO:SubProcess create_model() end ==================================
2023-04-20 10:58:45,083:INFO:Creating metrics dataframe
2023-04-20 10:58:45,108:INFO:Initializing CatBoost Classifier
2023-04-20 10:58:45,108:INFO:Total runtime is 9.136986343065898 minutes
2023-04-20 10:58:45,121:INFO:SubProcess create_model() called ==================================
2023-04-20 10:58:45,125:INFO:Initializing create_model()
2023-04-20 10:58:45,126:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DBC250F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 10:58:45,126:INFO:Checking exceptions
2023-04-20 10:58:45,126:INFO:Importing libraries
2023-04-20 10:58:45,128:INFO:Copying training dataset
2023-04-20 10:58:45,141:INFO:Defining folds
2023-04-20 10:58:45,142:INFO:Declaring metric variables
2023-04-20 10:58:45,152:INFO:Importing untrained model
2023-04-20 10:58:45,165:INFO:CatBoost Classifier Imported successfully
2023-04-20 10:58:45,198:INFO:Starting cross validation
2023-04-20 10:58:45,205:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 10:59:11,226:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:59:15,988:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:59:43,763:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:59:43,803:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:59:46,849:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 10:59:49,782:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:00:15,304:INFO:Calculating mean and std
2023-04-20 11:00:15,308:INFO:Creating metrics dataframe
2023-04-20 11:00:19,318:INFO:Uploading results into container
2023-04-20 11:00:19,323:INFO:Uploading model into container now
2023-04-20 11:00:19,323:INFO:_master_model_container: 15
2023-04-20 11:00:19,323:INFO:_display_container: 2
2023-04-20 11:00:19,323:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DC861390>
2023-04-20 11:00:19,323:INFO:create_model() successfully completed......................................
2023-04-20 11:00:19,488:INFO:SubProcess create_model() end ==================================
2023-04-20 11:00:19,488:INFO:Creating metrics dataframe
2023-04-20 11:00:19,513:INFO:Initializing Dummy Classifier
2023-04-20 11:00:19,513:INFO:Total runtime is 10.710409744580588 minutes
2023-04-20 11:00:19,527:INFO:SubProcess create_model() called ==================================
2023-04-20 11:00:19,528:INFO:Initializing create_model()
2023-04-20 11:00:19,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DBC250F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:00:19,529:INFO:Checking exceptions
2023-04-20 11:00:19,529:INFO:Importing libraries
2023-04-20 11:00:19,530:INFO:Copying training dataset
2023-04-20 11:00:19,542:INFO:Defining folds
2023-04-20 11:00:19,543:INFO:Declaring metric variables
2023-04-20 11:00:19,555:INFO:Importing untrained model
2023-04-20 11:00:19,566:INFO:Dummy Classifier Imported successfully
2023-04-20 11:00:19,596:INFO:Starting cross validation
2023-04-20 11:00:19,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:00:21,181:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:00:21,263:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:00:21,263:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:00:21,273:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:00:28,013:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:00:28,053:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:00:28,102:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:00:28,128:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:00:28,212:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:00:28,235:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:00:28,326:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:00:28,353:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:00:35,591:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:00:35,593:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:00:51,659:INFO:Calculating mean and std
2023-04-20 11:00:51,659:INFO:Creating metrics dataframe
2023-04-20 11:00:54,573:INFO:Uploading results into container
2023-04-20 11:00:54,573:INFO:Uploading model into container now
2023-04-20 11:00:54,573:INFO:_master_model_container: 16
2023-04-20 11:00:54,573:INFO:_display_container: 2
2023-04-20 11:00:54,573:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-04-20 11:00:54,573:INFO:create_model() successfully completed......................................
2023-04-20 11:00:54,723:INFO:SubProcess create_model() end ==================================
2023-04-20 11:00:54,723:INFO:Creating metrics dataframe
2023-04-20 11:00:54,768:INFO:Initializing create_model()
2023-04-20 11:00:54,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DC7BD510>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1DC861390>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:00:54,778:INFO:Checking exceptions
2023-04-20 11:00:54,778:INFO:Importing libraries
2023-04-20 11:00:54,783:INFO:Copying training dataset
2023-04-20 11:00:54,799:INFO:Defining folds
2023-04-20 11:00:54,799:INFO:Declaring metric variables
2023-04-20 11:00:54,800:INFO:Importing untrained model
2023-04-20 11:00:54,800:INFO:Declaring custom model
2023-04-20 11:00:54,801:INFO:CatBoost Classifier Imported successfully
2023-04-20 11:00:54,810:INFO:Cross validation set to False
2023-04-20 11:00:54,811:INFO:Fitting Model
2023-04-20 11:01:06,978:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DC9D34F0>
2023-04-20 11:01:06,978:INFO:create_model() successfully completed......................................
2023-04-20 11:01:07,209:INFO:_master_model_container: 16
2023-04-20 11:01:07,210:INFO:_display_container: 2
2023-04-20 11:01:07,210:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DC9D34F0>
2023-04-20 11:01:07,210:INFO:compare_models() successfully completed......................................
2023-04-20 11:07:58,287:INFO:PyCaret ClassificationExperiment
2023-04-20 11:07:58,288:INFO:Logging name: clf-default-name
2023-04-20 11:07:58,288:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-20 11:07:58,288:INFO:version 3.0.0
2023-04-20 11:07:58,288:INFO:Initializing setup()
2023-04-20 11:07:58,288:INFO:self.USI: 0def
2023-04-20 11:07:58,289:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'memory', 'USI', 'X_train', 'seed', 'log_plots_param', 'gpu_param', 'html_param', 'exp_id', 'gpu_n_jobs_param', 'target_param', 'is_multiclass', 'data', 'y_train', 'y_test', 'X_test', 'y', '_ml_usecase', 'n_jobs_param', 'fix_imbalance', 'fold_groups_param', 'idx', 'exp_name_log', 'fold_generator', 'logging_param', 'X', '_available_plots'}
2023-04-20 11:07:58,289:INFO:Checking environment
2023-04-20 11:07:58,289:INFO:python_version: 3.10.9
2023-04-20 11:07:58,290:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-04-20 11:07:58,290:INFO:machine: AMD64
2023-04-20 11:07:58,290:INFO:platform: Windows-10-10.0.19044-SP0
2023-04-20 11:07:58,290:INFO:Memory: svmem(total=8483184640, available=4155420672, percent=51.0, used=4327763968, free=4155420672)
2023-04-20 11:07:58,290:INFO:Physical Core: 2
2023-04-20 11:07:58,290:INFO:Logical Core: 4
2023-04-20 11:07:58,290:INFO:Checking libraries
2023-04-20 11:07:58,290:INFO:System:
2023-04-20 11:07:58,290:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-04-20 11:07:58,290:INFO:executable: C:\Users\User\.conda\envs\My_envI\python.exe
2023-04-20 11:07:58,290:INFO:   machine: Windows-10-10.0.19044-SP0
2023-04-20 11:07:58,291:INFO:PyCaret required dependencies:
2023-04-20 11:07:58,291:INFO:                 pip: 22.3.1
2023-04-20 11:07:58,291:INFO:          setuptools: 66.0.0
2023-04-20 11:07:58,291:INFO:             pycaret: 3.0.0
2023-04-20 11:07:58,291:INFO:             IPython: 8.12.0
2023-04-20 11:07:58,291:INFO:          ipywidgets: 7.6.5
2023-04-20 11:07:58,291:INFO:                tqdm: 4.64.1
2023-04-20 11:07:58,291:INFO:               numpy: 1.23.5
2023-04-20 11:07:58,291:INFO:              pandas: 1.5.3
2023-04-20 11:07:58,291:INFO:              jinja2: 3.1.2
2023-04-20 11:07:58,292:INFO:               scipy: 1.10.1
2023-04-20 11:07:58,292:INFO:              joblib: 1.2.0
2023-04-20 11:07:58,292:INFO:             sklearn: 1.2.1
2023-04-20 11:07:58,292:INFO:                pyod: 1.0.9
2023-04-20 11:07:58,292:INFO:            imblearn: 0.10.1
2023-04-20 11:07:58,292:INFO:   category_encoders: 2.6.0
2023-04-20 11:07:58,292:INFO:            lightgbm: 3.3.5
2023-04-20 11:07:58,292:INFO:               numba: 0.56.4
2023-04-20 11:07:58,292:INFO:            requests: 2.28.1
2023-04-20 11:07:58,292:INFO:          matplotlib: 3.7.0
2023-04-20 11:07:58,292:INFO:          scikitplot: 0.3.7
2023-04-20 11:07:58,292:INFO:         yellowbrick: 1.5
2023-04-20 11:07:58,292:INFO:              plotly: 5.14.1
2023-04-20 11:07:58,293:INFO:             kaleido: 0.2.1
2023-04-20 11:07:58,293:INFO:         statsmodels: 0.13.5
2023-04-20 11:07:58,293:INFO:              sktime: 0.17.0
2023-04-20 11:07:58,293:INFO:               tbats: 1.1.2
2023-04-20 11:07:58,293:INFO:            pmdarima: 2.0.3
2023-04-20 11:07:58,293:INFO:              psutil: 5.9.0
2023-04-20 11:07:58,293:INFO:PyCaret optional dependencies:
2023-04-20 11:07:58,293:INFO:                shap: 0.41.0
2023-04-20 11:07:58,293:INFO:           interpret: 0.3.2
2023-04-20 11:07:58,293:INFO:                umap: 0.5.3
2023-04-20 11:07:58,293:INFO:    pandas_profiling: 4.1.2
2023-04-20 11:07:58,294:INFO:  explainerdashboard: 0.4.2.1
2023-04-20 11:07:58,294:INFO:             autoviz: 0.1.58
2023-04-20 11:07:58,294:INFO:           fairlearn: 0.7.0
2023-04-20 11:07:58,294:INFO:             xgboost: 1.7.5
2023-04-20 11:07:58,294:INFO:            catboost: 1.1.1
2023-04-20 11:07:58,294:INFO:              kmodes: 0.12.2
2023-04-20 11:07:58,294:INFO:             mlxtend: 0.22.0
2023-04-20 11:07:58,294:INFO:       statsforecast: 1.5.0
2023-04-20 11:07:58,294:INFO:        tune_sklearn: 0.4.5
2023-04-20 11:07:58,294:INFO:                 ray: 2.3.1
2023-04-20 11:07:58,294:INFO:            hyperopt: 0.2.7
2023-04-20 11:07:58,294:INFO:              optuna: 3.1.0
2023-04-20 11:07:58,294:INFO:               skopt: 0.9.0
2023-04-20 11:07:58,294:INFO:              mlflow: 1.30.1
2023-04-20 11:07:58,295:INFO:              gradio: Not installed
2023-04-20 11:07:58,295:INFO:             fastapi: 0.89.1
2023-04-20 11:07:58,295:INFO:             uvicorn: 0.21.1
2023-04-20 11:07:58,295:INFO:              m2cgen: 0.10.0
2023-04-20 11:07:58,295:INFO:           evidently: 0.2.8
2023-04-20 11:07:58,295:INFO:               fugue: 0.8.3
2023-04-20 11:07:58,295:INFO:           streamlit: Not installed
2023-04-20 11:07:58,295:INFO:             prophet: Not installed
2023-04-20 11:07:58,295:INFO:None
2023-04-20 11:07:58,295:INFO:Set up data.
2023-04-20 11:07:58,333:INFO:Set up train/test split.
2023-04-20 11:07:58,338:INFO:Set up index.
2023-04-20 11:07:58,348:INFO:Set up folding strategy.
2023-04-20 11:07:58,348:INFO:Assigning column types.
2023-04-20 11:22:20,333:INFO:PyCaret ClassificationExperiment
2023-04-20 11:22:20,333:INFO:Logging name: clf-default-name
2023-04-20 11:22:20,333:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-20 11:22:20,338:INFO:version 3.0.0
2023-04-20 11:22:20,338:INFO:Initializing setup()
2023-04-20 11:22:20,338:INFO:self.USI: 343b
2023-04-20 11:22:20,338:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'memory', 'USI', 'X_train', 'seed', 'log_plots_param', 'gpu_param', 'html_param', 'exp_id', 'gpu_n_jobs_param', 'target_param', 'is_multiclass', 'data', 'y_train', 'y_test', 'X_test', 'y', '_ml_usecase', 'n_jobs_param', 'fix_imbalance', 'fold_groups_param', 'idx', 'exp_name_log', 'fold_generator', 'logging_param', 'X', '_available_plots'}
2023-04-20 11:22:20,338:INFO:Checking environment
2023-04-20 11:22:20,338:INFO:python_version: 3.10.9
2023-04-20 11:22:20,338:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-04-20 11:22:20,338:INFO:machine: AMD64
2023-04-20 11:22:20,338:INFO:platform: Windows-10-10.0.19044-SP0
2023-04-20 11:22:20,338:INFO:Memory: svmem(total=8483184640, available=4176707584, percent=50.8, used=4306477056, free=4176707584)
2023-04-20 11:22:20,338:INFO:Physical Core: 2
2023-04-20 11:22:20,338:INFO:Logical Core: 4
2023-04-20 11:22:20,338:INFO:Checking libraries
2023-04-20 11:22:20,338:INFO:System:
2023-04-20 11:22:20,338:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-04-20 11:22:20,338:INFO:executable: C:\Users\User\.conda\envs\My_envI\python.exe
2023-04-20 11:22:20,338:INFO:   machine: Windows-10-10.0.19044-SP0
2023-04-20 11:22:20,338:INFO:PyCaret required dependencies:
2023-04-20 11:22:20,338:INFO:                 pip: 22.3.1
2023-04-20 11:22:20,338:INFO:          setuptools: 66.0.0
2023-04-20 11:22:20,338:INFO:             pycaret: 3.0.0
2023-04-20 11:22:20,338:INFO:             IPython: 8.12.0
2023-04-20 11:22:20,338:INFO:          ipywidgets: 7.6.5
2023-04-20 11:22:20,338:INFO:                tqdm: 4.64.1
2023-04-20 11:22:20,338:INFO:               numpy: 1.23.5
2023-04-20 11:22:20,338:INFO:              pandas: 1.5.3
2023-04-20 11:22:20,338:INFO:              jinja2: 3.1.2
2023-04-20 11:22:20,338:INFO:               scipy: 1.10.1
2023-04-20 11:22:20,338:INFO:              joblib: 1.2.0
2023-04-20 11:22:20,338:INFO:             sklearn: 1.2.1
2023-04-20 11:22:20,338:INFO:                pyod: 1.0.9
2023-04-20 11:22:20,343:INFO:            imblearn: 0.10.1
2023-04-20 11:22:20,343:INFO:   category_encoders: 2.6.0
2023-04-20 11:22:20,343:INFO:            lightgbm: 3.3.5
2023-04-20 11:22:20,343:INFO:               numba: 0.56.4
2023-04-20 11:22:20,343:INFO:            requests: 2.28.1
2023-04-20 11:22:20,343:INFO:          matplotlib: 3.7.0
2023-04-20 11:22:20,343:INFO:          scikitplot: 0.3.7
2023-04-20 11:22:20,343:INFO:         yellowbrick: 1.5
2023-04-20 11:22:20,343:INFO:              plotly: 5.14.1
2023-04-20 11:22:20,343:INFO:             kaleido: 0.2.1
2023-04-20 11:22:20,343:INFO:         statsmodels: 0.13.5
2023-04-20 11:22:20,343:INFO:              sktime: 0.17.0
2023-04-20 11:22:20,343:INFO:               tbats: 1.1.2
2023-04-20 11:22:20,343:INFO:            pmdarima: 2.0.3
2023-04-20 11:22:20,343:INFO:              psutil: 5.9.0
2023-04-20 11:22:20,343:INFO:PyCaret optional dependencies:
2023-04-20 11:22:20,343:INFO:                shap: 0.41.0
2023-04-20 11:22:20,343:INFO:           interpret: 0.3.2
2023-04-20 11:22:20,343:INFO:                umap: 0.5.3
2023-04-20 11:22:20,343:INFO:    pandas_profiling: 4.1.2
2023-04-20 11:22:20,343:INFO:  explainerdashboard: 0.4.2.1
2023-04-20 11:22:20,343:INFO:             autoviz: 0.1.58
2023-04-20 11:22:20,343:INFO:           fairlearn: 0.7.0
2023-04-20 11:22:20,343:INFO:             xgboost: 1.7.5
2023-04-20 11:22:20,343:INFO:            catboost: 1.1.1
2023-04-20 11:22:20,343:INFO:              kmodes: 0.12.2
2023-04-20 11:22:20,343:INFO:             mlxtend: 0.22.0
2023-04-20 11:22:20,343:INFO:       statsforecast: 1.5.0
2023-04-20 11:22:20,343:INFO:        tune_sklearn: 0.4.5
2023-04-20 11:22:20,343:INFO:                 ray: 2.3.1
2023-04-20 11:22:20,343:INFO:            hyperopt: 0.2.7
2023-04-20 11:22:20,343:INFO:              optuna: 3.1.0
2023-04-20 11:22:20,343:INFO:               skopt: 0.9.0
2023-04-20 11:22:20,343:INFO:              mlflow: 1.30.1
2023-04-20 11:22:20,343:INFO:              gradio: Not installed
2023-04-20 11:22:20,343:INFO:             fastapi: 0.89.1
2023-04-20 11:22:20,343:INFO:             uvicorn: 0.21.1
2023-04-20 11:22:20,343:INFO:              m2cgen: 0.10.0
2023-04-20 11:22:20,343:INFO:           evidently: 0.2.8
2023-04-20 11:22:20,343:INFO:               fugue: 0.8.3
2023-04-20 11:22:20,343:INFO:           streamlit: Not installed
2023-04-20 11:22:20,343:INFO:             prophet: Not installed
2023-04-20 11:22:20,343:INFO:None
2023-04-20 11:22:20,343:INFO:Set up data.
2023-04-20 11:22:20,372:INFO:Set up train/test split.
2023-04-20 11:22:20,388:INFO:Set up index.
2023-04-20 11:22:20,388:INFO:Set up folding strategy.
2023-04-20 11:22:20,388:INFO:Assigning column types.
2023-04-20 11:24:20,602:INFO:PyCaret ClassificationExperiment
2023-04-20 11:24:20,602:INFO:Logging name: clf-default-name
2023-04-20 11:24:20,602:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-20 11:24:20,602:INFO:version 3.0.0
2023-04-20 11:24:20,602:INFO:Initializing setup()
2023-04-20 11:24:20,602:INFO:self.USI: 9770
2023-04-20 11:24:20,602:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'memory', 'USI', 'X_train', 'seed', 'log_plots_param', 'gpu_param', 'html_param', 'exp_id', 'gpu_n_jobs_param', 'target_param', 'is_multiclass', 'data', 'y_train', 'y_test', 'X_test', 'y', '_ml_usecase', 'n_jobs_param', 'fix_imbalance', 'fold_groups_param', 'idx', 'exp_name_log', 'fold_generator', 'logging_param', 'X', '_available_plots'}
2023-04-20 11:24:20,602:INFO:Checking environment
2023-04-20 11:24:20,602:INFO:python_version: 3.10.9
2023-04-20 11:24:20,602:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-04-20 11:24:20,602:INFO:machine: AMD64
2023-04-20 11:24:20,602:INFO:platform: Windows-10-10.0.19044-SP0
2023-04-20 11:24:20,602:INFO:Memory: svmem(total=8483184640, available=4266885120, percent=49.7, used=4216299520, free=4266885120)
2023-04-20 11:24:20,602:INFO:Physical Core: 2
2023-04-20 11:24:20,602:INFO:Logical Core: 4
2023-04-20 11:24:20,602:INFO:Checking libraries
2023-04-20 11:24:20,602:INFO:System:
2023-04-20 11:24:20,602:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-04-20 11:24:20,602:INFO:executable: C:\Users\User\.conda\envs\My_envI\python.exe
2023-04-20 11:24:20,602:INFO:   machine: Windows-10-10.0.19044-SP0
2023-04-20 11:24:20,602:INFO:PyCaret required dependencies:
2023-04-20 11:24:20,602:INFO:                 pip: 22.3.1
2023-04-20 11:24:20,602:INFO:          setuptools: 66.0.0
2023-04-20 11:24:20,602:INFO:             pycaret: 3.0.0
2023-04-20 11:24:20,602:INFO:             IPython: 8.12.0
2023-04-20 11:24:20,602:INFO:          ipywidgets: 7.6.5
2023-04-20 11:24:20,602:INFO:                tqdm: 4.64.1
2023-04-20 11:24:20,602:INFO:               numpy: 1.23.5
2023-04-20 11:24:20,602:INFO:              pandas: 1.5.3
2023-04-20 11:24:20,602:INFO:              jinja2: 3.1.2
2023-04-20 11:24:20,602:INFO:               scipy: 1.10.1
2023-04-20 11:24:20,602:INFO:              joblib: 1.2.0
2023-04-20 11:24:20,602:INFO:             sklearn: 1.2.1
2023-04-20 11:24:20,602:INFO:                pyod: 1.0.9
2023-04-20 11:24:20,602:INFO:            imblearn: 0.10.1
2023-04-20 11:24:20,602:INFO:   category_encoders: 2.6.0
2023-04-20 11:24:20,602:INFO:            lightgbm: 3.3.5
2023-04-20 11:24:20,602:INFO:               numba: 0.56.4
2023-04-20 11:24:20,602:INFO:            requests: 2.28.1
2023-04-20 11:24:20,602:INFO:          matplotlib: 3.7.0
2023-04-20 11:24:20,602:INFO:          scikitplot: 0.3.7
2023-04-20 11:24:20,602:INFO:         yellowbrick: 1.5
2023-04-20 11:24:20,602:INFO:              plotly: 5.14.1
2023-04-20 11:24:20,602:INFO:             kaleido: 0.2.1
2023-04-20 11:24:20,608:INFO:         statsmodels: 0.13.5
2023-04-20 11:24:20,608:INFO:              sktime: 0.17.0
2023-04-20 11:24:20,608:INFO:               tbats: 1.1.2
2023-04-20 11:24:20,608:INFO:            pmdarima: 2.0.3
2023-04-20 11:24:20,608:INFO:              psutil: 5.9.0
2023-04-20 11:24:20,608:INFO:PyCaret optional dependencies:
2023-04-20 11:24:20,608:INFO:                shap: 0.41.0
2023-04-20 11:24:20,608:INFO:           interpret: 0.3.2
2023-04-20 11:24:20,608:INFO:                umap: 0.5.3
2023-04-20 11:24:20,608:INFO:    pandas_profiling: 4.1.2
2023-04-20 11:24:20,608:INFO:  explainerdashboard: 0.4.2.1
2023-04-20 11:24:20,608:INFO:             autoviz: 0.1.58
2023-04-20 11:24:20,608:INFO:           fairlearn: 0.7.0
2023-04-20 11:24:20,608:INFO:             xgboost: 1.7.5
2023-04-20 11:24:20,608:INFO:            catboost: 1.1.1
2023-04-20 11:24:20,608:INFO:              kmodes: 0.12.2
2023-04-20 11:24:20,608:INFO:             mlxtend: 0.22.0
2023-04-20 11:24:20,608:INFO:       statsforecast: 1.5.0
2023-04-20 11:24:20,608:INFO:        tune_sklearn: 0.4.5
2023-04-20 11:24:20,608:INFO:                 ray: 2.3.1
2023-04-20 11:24:20,608:INFO:            hyperopt: 0.2.7
2023-04-20 11:24:20,608:INFO:              optuna: 3.1.0
2023-04-20 11:24:20,608:INFO:               skopt: 0.9.0
2023-04-20 11:24:20,608:INFO:              mlflow: 1.30.1
2023-04-20 11:24:20,612:INFO:              gradio: Not installed
2023-04-20 11:24:20,612:INFO:             fastapi: 0.89.1
2023-04-20 11:24:20,612:INFO:             uvicorn: 0.21.1
2023-04-20 11:24:20,612:INFO:              m2cgen: 0.10.0
2023-04-20 11:24:20,612:INFO:           evidently: 0.2.8
2023-04-20 11:24:20,612:INFO:               fugue: 0.8.3
2023-04-20 11:24:20,612:INFO:           streamlit: Not installed
2023-04-20 11:24:20,612:INFO:             prophet: Not installed
2023-04-20 11:24:20,612:INFO:None
2023-04-20 11:24:20,612:INFO:Set up data.
2023-04-20 11:24:20,638:INFO:Set up train/test split.
2023-04-20 11:24:20,655:INFO:Set up index.
2023-04-20 11:24:20,655:INFO:Set up folding strategy.
2023-04-20 11:24:20,655:INFO:Assigning column types.
2023-04-20 11:26:57,100:INFO:PyCaret ClassificationExperiment
2023-04-20 11:26:57,100:INFO:Logging name: clf-default-name
2023-04-20 11:26:57,100:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-20 11:26:57,100:INFO:version 3.0.0
2023-04-20 11:26:57,100:INFO:Initializing setup()
2023-04-20 11:26:57,100:INFO:self.USI: 2267
2023-04-20 11:26:57,100:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'memory', 'USI', 'X_train', 'seed', 'log_plots_param', 'gpu_param', 'html_param', 'exp_id', 'gpu_n_jobs_param', 'target_param', 'is_multiclass', 'data', 'y_train', 'y_test', 'X_test', 'y', '_ml_usecase', 'n_jobs_param', 'fix_imbalance', 'fold_groups_param', 'idx', 'exp_name_log', 'fold_generator', 'logging_param', 'X', '_available_plots'}
2023-04-20 11:26:57,100:INFO:Checking environment
2023-04-20 11:26:57,100:INFO:python_version: 3.10.9
2023-04-20 11:26:57,108:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-04-20 11:26:57,108:INFO:machine: AMD64
2023-04-20 11:26:57,108:INFO:platform: Windows-10-10.0.19044-SP0
2023-04-20 11:26:57,108:INFO:Memory: svmem(total=8483184640, available=4264226816, percent=49.7, used=4218957824, free=4264226816)
2023-04-20 11:26:57,108:INFO:Physical Core: 2
2023-04-20 11:26:57,108:INFO:Logical Core: 4
2023-04-20 11:26:57,108:INFO:Checking libraries
2023-04-20 11:26:57,108:INFO:System:
2023-04-20 11:26:57,108:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-04-20 11:26:57,108:INFO:executable: C:\Users\User\.conda\envs\My_envI\python.exe
2023-04-20 11:26:57,108:INFO:   machine: Windows-10-10.0.19044-SP0
2023-04-20 11:26:57,108:INFO:PyCaret required dependencies:
2023-04-20 11:26:57,108:INFO:                 pip: 22.3.1
2023-04-20 11:26:57,108:INFO:          setuptools: 66.0.0
2023-04-20 11:26:57,108:INFO:             pycaret: 3.0.0
2023-04-20 11:26:57,108:INFO:             IPython: 8.12.0
2023-04-20 11:26:57,108:INFO:          ipywidgets: 7.6.5
2023-04-20 11:26:57,108:INFO:                tqdm: 4.64.1
2023-04-20 11:26:57,108:INFO:               numpy: 1.23.5
2023-04-20 11:26:57,108:INFO:              pandas: 1.5.3
2023-04-20 11:26:57,108:INFO:              jinja2: 3.1.2
2023-04-20 11:26:57,108:INFO:               scipy: 1.10.1
2023-04-20 11:26:57,108:INFO:              joblib: 1.2.0
2023-04-20 11:26:57,108:INFO:             sklearn: 1.2.1
2023-04-20 11:26:57,108:INFO:                pyod: 1.0.9
2023-04-20 11:26:57,108:INFO:            imblearn: 0.10.1
2023-04-20 11:26:57,108:INFO:   category_encoders: 2.6.0
2023-04-20 11:26:57,108:INFO:            lightgbm: 3.3.5
2023-04-20 11:26:57,108:INFO:               numba: 0.56.4
2023-04-20 11:26:57,108:INFO:            requests: 2.28.1
2023-04-20 11:26:57,108:INFO:          matplotlib: 3.7.0
2023-04-20 11:26:57,108:INFO:          scikitplot: 0.3.7
2023-04-20 11:26:57,108:INFO:         yellowbrick: 1.5
2023-04-20 11:26:57,108:INFO:              plotly: 5.14.1
2023-04-20 11:26:57,108:INFO:             kaleido: 0.2.1
2023-04-20 11:26:57,108:INFO:         statsmodels: 0.13.5
2023-04-20 11:26:57,108:INFO:              sktime: 0.17.0
2023-04-20 11:26:57,108:INFO:               tbats: 1.1.2
2023-04-20 11:26:57,108:INFO:            pmdarima: 2.0.3
2023-04-20 11:26:57,108:INFO:              psutil: 5.9.0
2023-04-20 11:26:57,108:INFO:PyCaret optional dependencies:
2023-04-20 11:26:57,108:INFO:                shap: 0.41.0
2023-04-20 11:26:57,108:INFO:           interpret: 0.3.2
2023-04-20 11:26:57,108:INFO:                umap: 0.5.3
2023-04-20 11:26:57,108:INFO:    pandas_profiling: 4.1.2
2023-04-20 11:26:57,108:INFO:  explainerdashboard: 0.4.2.1
2023-04-20 11:26:57,108:INFO:             autoviz: 0.1.58
2023-04-20 11:26:57,108:INFO:           fairlearn: 0.7.0
2023-04-20 11:26:57,108:INFO:             xgboost: 1.7.5
2023-04-20 11:26:57,108:INFO:            catboost: 1.1.1
2023-04-20 11:26:57,108:INFO:              kmodes: 0.12.2
2023-04-20 11:26:57,108:INFO:             mlxtend: 0.22.0
2023-04-20 11:26:57,108:INFO:       statsforecast: 1.5.0
2023-04-20 11:26:57,108:INFO:        tune_sklearn: 0.4.5
2023-04-20 11:26:57,108:INFO:                 ray: 2.3.1
2023-04-20 11:26:57,108:INFO:            hyperopt: 0.2.7
2023-04-20 11:26:57,108:INFO:              optuna: 3.1.0
2023-04-20 11:26:57,118:INFO:               skopt: 0.9.0
2023-04-20 11:26:57,118:INFO:              mlflow: 1.30.1
2023-04-20 11:26:57,118:INFO:              gradio: Not installed
2023-04-20 11:26:57,118:INFO:             fastapi: 0.89.1
2023-04-20 11:26:57,118:INFO:             uvicorn: 0.21.1
2023-04-20 11:26:57,118:INFO:              m2cgen: 0.10.0
2023-04-20 11:26:57,118:INFO:           evidently: 0.2.8
2023-04-20 11:26:57,118:INFO:               fugue: 0.8.3
2023-04-20 11:26:57,118:INFO:           streamlit: Not installed
2023-04-20 11:26:57,118:INFO:             prophet: Not installed
2023-04-20 11:26:57,118:INFO:None
2023-04-20 11:26:57,118:INFO:Set up data.
2023-04-20 11:26:57,138:INFO:Set up train/test split.
2023-04-20 11:26:57,148:INFO:Set up index.
2023-04-20 11:26:57,148:INFO:Set up folding strategy.
2023-04-20 11:26:57,148:INFO:Assigning column types.
2023-04-20 11:26:57,163:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-20 11:26:57,248:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-20 11:26:57,248:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 11:26:57,301:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:26:57,308:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:26:57,393:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-20 11:26:57,398:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 11:26:57,438:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:26:57,448:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:26:57,448:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-20 11:26:57,528:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 11:26:57,588:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:26:57,588:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:26:57,678:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 11:26:57,728:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:26:57,728:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:26:57,728:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-20 11:26:57,868:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:26:57,868:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:26:58,038:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:26:58,048:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:26:58,053:INFO:Preparing preprocessing pipeline...
2023-04-20 11:26:58,053:INFO:Set up label encoding.
2023-04-20 11:26:58,053:INFO:Set up simple imputation.
2023-04-20 11:26:58,063:INFO:Set up encoding of ordinal features.
2023-04-20 11:26:58,068:INFO:Set up encoding of categorical features.
2023-04-20 11:26:58,068:INFO:Set up imbalanced handling.
2023-04-20 11:26:58,338:INFO:Finished creating preprocessing pipeline.
2023-04-20 11:26:58,408:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                                    'other_payment_plans',
                                                                    'housing',
                                                                    'job',
                                                                    'marital_status'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2023-04-20 11:26:58,408:INFO:Creating final display dataframe.
2023-04-20 11:26:59,263:INFO:Setup _display_container:                     Description                      Value
0                    Session id                        123
1                        Target                      class
2                   Target type                     Binary
3                Target mapping  Aprovado: 0, Reprovado: 1
4           Original data shape                  (950, 22)
5        Transformed data shape                 (1217, 50)
6   Transformed train set shape                  (932, 50)
7    Transformed test set shape                  (285, 50)
8              Ordinal features                          3
9              Numeric features                         10
10         Categorical features                         11
11                   Preprocess                       True
12              Imputation type                     simple
13           Numeric imputation                       mean
14       Categorical imputation                       mode
15     Maximum one-hot encoding                         25
16              Encoding method                       None
17                Fix imbalance                       True
18         Fix imbalance method                      SMOTE
19               Fold Generator            StratifiedKFold
20                  Fold Number                         10
21                     CPU Jobs                         -1
22                      Use GPU                      False
23               Log Experiment                      False
24              Experiment Name           clf-default-name
25                          USI                       2267
2023-04-20 11:26:59,453:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:26:59,458:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:26:59,588:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:26:59,593:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:26:59,593:INFO:setup() successfully completed in 4.36s...............
2023-04-20 11:27:28,493:INFO:Initializing get_config()
2023-04-20 11:27:28,493:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, variable=X_transformed)
2023-04-20 11:27:28,688:INFO:Variable: X returned as      checking_status  duration  credit_history_existing paid  \
266              1.0      24.0                           1.0   
400              2.0       9.0                           1.0   
395              1.0       6.0                           0.0   
553              0.0      30.0                           0.0   
560              1.0      12.0                           1.0   
..               ...       ...                           ...   
290              1.0      24.0                           0.0   
770              0.0      15.0                           1.0   
257              2.0       9.0                           1.0   
878              2.0      18.0                           0.0   
278              2.0      16.0                           0.0   

     credit_history_critical/other existing credit  \
266                                            0.0   
400                                            0.0   
395                                            1.0   
553                                            0.0   
560                                            0.0   
..                                             ...   
290                                            1.0   
770                                            0.0   
257                                            0.0   
878                                            0.0   
278                                            1.0   

     credit_history_delayed previously  credit_history_no credits/all paid  \
266                                0.0                                 0.0   
400                                0.0                                 0.0   
395                                0.0                                 0.0   
553                                1.0                                 0.0   
560                                0.0                                 0.0   
..                                 ...                                 ...   
290                                0.0                                 0.0   
770                                0.0                                 0.0   
257                                0.0                                 0.0   
878                                1.0                                 0.0   
278                                0.0                                 0.0   

     credit_history_all paid  purpose_new car  purpose_radio/tv  \
266                      0.0              1.0               0.0   
400                      0.0              1.0               0.0   
395                      0.0              0.0               1.0   
553                      0.0              0.0               0.0   
560                      0.0              1.0               0.0   
..                       ...              ...               ...   
290                      0.0              0.0               0.0   
770                      0.0              0.0               1.0   
257                      0.0              0.0               0.0   
878                      0.0              1.0               0.0   
278                      0.0              1.0               0.0   

     purpose_business  ...  job_high qualif/self emp/mgmt  \
266               0.0  ...                            0.0   
400               0.0  ...                            0.0   
395               0.0  ...                            0.0   
553               1.0  ...                            0.0   
560               0.0  ...                            0.0   
..                ...  ...                            ...   
290               0.0  ...                            1.0   
770               0.0  ...                            0.0   
257               0.0  ...                            1.0   
878               0.0  ...                            0.0   
278               0.0  ...                            0.0   

     job_unemp/unskilled non res  num_dependents  own_telephone  \
266                          0.0             1.0            0.0   
400                          0.0             1.0            0.0   
395                          0.0             1.0            0.0   
553                          0.0             1.0            0.0   
560                          0.0             1.0            0.0   
..                           ...             ...            ...   
290                          0.0             2.0            1.0   
770                          0.0             1.0            0.0   
257                          0.0             1.0            1.0   
878                          0.0             2.0            0.0   
278                          1.0             1.0            1.0   

     foreign_worker  sex  marital_status_div/dep/mar  marital_status_single  \
266             1.0  0.0                         1.0                    0.0   
400             1.0  0.0                         1.0                    0.0   
395             1.0  0.0                         1.0                    0.0   
553             1.0  1.0                         0.0                    1.0   
560             1.0  0.0                         1.0                    0.0   
..              ...  ...                         ...                    ...   
290             1.0  0.0                         1.0                    0.0   
770             1.0  1.0                         0.0                    1.0   
257             1.0  0.0                         1.0                    0.0   
878             1.0  1.0                         0.0                    1.0   
278             1.0  1.0                         0.0                    1.0   

     marital_status_mar/wid  marital_status_div/sep  
266                     0.0                     0.0  
400                     0.0                     0.0  
395                     0.0                     0.0  
553                     0.0                     0.0  
560                     0.0                     0.0  
..                      ...                     ...  
290                     0.0                     0.0  
770                     0.0                     0.0  
257                     0.0                     0.0  
878                     0.0                     0.0  
278                     0.0                     0.0  

[1217 rows x 49 columns]
2023-04-20 11:27:28,688:INFO:get_config() successfully completed......................................
2023-04-20 11:27:38,857:INFO:Initializing compare_models()
2023-04-20 11:27:38,857:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-20 11:27:38,858:INFO:Checking exceptions
2023-04-20 11:27:38,870:INFO:Preparing display monitor
2023-04-20 11:27:38,959:INFO:Initializing Logistic Regression
2023-04-20 11:27:38,959:INFO:Total runtime is 0.0 minutes
2023-04-20 11:27:38,982:INFO:SubProcess create_model() called ==================================
2023-04-20 11:27:38,983:INFO:Initializing create_model()
2023-04-20 11:27:38,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DFFAF9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:27:38,985:INFO:Checking exceptions
2023-04-20 11:27:38,986:INFO:Importing libraries
2023-04-20 11:27:38,986:INFO:Copying training dataset
2023-04-20 11:27:39,009:INFO:Defining folds
2023-04-20 11:27:39,010:INFO:Declaring metric variables
2023-04-20 11:27:39,029:INFO:Importing untrained model
2023-04-20 11:27:39,041:INFO:Logistic Regression Imported successfully
2023-04-20 11:27:39,068:INFO:Starting cross validation
2023-04-20 11:27:39,078:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:27:56,428:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:28:03,369:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:28:25,156:INFO:Calculating mean and std
2023-04-20 11:28:25,156:INFO:Creating metrics dataframe
2023-04-20 11:28:29,261:INFO:Uploading results into container
2023-04-20 11:28:29,261:INFO:Uploading model into container now
2023-04-20 11:28:29,261:INFO:_master_model_container: 1
2023-04-20 11:28:29,261:INFO:_display_container: 2
2023-04-20 11:28:29,261:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-20 11:28:29,261:INFO:create_model() successfully completed......................................
2023-04-20 11:28:33,648:INFO:SubProcess create_model() end ==================================
2023-04-20 11:28:33,648:INFO:Creating metrics dataframe
2023-04-20 11:28:33,648:INFO:Initializing K Neighbors Classifier
2023-04-20 11:28:33,648:INFO:Total runtime is 0.9114720384279887 minutes
2023-04-20 11:28:33,663:INFO:SubProcess create_model() called ==================================
2023-04-20 11:28:33,669:INFO:Initializing create_model()
2023-04-20 11:28:33,670:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DFFAF9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:28:33,670:INFO:Checking exceptions
2023-04-20 11:28:33,670:INFO:Importing libraries
2023-04-20 11:28:33,670:INFO:Copying training dataset
2023-04-20 11:28:33,683:INFO:Defining folds
2023-04-20 11:28:33,683:INFO:Declaring metric variables
2023-04-20 11:28:33,692:INFO:Importing untrained model
2023-04-20 11:28:33,707:INFO:K Neighbors Classifier Imported successfully
2023-04-20 11:28:33,724:INFO:Starting cross validation
2023-04-20 11:28:33,739:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:28:41,375:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:29:03,089:INFO:Calculating mean and std
2023-04-20 11:29:03,091:INFO:Creating metrics dataframe
2023-04-20 11:29:06,298:INFO:Uploading results into container
2023-04-20 11:29:06,298:INFO:Uploading model into container now
2023-04-20 11:29:06,298:INFO:_master_model_container: 2
2023-04-20 11:29:06,298:INFO:_display_container: 2
2023-04-20 11:29:06,298:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-20 11:29:06,298:INFO:create_model() successfully completed......................................
2023-04-20 11:29:06,474:INFO:SubProcess create_model() end ==================================
2023-04-20 11:29:06,474:INFO:Creating metrics dataframe
2023-04-20 11:29:06,497:INFO:Initializing Naive Bayes
2023-04-20 11:29:06,497:INFO:Total runtime is 1.4589608112970989 minutes
2023-04-20 11:29:06,497:INFO:SubProcess create_model() called ==================================
2023-04-20 11:29:06,497:INFO:Initializing create_model()
2023-04-20 11:29:06,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DFFAF9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:29:06,497:INFO:Checking exceptions
2023-04-20 11:29:06,497:INFO:Importing libraries
2023-04-20 11:29:06,497:INFO:Copying training dataset
2023-04-20 11:29:06,513:INFO:Defining folds
2023-04-20 11:29:06,513:INFO:Declaring metric variables
2023-04-20 11:29:06,535:INFO:Importing untrained model
2023-04-20 11:29:06,557:INFO:Naive Bayes Imported successfully
2023-04-20 11:29:06,582:INFO:Starting cross validation
2023-04-20 11:29:06,588:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:29:13,918:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:29:35,243:INFO:Calculating mean and std
2023-04-20 11:29:35,243:INFO:Creating metrics dataframe
2023-04-20 11:29:38,263:INFO:Uploading results into container
2023-04-20 11:29:38,263:INFO:Uploading model into container now
2023-04-20 11:29:38,263:INFO:_master_model_container: 3
2023-04-20 11:29:38,263:INFO:_display_container: 2
2023-04-20 11:29:38,263:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-20 11:29:38,263:INFO:create_model() successfully completed......................................
2023-04-20 11:29:38,435:INFO:SubProcess create_model() end ==================================
2023-04-20 11:29:38,435:INFO:Creating metrics dataframe
2023-04-20 11:29:38,471:INFO:Initializing Decision Tree Classifier
2023-04-20 11:29:38,471:INFO:Total runtime is 1.9918625116348267 minutes
2023-04-20 11:29:38,479:INFO:SubProcess create_model() called ==================================
2023-04-20 11:29:38,480:INFO:Initializing create_model()
2023-04-20 11:29:38,480:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DFFAF9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:29:38,481:INFO:Checking exceptions
2023-04-20 11:29:38,481:INFO:Importing libraries
2023-04-20 11:29:38,482:INFO:Copying training dataset
2023-04-20 11:29:38,500:INFO:Defining folds
2023-04-20 11:29:38,501:INFO:Declaring metric variables
2023-04-20 11:29:38,512:INFO:Importing untrained model
2023-04-20 11:29:38,526:INFO:Decision Tree Classifier Imported successfully
2023-04-20 11:29:38,560:INFO:Starting cross validation
2023-04-20 11:29:38,560:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:30:07,375:INFO:Calculating mean and std
2023-04-20 11:30:07,375:INFO:Creating metrics dataframe
2023-04-20 11:30:10,404:INFO:Uploading results into container
2023-04-20 11:30:10,404:INFO:Uploading model into container now
2023-04-20 11:30:10,404:INFO:_master_model_container: 4
2023-04-20 11:30:10,404:INFO:_display_container: 2
2023-04-20 11:30:10,404:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-04-20 11:30:10,411:INFO:create_model() successfully completed......................................
2023-04-20 11:30:10,581:INFO:SubProcess create_model() end ==================================
2023-04-20 11:30:10,581:INFO:Creating metrics dataframe
2023-04-20 11:30:10,596:INFO:Initializing SVM - Linear Kernel
2023-04-20 11:30:10,596:INFO:Total runtime is 2.5272830724716187 minutes
2023-04-20 11:30:10,596:INFO:SubProcess create_model() called ==================================
2023-04-20 11:30:10,612:INFO:Initializing create_model()
2023-04-20 11:30:10,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DFFAF9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:30:10,612:INFO:Checking exceptions
2023-04-20 11:30:10,612:INFO:Importing libraries
2023-04-20 11:30:10,612:INFO:Copying training dataset
2023-04-20 11:30:10,628:INFO:Defining folds
2023-04-20 11:30:10,629:INFO:Declaring metric variables
2023-04-20 11:30:10,640:INFO:Importing untrained model
2023-04-20 11:30:10,652:INFO:SVM - Linear Kernel Imported successfully
2023-04-20 11:30:10,678:INFO:Starting cross validation
2023-04-20 11:30:10,688:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:30:11,889:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:30:11,951:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:30:11,951:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:30:11,967:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:30:11,967:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:30:11,983:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:30:17,688:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:30:17,750:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:30:17,766:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:30:17,922:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:30:17,922:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:30:17,938:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:30:17,954:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:30:24,086:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:30:24,414:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:30:24,430:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:30:39,447:INFO:Calculating mean and std
2023-04-20 11:30:39,447:INFO:Creating metrics dataframe
2023-04-20 11:30:42,509:INFO:Uploading results into container
2023-04-20 11:30:42,509:INFO:Uploading model into container now
2023-04-20 11:30:42,509:INFO:_master_model_container: 5
2023-04-20 11:30:42,509:INFO:_display_container: 2
2023-04-20 11:30:42,509:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-20 11:30:42,520:INFO:create_model() successfully completed......................................
2023-04-20 11:30:42,690:INFO:SubProcess create_model() end ==================================
2023-04-20 11:30:42,690:INFO:Creating metrics dataframe
2023-04-20 11:30:42,706:INFO:Initializing Ridge Classifier
2023-04-20 11:30:42,706:INFO:Total runtime is 3.0624383052190147 minutes
2023-04-20 11:30:42,724:INFO:SubProcess create_model() called ==================================
2023-04-20 11:30:42,725:INFO:Initializing create_model()
2023-04-20 11:30:42,725:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DFFAF9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:30:42,726:INFO:Checking exceptions
2023-04-20 11:30:42,726:INFO:Importing libraries
2023-04-20 11:30:42,726:INFO:Copying training dataset
2023-04-20 11:30:42,743:INFO:Defining folds
2023-04-20 11:30:42,743:INFO:Declaring metric variables
2023-04-20 11:30:42,753:INFO:Importing untrained model
2023-04-20 11:30:42,775:INFO:Ridge Classifier Imported successfully
2023-04-20 11:30:42,806:INFO:Starting cross validation
2023-04-20 11:30:42,813:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:30:44,018:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:30:44,034:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:30:44,034:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:30:44,034:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:30:49,856:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:30:49,934:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:30:49,996:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:30:50,012:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:30:50,314:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:30:56,425:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:30:56,690:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:31:11,848:INFO:Calculating mean and std
2023-04-20 11:31:11,848:INFO:Creating metrics dataframe
2023-04-20 11:31:14,843:INFO:Uploading results into container
2023-04-20 11:31:14,858:INFO:Uploading model into container now
2023-04-20 11:31:14,858:INFO:_master_model_container: 6
2023-04-20 11:31:14,858:INFO:_display_container: 2
2023-04-20 11:31:14,858:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-04-20 11:31:14,858:INFO:create_model() successfully completed......................................
2023-04-20 11:31:15,037:INFO:SubProcess create_model() end ==================================
2023-04-20 11:31:15,037:INFO:Creating metrics dataframe
2023-04-20 11:31:15,059:INFO:Initializing Random Forest Classifier
2023-04-20 11:31:15,059:INFO:Total runtime is 3.6016589601834617 minutes
2023-04-20 11:31:15,070:INFO:SubProcess create_model() called ==================================
2023-04-20 11:31:15,071:INFO:Initializing create_model()
2023-04-20 11:31:15,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DFFAF9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:31:15,072:INFO:Checking exceptions
2023-04-20 11:31:15,073:INFO:Importing libraries
2023-04-20 11:31:15,073:INFO:Copying training dataset
2023-04-20 11:31:15,086:INFO:Defining folds
2023-04-20 11:31:15,086:INFO:Declaring metric variables
2023-04-20 11:31:15,096:INFO:Importing untrained model
2023-04-20 11:31:15,108:INFO:Random Forest Classifier Imported successfully
2023-04-20 11:31:15,135:INFO:Starting cross validation
2023-04-20 11:31:15,145:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:31:18,028:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:31:18,088:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:31:18,103:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:31:18,275:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:31:25,377:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:31:25,674:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:31:26,704:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:31:26,939:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:31:27,172:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:31:27,216:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:31:28,452:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:31:36,075:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:31:36,192:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:31:50,567:INFO:Calculating mean and std
2023-04-20 11:31:50,567:INFO:Creating metrics dataframe
2023-04-20 11:31:53,517:INFO:Uploading results into container
2023-04-20 11:31:53,517:INFO:Uploading model into container now
2023-04-20 11:31:53,517:INFO:_master_model_container: 7
2023-04-20 11:31:53,517:INFO:_display_container: 2
2023-04-20 11:31:53,517:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-20 11:31:53,517:INFO:create_model() successfully completed......................................
2023-04-20 11:31:53,721:INFO:SubProcess create_model() end ==================================
2023-04-20 11:31:53,721:INFO:Creating metrics dataframe
2023-04-20 11:31:53,759:INFO:Initializing Quadratic Discriminant Analysis
2023-04-20 11:31:53,760:INFO:Total runtime is 4.246676929791769 minutes
2023-04-20 11:31:53,772:INFO:SubProcess create_model() called ==================================
2023-04-20 11:31:53,773:INFO:Initializing create_model()
2023-04-20 11:31:53,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DFFAF9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:31:53,774:INFO:Checking exceptions
2023-04-20 11:31:53,774:INFO:Importing libraries
2023-04-20 11:31:53,775:INFO:Copying training dataset
2023-04-20 11:31:53,787:INFO:Defining folds
2023-04-20 11:31:53,788:INFO:Declaring metric variables
2023-04-20 11:31:53,802:INFO:Importing untrained model
2023-04-20 11:31:53,816:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-20 11:31:53,854:INFO:Starting cross validation
2023-04-20 11:31:53,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:31:54,500:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:31:54,516:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:31:54,531:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:31:54,578:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:32:01,036:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:32:01,118:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:32:01,149:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:32:01,407:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:32:07,471:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:32:07,627:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:32:23,264:INFO:Calculating mean and std
2023-04-20 11:32:23,264:INFO:Creating metrics dataframe
2023-04-20 11:32:26,542:INFO:Uploading results into container
2023-04-20 11:32:26,542:INFO:Uploading model into container now
2023-04-20 11:32:26,542:INFO:_master_model_container: 8
2023-04-20 11:32:26,542:INFO:_display_container: 2
2023-04-20 11:32:26,542:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-20 11:32:26,542:INFO:create_model() successfully completed......................................
2023-04-20 11:32:26,749:INFO:SubProcess create_model() end ==================================
2023-04-20 11:32:26,749:INFO:Creating metrics dataframe
2023-04-20 11:32:26,780:INFO:Initializing Ada Boost Classifier
2023-04-20 11:32:26,780:INFO:Total runtime is 4.797008041540782 minutes
2023-04-20 11:32:26,796:INFO:SubProcess create_model() called ==================================
2023-04-20 11:32:26,797:INFO:Initializing create_model()
2023-04-20 11:32:26,798:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DFFAF9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:32:26,798:INFO:Checking exceptions
2023-04-20 11:32:26,799:INFO:Importing libraries
2023-04-20 11:32:26,799:INFO:Copying training dataset
2023-04-20 11:32:26,816:INFO:Defining folds
2023-04-20 11:32:26,816:INFO:Declaring metric variables
2023-04-20 11:32:26,828:INFO:Importing untrained model
2023-04-20 11:32:26,844:INFO:Ada Boost Classifier Imported successfully
2023-04-20 11:32:26,874:INFO:Starting cross validation
2023-04-20 11:32:26,880:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:32:37,126:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:32:37,172:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:32:37,204:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:32:37,547:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:33:00,598:INFO:Calculating mean and std
2023-04-20 11:33:00,598:INFO:Creating metrics dataframe
2023-04-20 11:33:04,594:INFO:Uploading results into container
2023-04-20 11:33:04,594:INFO:Uploading model into container now
2023-04-20 11:33:04,594:INFO:_master_model_container: 9
2023-04-20 11:33:04,594:INFO:_display_container: 2
2023-04-20 11:33:04,610:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-04-20 11:33:04,610:INFO:create_model() successfully completed......................................
2023-04-20 11:33:04,818:INFO:SubProcess create_model() end ==================================
2023-04-20 11:33:04,818:INFO:Creating metrics dataframe
2023-04-20 11:33:04,834:INFO:Initializing Gradient Boosting Classifier
2023-04-20 11:33:04,834:INFO:Total runtime is 5.43123909632365 minutes
2023-04-20 11:33:04,857:INFO:SubProcess create_model() called ==================================
2023-04-20 11:33:04,858:INFO:Initializing create_model()
2023-04-20 11:33:04,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DFFAF9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:33:04,859:INFO:Checking exceptions
2023-04-20 11:33:04,860:INFO:Importing libraries
2023-04-20 11:33:04,860:INFO:Copying training dataset
2023-04-20 11:33:04,879:INFO:Defining folds
2023-04-20 11:33:04,880:INFO:Declaring metric variables
2023-04-20 11:33:04,889:INFO:Importing untrained model
2023-04-20 11:33:04,904:INFO:Gradient Boosting Classifier Imported successfully
2023-04-20 11:33:04,932:INFO:Starting cross validation
2023-04-20 11:33:04,933:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:33:16,004:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:33:16,067:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:33:16,067:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:33:16,192:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:33:24,461:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:33:24,555:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:33:37,993:INFO:Calculating mean and std
2023-04-20 11:33:37,993:INFO:Creating metrics dataframe
2023-04-20 11:33:40,818:INFO:Uploading results into container
2023-04-20 11:33:40,818:INFO:Uploading model into container now
2023-04-20 11:33:40,818:INFO:_master_model_container: 10
2023-04-20 11:33:40,818:INFO:_display_container: 2
2023-04-20 11:33:40,818:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-20 11:33:40,818:INFO:create_model() successfully completed......................................
2023-04-20 11:33:40,994:INFO:SubProcess create_model() end ==================================
2023-04-20 11:33:40,994:INFO:Creating metrics dataframe
2023-04-20 11:33:41,028:INFO:Initializing Linear Discriminant Analysis
2023-04-20 11:33:41,028:INFO:Total runtime is 6.0344839374224355 minutes
2023-04-20 11:33:41,036:INFO:SubProcess create_model() called ==================================
2023-04-20 11:33:41,036:INFO:Initializing create_model()
2023-04-20 11:33:41,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DFFAF9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:33:41,037:INFO:Checking exceptions
2023-04-20 11:33:41,038:INFO:Importing libraries
2023-04-20 11:33:41,038:INFO:Copying training dataset
2023-04-20 11:33:41,055:INFO:Defining folds
2023-04-20 11:33:41,055:INFO:Declaring metric variables
2023-04-20 11:33:41,068:INFO:Importing untrained model
2023-04-20 11:33:41,076:INFO:Linear Discriminant Analysis Imported successfully
2023-04-20 11:33:41,093:INFO:Starting cross validation
2023-04-20 11:33:41,104:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:33:48,936:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:34:10,973:INFO:Calculating mean and std
2023-04-20 11:34:10,973:INFO:Creating metrics dataframe
2023-04-20 11:34:13,772:INFO:Uploading results into container
2023-04-20 11:34:13,772:INFO:Uploading model into container now
2023-04-20 11:34:13,772:INFO:_master_model_container: 11
2023-04-20 11:34:13,772:INFO:_display_container: 2
2023-04-20 11:34:13,772:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-20 11:34:13,772:INFO:create_model() successfully completed......................................
2023-04-20 11:34:13,956:INFO:SubProcess create_model() end ==================================
2023-04-20 11:34:13,956:INFO:Creating metrics dataframe
2023-04-20 11:34:13,972:INFO:Initializing Extra Trees Classifier
2023-04-20 11:34:13,972:INFO:Total runtime is 6.583540761470796 minutes
2023-04-20 11:34:13,987:INFO:SubProcess create_model() called ==================================
2023-04-20 11:34:13,987:INFO:Initializing create_model()
2023-04-20 11:34:13,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DFFAF9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:34:13,987:INFO:Checking exceptions
2023-04-20 11:34:13,987:INFO:Importing libraries
2023-04-20 11:34:13,987:INFO:Copying training dataset
2023-04-20 11:34:14,013:INFO:Defining folds
2023-04-20 11:34:14,014:INFO:Declaring metric variables
2023-04-20 11:34:14,025:INFO:Importing untrained model
2023-04-20 11:34:14,047:INFO:Extra Trees Classifier Imported successfully
2023-04-20 11:34:14,063:INFO:Starting cross validation
2023-04-20 11:34:14,081:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:34:16,794:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:34:16,872:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:34:16,872:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:34:16,934:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:34:24,832:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:34:24,848:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:34:24,957:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:34:25,378:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:34:26,378:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:34:26,488:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:34:26,488:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:34:26,941:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:34:34,977:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:34:35,350:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:34:49,116:INFO:Calculating mean and std
2023-04-20 11:34:49,116:INFO:Creating metrics dataframe
2023-04-20 11:34:53,308:INFO:Uploading results into container
2023-04-20 11:34:53,324:INFO:Uploading model into container now
2023-04-20 11:34:53,324:INFO:_master_model_container: 12
2023-04-20 11:34:53,324:INFO:_display_container: 2
2023-04-20 11:34:53,324:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-04-20 11:34:53,324:INFO:create_model() successfully completed......................................
2023-04-20 11:34:53,522:INFO:SubProcess create_model() end ==================================
2023-04-20 11:34:53,522:INFO:Creating metrics dataframe
2023-04-20 11:34:53,553:INFO:Initializing Extreme Gradient Boosting
2023-04-20 11:34:53,553:INFO:Total runtime is 7.243225232760112 minutes
2023-04-20 11:34:53,577:INFO:SubProcess create_model() called ==================================
2023-04-20 11:34:53,578:INFO:Initializing create_model()
2023-04-20 11:34:53,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DFFAF9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:34:53,579:INFO:Checking exceptions
2023-04-20 11:34:53,579:INFO:Importing libraries
2023-04-20 11:34:53,579:INFO:Copying training dataset
2023-04-20 11:34:53,603:INFO:Defining folds
2023-04-20 11:34:53,604:INFO:Declaring metric variables
2023-04-20 11:34:53,617:INFO:Importing untrained model
2023-04-20 11:34:53,635:INFO:Extreme Gradient Boosting Imported successfully
2023-04-20 11:34:53,668:INFO:Starting cross validation
2023-04-20 11:34:53,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:35:04,414:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:35:04,617:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:35:04,774:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:35:26,981:INFO:Calculating mean and std
2023-04-20 11:35:26,981:INFO:Creating metrics dataframe
2023-04-20 11:35:30,414:INFO:Uploading results into container
2023-04-20 11:35:30,414:INFO:Uploading model into container now
2023-04-20 11:35:30,414:INFO:_master_model_container: 13
2023-04-20 11:35:30,414:INFO:_display_container: 2
2023-04-20 11:35:30,414:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-20 11:35:30,414:INFO:create_model() successfully completed......................................
2023-04-20 11:35:30,598:INFO:SubProcess create_model() end ==================================
2023-04-20 11:35:30,598:INFO:Creating metrics dataframe
2023-04-20 11:35:30,613:INFO:Initializing Light Gradient Boosting Machine
2023-04-20 11:35:30,613:INFO:Total runtime is 7.860900612672171 minutes
2023-04-20 11:35:30,629:INFO:SubProcess create_model() called ==================================
2023-04-20 11:35:30,629:INFO:Initializing create_model()
2023-04-20 11:35:30,629:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DFFAF9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:35:30,629:INFO:Checking exceptions
2023-04-20 11:35:30,629:INFO:Importing libraries
2023-04-20 11:35:30,629:INFO:Copying training dataset
2023-04-20 11:35:30,656:INFO:Defining folds
2023-04-20 11:35:30,657:INFO:Declaring metric variables
2023-04-20 11:35:30,667:INFO:Importing untrained model
2023-04-20 11:35:30,679:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-20 11:35:30,711:INFO:Starting cross validation
2023-04-20 11:35:30,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:35:42,558:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:35:42,574:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:35:42,683:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:36:04,376:INFO:Calculating mean and std
2023-04-20 11:36:04,376:INFO:Creating metrics dataframe
2023-04-20 11:36:07,216:INFO:Uploading results into container
2023-04-20 11:36:07,216:INFO:Uploading model into container now
2023-04-20 11:36:07,216:INFO:_master_model_container: 14
2023-04-20 11:36:07,216:INFO:_display_container: 2
2023-04-20 11:36:07,216:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-20 11:36:07,216:INFO:create_model() successfully completed......................................
2023-04-20 11:36:07,384:INFO:SubProcess create_model() end ==================================
2023-04-20 11:36:07,384:INFO:Creating metrics dataframe
2023-04-20 11:36:07,428:INFO:Initializing CatBoost Classifier
2023-04-20 11:36:07,429:INFO:Total runtime is 8.474490201473238 minutes
2023-04-20 11:36:07,436:INFO:SubProcess create_model() called ==================================
2023-04-20 11:36:07,437:INFO:Initializing create_model()
2023-04-20 11:36:07,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DFFAF9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:36:07,437:INFO:Checking exceptions
2023-04-20 11:36:07,438:INFO:Importing libraries
2023-04-20 11:36:07,438:INFO:Copying training dataset
2023-04-20 11:36:07,442:INFO:Defining folds
2023-04-20 11:36:07,442:INFO:Declaring metric variables
2023-04-20 11:36:07,461:INFO:Importing untrained model
2023-04-20 11:36:07,475:INFO:CatBoost Classifier Imported successfully
2023-04-20 11:36:07,494:INFO:Starting cross validation
2023-04-20 11:36:07,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:36:33,689:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:36:41,238:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:37:07,901:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:37:15,313:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:37:38,849:INFO:Calculating mean and std
2023-04-20 11:37:38,849:INFO:Creating metrics dataframe
2023-04-20 11:37:42,066:INFO:Uploading results into container
2023-04-20 11:37:42,067:INFO:Uploading model into container now
2023-04-20 11:37:42,068:INFO:_master_model_container: 15
2023-04-20 11:37:42,068:INFO:_display_container: 2
2023-04-20 11:37:42,069:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DFE10520>
2023-04-20 11:37:42,069:INFO:create_model() successfully completed......................................
2023-04-20 11:37:42,239:INFO:SubProcess create_model() end ==================================
2023-04-20 11:37:42,239:INFO:Creating metrics dataframe
2023-04-20 11:37:42,270:INFO:Initializing Dummy Classifier
2023-04-20 11:37:42,270:INFO:Total runtime is 10.055179472764335 minutes
2023-04-20 11:37:42,270:INFO:SubProcess create_model() called ==================================
2023-04-20 11:37:42,270:INFO:Initializing create_model()
2023-04-20 11:37:42,270:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DFFAF9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:37:42,270:INFO:Checking exceptions
2023-04-20 11:37:42,270:INFO:Importing libraries
2023-04-20 11:37:42,270:INFO:Copying training dataset
2023-04-20 11:37:42,302:INFO:Defining folds
2023-04-20 11:37:42,303:INFO:Declaring metric variables
2023-04-20 11:37:42,314:INFO:Importing untrained model
2023-04-20 11:37:42,325:INFO:Dummy Classifier Imported successfully
2023-04-20 11:37:42,351:INFO:Starting cross validation
2023-04-20 11:37:42,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:37:43,662:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:37:43,725:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:37:43,725:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:37:43,740:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:37:50,338:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:37:50,479:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:37:50,557:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:37:50,557:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:37:50,698:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:37:56,860:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:37:56,922:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:38:12,583:INFO:Calculating mean and std
2023-04-20 11:38:12,583:INFO:Creating metrics dataframe
2023-04-20 11:38:15,510:INFO:Uploading results into container
2023-04-20 11:38:15,510:INFO:Uploading model into container now
2023-04-20 11:38:15,510:INFO:_master_model_container: 16
2023-04-20 11:38:15,510:INFO:_display_container: 2
2023-04-20 11:38:15,510:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-04-20 11:38:15,510:INFO:create_model() successfully completed......................................
2023-04-20 11:38:15,700:INFO:SubProcess create_model() end ==================================
2023-04-20 11:38:15,700:INFO:Creating metrics dataframe
2023-04-20 11:38:15,759:INFO:Initializing create_model()
2023-04-20 11:38:15,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFB52020>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1DFE10520>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:38:15,759:INFO:Checking exceptions
2023-04-20 11:38:15,765:INFO:Importing libraries
2023-04-20 11:38:15,765:INFO:Copying training dataset
2023-04-20 11:38:15,780:INFO:Defining folds
2023-04-20 11:38:15,780:INFO:Declaring metric variables
2023-04-20 11:38:15,781:INFO:Importing untrained model
2023-04-20 11:38:15,781:INFO:Declaring custom model
2023-04-20 11:38:15,782:INFO:CatBoost Classifier Imported successfully
2023-04-20 11:38:15,787:INFO:Cross validation set to False
2023-04-20 11:38:15,787:INFO:Fitting Model
2023-04-20 11:38:28,370:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DFE12B90>
2023-04-20 11:38:28,370:INFO:create_model() successfully completed......................................
2023-04-20 11:38:28,635:INFO:_master_model_container: 16
2023-04-20 11:38:28,636:INFO:_display_container: 2
2023-04-20 11:38:28,636:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DFE12B90>
2023-04-20 11:38:28,636:INFO:compare_models() successfully completed......................................
2023-04-20 11:38:55,431:INFO:PyCaret ClassificationExperiment
2023-04-20 11:38:55,431:INFO:Logging name: clf-default-name
2023-04-20 11:38:55,431:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-20 11:38:55,431:INFO:version 3.0.0
2023-04-20 11:38:55,431:INFO:Initializing setup()
2023-04-20 11:38:55,431:INFO:self.USI: 05ee
2023-04-20 11:38:55,431:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'memory', 'USI', 'X_train', 'seed', 'log_plots_param', 'gpu_param', 'html_param', 'exp_id', 'gpu_n_jobs_param', 'target_param', 'is_multiclass', 'data', 'y_train', 'y_test', 'X_test', 'y', '_ml_usecase', 'n_jobs_param', 'fix_imbalance', 'fold_groups_param', 'idx', 'exp_name_log', 'fold_generator', 'logging_param', 'X', '_available_plots'}
2023-04-20 11:38:55,431:INFO:Checking environment
2023-04-20 11:38:55,431:INFO:python_version: 3.10.9
2023-04-20 11:38:55,431:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-04-20 11:38:55,431:INFO:machine: AMD64
2023-04-20 11:38:55,431:INFO:platform: Windows-10-10.0.19044-SP0
2023-04-20 11:38:55,431:INFO:Memory: svmem(total=8483184640, available=3494330368, percent=58.8, used=4988854272, free=3494330368)
2023-04-20 11:38:55,431:INFO:Physical Core: 2
2023-04-20 11:38:55,431:INFO:Logical Core: 4
2023-04-20 11:38:55,431:INFO:Checking libraries
2023-04-20 11:38:55,431:INFO:System:
2023-04-20 11:38:55,431:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-04-20 11:38:55,431:INFO:executable: C:\Users\User\.conda\envs\My_envI\python.exe
2023-04-20 11:38:55,431:INFO:   machine: Windows-10-10.0.19044-SP0
2023-04-20 11:38:55,431:INFO:PyCaret required dependencies:
2023-04-20 11:38:55,431:INFO:                 pip: 22.3.1
2023-04-20 11:38:55,431:INFO:          setuptools: 66.0.0
2023-04-20 11:38:55,431:INFO:             pycaret: 3.0.0
2023-04-20 11:38:55,431:INFO:             IPython: 8.12.0
2023-04-20 11:38:55,431:INFO:          ipywidgets: 7.6.5
2023-04-20 11:38:55,431:INFO:                tqdm: 4.64.1
2023-04-20 11:38:55,431:INFO:               numpy: 1.23.5
2023-04-20 11:38:55,431:INFO:              pandas: 1.5.3
2023-04-20 11:38:55,431:INFO:              jinja2: 3.1.2
2023-04-20 11:38:55,431:INFO:               scipy: 1.10.1
2023-04-20 11:38:55,431:INFO:              joblib: 1.2.0
2023-04-20 11:38:55,431:INFO:             sklearn: 1.2.1
2023-04-20 11:38:55,431:INFO:                pyod: 1.0.9
2023-04-20 11:38:55,431:INFO:            imblearn: 0.10.1
2023-04-20 11:38:55,431:INFO:   category_encoders: 2.6.0
2023-04-20 11:38:55,431:INFO:            lightgbm: 3.3.5
2023-04-20 11:38:55,431:INFO:               numba: 0.56.4
2023-04-20 11:38:55,431:INFO:            requests: 2.28.1
2023-04-20 11:38:55,431:INFO:          matplotlib: 3.7.0
2023-04-20 11:38:55,431:INFO:          scikitplot: 0.3.7
2023-04-20 11:38:55,431:INFO:         yellowbrick: 1.5
2023-04-20 11:38:55,431:INFO:              plotly: 5.14.1
2023-04-20 11:38:55,431:INFO:             kaleido: 0.2.1
2023-04-20 11:38:55,431:INFO:         statsmodels: 0.13.5
2023-04-20 11:38:55,431:INFO:              sktime: 0.17.0
2023-04-20 11:38:55,431:INFO:               tbats: 1.1.2
2023-04-20 11:38:55,431:INFO:            pmdarima: 2.0.3
2023-04-20 11:38:55,431:INFO:              psutil: 5.9.0
2023-04-20 11:38:55,431:INFO:PyCaret optional dependencies:
2023-04-20 11:38:55,431:INFO:                shap: 0.41.0
2023-04-20 11:38:55,431:INFO:           interpret: 0.3.2
2023-04-20 11:38:55,431:INFO:                umap: 0.5.3
2023-04-20 11:38:55,431:INFO:    pandas_profiling: 4.1.2
2023-04-20 11:38:55,431:INFO:  explainerdashboard: 0.4.2.1
2023-04-20 11:38:55,431:INFO:             autoviz: 0.1.58
2023-04-20 11:38:55,431:INFO:           fairlearn: 0.7.0
2023-04-20 11:38:55,431:INFO:             xgboost: 1.7.5
2023-04-20 11:38:55,431:INFO:            catboost: 1.1.1
2023-04-20 11:38:55,431:INFO:              kmodes: 0.12.2
2023-04-20 11:38:55,431:INFO:             mlxtend: 0.22.0
2023-04-20 11:38:55,431:INFO:       statsforecast: 1.5.0
2023-04-20 11:38:55,431:INFO:        tune_sklearn: 0.4.5
2023-04-20 11:38:55,431:INFO:                 ray: 2.3.1
2023-04-20 11:38:55,431:INFO:            hyperopt: 0.2.7
2023-04-20 11:38:55,431:INFO:              optuna: 3.1.0
2023-04-20 11:38:55,431:INFO:               skopt: 0.9.0
2023-04-20 11:38:55,431:INFO:              mlflow: 1.30.1
2023-04-20 11:38:55,431:INFO:              gradio: Not installed
2023-04-20 11:38:55,431:INFO:             fastapi: 0.89.1
2023-04-20 11:38:55,431:INFO:             uvicorn: 0.21.1
2023-04-20 11:38:55,431:INFO:              m2cgen: 0.10.0
2023-04-20 11:38:55,431:INFO:           evidently: 0.2.8
2023-04-20 11:38:55,431:INFO:               fugue: 0.8.3
2023-04-20 11:38:55,431:INFO:           streamlit: Not installed
2023-04-20 11:38:55,431:INFO:             prophet: Not installed
2023-04-20 11:38:55,431:INFO:None
2023-04-20 11:38:55,431:INFO:Set up data.
2023-04-20 11:38:55,462:INFO:Set up train/test split.
2023-04-20 11:38:55,478:INFO:Set up index.
2023-04-20 11:38:55,478:INFO:Set up folding strategy.
2023-04-20 11:38:55,478:INFO:Assigning column types.
2023-04-20 11:38:55,494:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-20 11:38:55,572:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-20 11:38:55,587:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 11:38:55,650:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:38:55,650:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:38:55,744:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-20 11:38:55,744:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 11:38:55,844:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:38:55,849:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:38:55,850:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-20 11:38:55,950:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 11:38:56,013:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:38:56,029:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:38:56,122:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 11:38:56,169:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:38:56,185:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:38:56,185:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-20 11:38:56,324:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:38:56,324:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:38:56,465:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:38:56,465:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:38:56,465:INFO:Preparing preprocessing pipeline...
2023-04-20 11:38:56,465:INFO:Set up label encoding.
2023-04-20 11:38:56,465:INFO:Set up simple imputation.
2023-04-20 11:38:56,481:INFO:Set up encoding of ordinal features.
2023-04-20 11:38:56,481:INFO:Set up encoding of categorical features.
2023-04-20 11:38:56,684:INFO:Finished creating preprocessing pipeline.
2023-04-20 11:38:56,731:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                             'property_magnitude',
                                             'other_payment_plans', 'housing',
                                             'job', 'marital_status'],
                                    transformer=OneHotEncoder(cols=['credit_history',
                                                                    'purpose',
                                                                    'other_parties',
                                                                    'property_magnitude',
                                                                    'other_payment_plans',
                                                                    'housing',
                                                                    'job',
                                                                    'marital_status'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-04-20 11:38:56,731:INFO:Creating final display dataframe.
2023-04-20 11:38:57,565:INFO:Setup _display_container:                     Description                      Value
0                    Session id                        123
1                        Target                      class
2                   Target type                     Binary
3                Target mapping  Aprovado: 0, Reprovado: 1
4           Original data shape                  (950, 22)
5        Transformed data shape                  (950, 50)
6   Transformed train set shape                  (665, 50)
7    Transformed test set shape                  (285, 50)
8              Ordinal features                          3
9              Numeric features                         10
10         Categorical features                         11
11                   Preprocess                       True
12              Imputation type                     simple
13           Numeric imputation                       mean
14       Categorical imputation                       mode
15     Maximum one-hot encoding                         25
16              Encoding method                       None
17               Fold Generator            StratifiedKFold
18                  Fold Number                         10
19                     CPU Jobs                         -1
20                      Use GPU                      False
21               Log Experiment                      False
22              Experiment Name           clf-default-name
23                          USI                       05ee
2023-04-20 11:38:57,733:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:38:57,738:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:38:57,880:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:38:57,880:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:38:57,880:INFO:setup() successfully completed in 4.92s...............
2023-04-20 11:39:14,246:INFO:Initializing compare_models()
2023-04-20 11:39:14,247:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-20 11:39:14,248:INFO:Checking exceptions
2023-04-20 11:39:14,258:INFO:Preparing display monitor
2023-04-20 11:39:14,332:INFO:Initializing Logistic Regression
2023-04-20 11:39:14,333:INFO:Total runtime is 1.6637643178304036e-05 minutes
2023-04-20 11:39:14,349:INFO:SubProcess create_model() called ==================================
2023-04-20 11:39:14,350:INFO:Initializing create_model()
2023-04-20 11:39:14,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF803FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:39:14,350:INFO:Checking exceptions
2023-04-20 11:39:14,351:INFO:Importing libraries
2023-04-20 11:39:14,351:INFO:Copying training dataset
2023-04-20 11:39:14,364:INFO:Defining folds
2023-04-20 11:39:14,366:INFO:Declaring metric variables
2023-04-20 11:39:14,378:INFO:Importing untrained model
2023-04-20 11:39:14,387:INFO:Logistic Regression Imported successfully
2023-04-20 11:39:14,407:INFO:Starting cross validation
2023-04-20 11:39:14,414:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:39:45,585:INFO:Calculating mean and std
2023-04-20 11:39:45,585:INFO:Creating metrics dataframe
2023-04-20 11:39:48,533:INFO:Uploading results into container
2023-04-20 11:39:48,533:INFO:Uploading model into container now
2023-04-20 11:39:48,533:INFO:_master_model_container: 1
2023-04-20 11:39:48,533:INFO:_display_container: 2
2023-04-20 11:39:48,533:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-20 11:39:48,533:INFO:create_model() successfully completed......................................
2023-04-20 11:39:48,704:INFO:SubProcess create_model() end ==================================
2023-04-20 11:39:48,704:INFO:Creating metrics dataframe
2023-04-20 11:39:48,730:INFO:Initializing K Neighbors Classifier
2023-04-20 11:39:48,730:INFO:Total runtime is 0.5732966462771097 minutes
2023-04-20 11:39:48,730:INFO:SubProcess create_model() called ==================================
2023-04-20 11:39:48,730:INFO:Initializing create_model()
2023-04-20 11:39:48,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF803FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:39:48,743:INFO:Checking exceptions
2023-04-20 11:39:48,744:INFO:Importing libraries
2023-04-20 11:39:48,744:INFO:Copying training dataset
2023-04-20 11:39:48,756:INFO:Defining folds
2023-04-20 11:39:48,757:INFO:Declaring metric variables
2023-04-20 11:39:48,768:INFO:Importing untrained model
2023-04-20 11:39:48,786:INFO:K Neighbors Classifier Imported successfully
2023-04-20 11:39:48,812:INFO:Starting cross validation
2023-04-20 11:39:48,812:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:39:56,559:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:39:56,653:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:40:19,593:INFO:Calculating mean and std
2023-04-20 11:40:19,593:INFO:Creating metrics dataframe
2023-04-20 11:40:22,465:INFO:Uploading results into container
2023-04-20 11:40:22,465:INFO:Uploading model into container now
2023-04-20 11:40:22,465:INFO:_master_model_container: 2
2023-04-20 11:40:22,465:INFO:_display_container: 2
2023-04-20 11:40:22,465:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-20 11:40:22,465:INFO:create_model() successfully completed......................................
2023-04-20 11:40:22,648:INFO:SubProcess create_model() end ==================================
2023-04-20 11:40:22,648:INFO:Creating metrics dataframe
2023-04-20 11:40:22,664:INFO:Initializing Naive Bayes
2023-04-20 11:40:22,664:INFO:Total runtime is 1.1388675451278685 minutes
2023-04-20 11:40:22,679:INFO:SubProcess create_model() called ==================================
2023-04-20 11:40:22,679:INFO:Initializing create_model()
2023-04-20 11:40:22,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF803FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:40:22,680:INFO:Checking exceptions
2023-04-20 11:40:22,681:INFO:Importing libraries
2023-04-20 11:40:22,681:INFO:Copying training dataset
2023-04-20 11:40:22,694:INFO:Defining folds
2023-04-20 11:40:22,695:INFO:Declaring metric variables
2023-04-20 11:40:22,706:INFO:Importing untrained model
2023-04-20 11:40:22,724:INFO:Naive Bayes Imported successfully
2023-04-20 11:40:22,743:INFO:Starting cross validation
2023-04-20 11:40:22,756:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:40:53,118:INFO:Calculating mean and std
2023-04-20 11:40:53,118:INFO:Creating metrics dataframe
2023-04-20 11:40:56,224:INFO:Uploading results into container
2023-04-20 11:40:56,224:INFO:Uploading model into container now
2023-04-20 11:40:56,224:INFO:_master_model_container: 3
2023-04-20 11:40:56,224:INFO:_display_container: 2
2023-04-20 11:40:56,224:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-20 11:40:56,224:INFO:create_model() successfully completed......................................
2023-04-20 11:40:56,412:INFO:SubProcess create_model() end ==================================
2023-04-20 11:40:56,412:INFO:Creating metrics dataframe
2023-04-20 11:40:56,428:INFO:Initializing Decision Tree Classifier
2023-04-20 11:40:56,428:INFO:Total runtime is 1.7016026178995767 minutes
2023-04-20 11:40:56,428:INFO:SubProcess create_model() called ==================================
2023-04-20 11:40:56,428:INFO:Initializing create_model()
2023-04-20 11:40:56,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF803FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:40:56,428:INFO:Checking exceptions
2023-04-20 11:40:56,428:INFO:Importing libraries
2023-04-20 11:40:56,443:INFO:Copying training dataset
2023-04-20 11:40:56,459:INFO:Defining folds
2023-04-20 11:40:56,460:INFO:Declaring metric variables
2023-04-20 11:40:56,472:INFO:Importing untrained model
2023-04-20 11:40:56,502:INFO:Decision Tree Classifier Imported successfully
2023-04-20 11:40:56,547:INFO:Starting cross validation
2023-04-20 11:40:56,554:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:41:26,923:INFO:Calculating mean and std
2023-04-20 11:41:26,923:INFO:Creating metrics dataframe
2023-04-20 11:41:30,091:INFO:Uploading results into container
2023-04-20 11:41:30,091:INFO:Uploading model into container now
2023-04-20 11:41:30,091:INFO:_master_model_container: 4
2023-04-20 11:41:30,091:INFO:_display_container: 2
2023-04-20 11:41:30,091:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-04-20 11:41:30,091:INFO:create_model() successfully completed......................................
2023-04-20 11:41:30,298:INFO:SubProcess create_model() end ==================================
2023-04-20 11:41:30,298:INFO:Creating metrics dataframe
2023-04-20 11:41:30,329:INFO:Initializing SVM - Linear Kernel
2023-04-20 11:41:30,329:INFO:Total runtime is 2.2666168093681334 minutes
2023-04-20 11:41:30,338:INFO:SubProcess create_model() called ==================================
2023-04-20 11:41:30,338:INFO:Initializing create_model()
2023-04-20 11:41:30,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF803FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:41:30,338:INFO:Checking exceptions
2023-04-20 11:41:30,338:INFO:Importing libraries
2023-04-20 11:41:30,338:INFO:Copying training dataset
2023-04-20 11:41:30,354:INFO:Defining folds
2023-04-20 11:41:30,370:INFO:Declaring metric variables
2023-04-20 11:41:30,392:INFO:Importing untrained model
2023-04-20 11:41:30,401:INFO:SVM - Linear Kernel Imported successfully
2023-04-20 11:41:30,424:INFO:Starting cross validation
2023-04-20 11:41:30,432:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:41:31,676:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:41:31,707:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:41:31,707:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:41:31,707:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:41:31,769:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:41:31,785:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:41:38,274:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:41:38,305:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:41:38,475:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:41:38,647:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:41:38,662:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:41:38,803:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:41:38,818:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:41:44,639:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:41:44,655:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:41:44,796:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:41:44,796:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:42:00,558:INFO:Calculating mean and std
2023-04-20 11:42:00,573:INFO:Creating metrics dataframe
2023-04-20 11:42:04,320:INFO:Uploading results into container
2023-04-20 11:42:04,335:INFO:Uploading model into container now
2023-04-20 11:42:04,335:INFO:_master_model_container: 5
2023-04-20 11:42:04,335:INFO:_display_container: 2
2023-04-20 11:42:04,335:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-20 11:42:04,335:INFO:create_model() successfully completed......................................
2023-04-20 11:42:04,540:INFO:SubProcess create_model() end ==================================
2023-04-20 11:42:04,540:INFO:Creating metrics dataframe
2023-04-20 11:42:04,556:INFO:Initializing Ridge Classifier
2023-04-20 11:42:04,556:INFO:Total runtime is 2.8370619535446164 minutes
2023-04-20 11:42:04,576:INFO:SubProcess create_model() called ==================================
2023-04-20 11:42:04,576:INFO:Initializing create_model()
2023-04-20 11:42:04,577:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF803FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:42:04,577:INFO:Checking exceptions
2023-04-20 11:42:04,578:INFO:Importing libraries
2023-04-20 11:42:04,578:INFO:Copying training dataset
2023-04-20 11:42:04,599:INFO:Defining folds
2023-04-20 11:42:04,600:INFO:Declaring metric variables
2023-04-20 11:42:04,626:INFO:Importing untrained model
2023-04-20 11:42:04,638:INFO:Ridge Classifier Imported successfully
2023-04-20 11:42:04,665:INFO:Starting cross validation
2023-04-20 11:42:04,683:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:42:05,917:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:42:05,933:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:42:05,933:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:42:05,979:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:42:12,544:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:42:12,544:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:42:12,576:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:42:12,669:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:42:12,779:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:42:19,023:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:42:19,179:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:42:34,537:INFO:Calculating mean and std
2023-04-20 11:42:34,537:INFO:Creating metrics dataframe
2023-04-20 11:42:38,952:INFO:Uploading results into container
2023-04-20 11:42:38,968:INFO:Uploading model into container now
2023-04-20 11:42:38,968:INFO:_master_model_container: 6
2023-04-20 11:42:38,968:INFO:_display_container: 2
2023-04-20 11:42:38,968:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-04-20 11:42:38,968:INFO:create_model() successfully completed......................................
2023-04-20 11:42:39,166:INFO:SubProcess create_model() end ==================================
2023-04-20 11:42:39,166:INFO:Creating metrics dataframe
2023-04-20 11:42:39,182:INFO:Initializing Random Forest Classifier
2023-04-20 11:42:39,182:INFO:Total runtime is 3.4141660173734025 minutes
2023-04-20 11:42:39,209:INFO:SubProcess create_model() called ==================================
2023-04-20 11:42:39,210:INFO:Initializing create_model()
2023-04-20 11:42:39,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF803FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:42:39,211:INFO:Checking exceptions
2023-04-20 11:42:39,211:INFO:Importing libraries
2023-04-20 11:42:39,212:INFO:Copying training dataset
2023-04-20 11:42:39,233:INFO:Defining folds
2023-04-20 11:42:39,234:INFO:Declaring metric variables
2023-04-20 11:42:39,247:INFO:Importing untrained model
2023-04-20 11:42:39,271:INFO:Random Forest Classifier Imported successfully
2023-04-20 11:42:39,290:INFO:Starting cross validation
2023-04-20 11:42:39,310:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:42:42,401:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:42:42,448:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:42:42,479:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:42:42,495:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:42:49,706:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:42:49,753:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:42:49,894:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:42:50,253:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:42:51,128:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:42:51,159:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:42:51,383:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:42:51,610:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:42:59,290:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:43:00,538:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:43:00,991:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:43:15,379:INFO:Calculating mean and std
2023-04-20 11:43:15,379:INFO:Creating metrics dataframe
2023-04-20 11:43:19,389:INFO:Uploading results into container
2023-04-20 11:43:19,390:INFO:Uploading model into container now
2023-04-20 11:43:19,391:INFO:_master_model_container: 7
2023-04-20 11:43:19,391:INFO:_display_container: 2
2023-04-20 11:43:19,391:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-20 11:43:19,391:INFO:create_model() successfully completed......................................
2023-04-20 11:43:19,552:INFO:SubProcess create_model() end ==================================
2023-04-20 11:43:19,552:INFO:Creating metrics dataframe
2023-04-20 11:43:19,584:INFO:Initializing Quadratic Discriminant Analysis
2023-04-20 11:43:19,584:INFO:Total runtime is 4.087526893615722 minutes
2023-04-20 11:43:19,599:INFO:SubProcess create_model() called ==================================
2023-04-20 11:43:19,599:INFO:Initializing create_model()
2023-04-20 11:43:19,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF803FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:43:19,600:INFO:Checking exceptions
2023-04-20 11:43:19,601:INFO:Importing libraries
2023-04-20 11:43:19,601:INFO:Copying training dataset
2023-04-20 11:43:19,616:INFO:Defining folds
2023-04-20 11:43:19,617:INFO:Declaring metric variables
2023-04-20 11:43:19,627:INFO:Importing untrained model
2023-04-20 11:43:19,645:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-20 11:43:19,664:INFO:Starting cross validation
2023-04-20 11:43:19,680:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:43:20,163:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:43:20,178:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:43:20,194:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:43:20,194:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:43:26,542:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:43:26,699:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:43:26,745:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:43:26,902:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:43:27,820:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:43:27,914:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:43:33,454:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:43:33,485:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:43:50,264:INFO:Calculating mean and std
2023-04-20 11:43:50,264:INFO:Creating metrics dataframe
2023-04-20 11:43:53,213:INFO:Uploading results into container
2023-04-20 11:43:53,213:INFO:Uploading model into container now
2023-04-20 11:43:53,229:INFO:_master_model_container: 8
2023-04-20 11:43:53,229:INFO:_display_container: 2
2023-04-20 11:43:53,229:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-20 11:43:53,229:INFO:create_model() successfully completed......................................
2023-04-20 11:43:53,400:INFO:SubProcess create_model() end ==================================
2023-04-20 11:43:53,400:INFO:Creating metrics dataframe
2023-04-20 11:43:53,441:INFO:Initializing Ada Boost Classifier
2023-04-20 11:43:53,442:INFO:Total runtime is 4.6518307010332745 minutes
2023-04-20 11:43:53,449:INFO:SubProcess create_model() called ==================================
2023-04-20 11:43:53,450:INFO:Initializing create_model()
2023-04-20 11:43:53,450:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF803FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:43:53,451:INFO:Checking exceptions
2023-04-20 11:43:53,452:INFO:Importing libraries
2023-04-20 11:43:53,452:INFO:Copying training dataset
2023-04-20 11:43:53,470:INFO:Defining folds
2023-04-20 11:43:53,471:INFO:Declaring metric variables
2023-04-20 11:43:53,484:INFO:Importing untrained model
2023-04-20 11:43:53,493:INFO:Ada Boost Classifier Imported successfully
2023-04-20 11:43:53,512:INFO:Starting cross validation
2023-04-20 11:43:53,522:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:44:03,968:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:44:03,999:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:44:04,046:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:44:27,186:INFO:Calculating mean and std
2023-04-20 11:44:27,186:INFO:Creating metrics dataframe
2023-04-20 11:44:31,654:INFO:Uploading results into container
2023-04-20 11:44:31,654:INFO:Uploading model into container now
2023-04-20 11:44:31,654:INFO:_master_model_container: 9
2023-04-20 11:44:31,670:INFO:_display_container: 2
2023-04-20 11:44:31,670:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-04-20 11:44:31,670:INFO:create_model() successfully completed......................................
2023-04-20 11:44:31,842:INFO:SubProcess create_model() end ==================================
2023-04-20 11:44:31,842:INFO:Creating metrics dataframe
2023-04-20 11:44:31,873:INFO:Initializing Gradient Boosting Classifier
2023-04-20 11:44:31,873:INFO:Total runtime is 5.29235117038091 minutes
2023-04-20 11:44:31,873:INFO:SubProcess create_model() called ==================================
2023-04-20 11:44:31,873:INFO:Initializing create_model()
2023-04-20 11:44:31,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF803FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:44:31,873:INFO:Checking exceptions
2023-04-20 11:44:31,873:INFO:Importing libraries
2023-04-20 11:44:31,873:INFO:Copying training dataset
2023-04-20 11:44:31,899:INFO:Defining folds
2023-04-20 11:44:31,899:INFO:Declaring metric variables
2023-04-20 11:44:31,911:INFO:Importing untrained model
2023-04-20 11:44:31,924:INFO:Gradient Boosting Classifier Imported successfully
2023-04-20 11:44:31,953:INFO:Starting cross validation
2023-04-20 11:44:31,961:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:44:33,684:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:44:34,803:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:44:41,331:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:44:41,629:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:44:42,595:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:44:42,626:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:44:42,705:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:44:42,939:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:44:50,898:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:44:51,226:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:45:06,380:INFO:Calculating mean and std
2023-04-20 11:45:06,380:INFO:Creating metrics dataframe
2023-04-20 11:45:09,392:INFO:Uploading results into container
2023-04-20 11:45:09,392:INFO:Uploading model into container now
2023-04-20 11:45:09,392:INFO:_master_model_container: 10
2023-04-20 11:45:09,392:INFO:_display_container: 2
2023-04-20 11:45:09,408:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-20 11:45:09,408:INFO:create_model() successfully completed......................................
2023-04-20 11:45:09,605:INFO:SubProcess create_model() end ==================================
2023-04-20 11:45:09,605:INFO:Creating metrics dataframe
2023-04-20 11:45:09,621:INFO:Initializing Linear Discriminant Analysis
2023-04-20 11:45:09,621:INFO:Total runtime is 5.921483095486959 minutes
2023-04-20 11:45:09,644:INFO:SubProcess create_model() called ==================================
2023-04-20 11:45:09,644:INFO:Initializing create_model()
2023-04-20 11:45:09,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF803FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:45:09,644:INFO:Checking exceptions
2023-04-20 11:45:09,644:INFO:Importing libraries
2023-04-20 11:45:09,644:INFO:Copying training dataset
2023-04-20 11:45:09,644:INFO:Defining folds
2023-04-20 11:45:09,644:INFO:Declaring metric variables
2023-04-20 11:45:09,669:INFO:Importing untrained model
2023-04-20 11:45:09,679:INFO:Linear Discriminant Analysis Imported successfully
2023-04-20 11:45:09,704:INFO:Starting cross validation
2023-04-20 11:45:09,714:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:45:40,530:INFO:Calculating mean and std
2023-04-20 11:45:40,530:INFO:Creating metrics dataframe
2023-04-20 11:45:43,433:INFO:Uploading results into container
2023-04-20 11:45:43,433:INFO:Uploading model into container now
2023-04-20 11:45:43,433:INFO:_master_model_container: 11
2023-04-20 11:45:43,433:INFO:_display_container: 2
2023-04-20 11:45:43,433:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-20 11:45:43,433:INFO:create_model() successfully completed......................................
2023-04-20 11:45:43,598:INFO:SubProcess create_model() end ==================================
2023-04-20 11:45:43,598:INFO:Creating metrics dataframe
2023-04-20 11:45:43,629:INFO:Initializing Extra Trees Classifier
2023-04-20 11:45:43,629:INFO:Total runtime is 6.488284385204316 minutes
2023-04-20 11:45:43,645:INFO:SubProcess create_model() called ==================================
2023-04-20 11:45:43,645:INFO:Initializing create_model()
2023-04-20 11:45:43,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF803FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:45:43,645:INFO:Checking exceptions
2023-04-20 11:45:43,645:INFO:Importing libraries
2023-04-20 11:45:43,645:INFO:Copying training dataset
2023-04-20 11:45:43,668:INFO:Defining folds
2023-04-20 11:45:43,668:INFO:Declaring metric variables
2023-04-20 11:45:43,668:INFO:Importing untrained model
2023-04-20 11:45:43,690:INFO:Extra Trees Classifier Imported successfully
2023-04-20 11:45:43,721:INFO:Starting cross validation
2023-04-20 11:45:43,721:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:45:46,462:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:45:46,509:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:45:46,525:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:45:46,650:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:45:54,328:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:45:54,362:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:45:54,795:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:45:55,748:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:45:55,795:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:45:55,827:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:45:56,280:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:45:57,270:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:46:03,974:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:46:04,084:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:46:05,238:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:46:05,331:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:46:20,532:INFO:Calculating mean and std
2023-04-20 11:46:20,532:INFO:Creating metrics dataframe
2023-04-20 11:46:24,855:INFO:Uploading results into container
2023-04-20 11:46:24,855:INFO:Uploading model into container now
2023-04-20 11:46:24,855:INFO:_master_model_container: 12
2023-04-20 11:46:24,855:INFO:_display_container: 2
2023-04-20 11:46:24,871:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-04-20 11:46:24,871:INFO:create_model() successfully completed......................................
2023-04-20 11:46:25,064:INFO:SubProcess create_model() end ==================================
2023-04-20 11:46:25,079:INFO:Creating metrics dataframe
2023-04-20 11:46:25,095:INFO:Initializing Extreme Gradient Boosting
2023-04-20 11:46:25,095:INFO:Total runtime is 7.17938396135966 minutes
2023-04-20 11:46:25,119:INFO:SubProcess create_model() called ==================================
2023-04-20 11:46:25,119:INFO:Initializing create_model()
2023-04-20 11:46:25,119:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF803FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:46:25,119:INFO:Checking exceptions
2023-04-20 11:46:25,119:INFO:Importing libraries
2023-04-20 11:46:25,119:INFO:Copying training dataset
2023-04-20 11:46:25,135:INFO:Defining folds
2023-04-20 11:46:25,135:INFO:Declaring metric variables
2023-04-20 11:46:25,135:INFO:Importing untrained model
2023-04-20 11:46:25,169:INFO:Extreme Gradient Boosting Imported successfully
2023-04-20 11:46:25,196:INFO:Starting cross validation
2023-04-20 11:46:25,205:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:46:34,401:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:46:57,974:INFO:Calculating mean and std
2023-04-20 11:46:57,974:INFO:Creating metrics dataframe
2023-04-20 11:47:01,102:INFO:Uploading results into container
2023-04-20 11:47:01,102:INFO:Uploading model into container now
2023-04-20 11:47:01,102:INFO:_master_model_container: 13
2023-04-20 11:47:01,102:INFO:_display_container: 2
2023-04-20 11:47:01,115:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-20 11:47:01,116:INFO:create_model() successfully completed......................................
2023-04-20 11:47:01,285:INFO:SubProcess create_model() end ==================================
2023-04-20 11:47:01,285:INFO:Creating metrics dataframe
2023-04-20 11:47:01,301:INFO:Initializing Light Gradient Boosting Machine
2023-04-20 11:47:01,301:INFO:Total runtime is 7.782814359664917 minutes
2023-04-20 11:47:01,316:INFO:SubProcess create_model() called ==================================
2023-04-20 11:47:01,316:INFO:Initializing create_model()
2023-04-20 11:47:01,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF803FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:47:01,316:INFO:Checking exceptions
2023-04-20 11:47:01,316:INFO:Importing libraries
2023-04-20 11:47:01,316:INFO:Copying training dataset
2023-04-20 11:47:01,338:INFO:Defining folds
2023-04-20 11:47:01,338:INFO:Declaring metric variables
2023-04-20 11:47:01,351:INFO:Importing untrained model
2023-04-20 11:47:01,362:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-20 11:47:01,379:INFO:Starting cross validation
2023-04-20 11:47:01,400:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:47:10,321:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:47:34,317:INFO:Calculating mean and std
2023-04-20 11:47:34,317:INFO:Creating metrics dataframe
2023-04-20 11:47:37,664:INFO:Uploading results into container
2023-04-20 11:47:37,665:INFO:Uploading model into container now
2023-04-20 11:47:37,666:INFO:_master_model_container: 14
2023-04-20 11:47:37,666:INFO:_display_container: 2
2023-04-20 11:47:37,668:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-20 11:47:37,668:INFO:create_model() successfully completed......................................
2023-04-20 11:47:37,831:INFO:SubProcess create_model() end ==================================
2023-04-20 11:47:37,831:INFO:Creating metrics dataframe
2023-04-20 11:47:37,878:INFO:Initializing CatBoost Classifier
2023-04-20 11:47:37,878:INFO:Total runtime is 8.392433524131775 minutes
2023-04-20 11:47:37,891:INFO:SubProcess create_model() called ==================================
2023-04-20 11:47:37,892:INFO:Initializing create_model()
2023-04-20 11:47:37,893:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF803FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:47:37,894:INFO:Checking exceptions
2023-04-20 11:47:37,894:INFO:Importing libraries
2023-04-20 11:47:37,894:INFO:Copying training dataset
2023-04-20 11:47:37,915:INFO:Defining folds
2023-04-20 11:47:37,917:INFO:Declaring metric variables
2023-04-20 11:47:37,930:INFO:Importing untrained model
2023-04-20 11:47:37,941:INFO:CatBoost Classifier Imported successfully
2023-04-20 11:47:37,969:INFO:Starting cross validation
2023-04-20 11:47:37,976:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:47:48,847:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:47:48,878:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:47:48,894:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:48:10,124:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:48:10,817:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:48:10,987:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:48:11,123:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:48:40,465:INFO:Calculating mean and std
2023-04-20 11:48:40,465:INFO:Creating metrics dataframe
2023-04-20 11:48:44,479:INFO:Uploading results into container
2023-04-20 11:48:44,479:INFO:Uploading model into container now
2023-04-20 11:48:44,495:INFO:_master_model_container: 15
2023-04-20 11:48:44,495:INFO:_display_container: 2
2023-04-20 11:48:44,495:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DFB80100>
2023-04-20 11:48:44,495:INFO:create_model() successfully completed......................................
2023-04-20 11:48:44,683:INFO:SubProcess create_model() end ==================================
2023-04-20 11:48:44,683:INFO:Creating metrics dataframe
2023-04-20 11:48:44,714:INFO:Initializing Dummy Classifier
2023-04-20 11:48:44,714:INFO:Total runtime is 9.506365378697714 minutes
2023-04-20 11:48:44,714:INFO:SubProcess create_model() called ==================================
2023-04-20 11:48:44,714:INFO:Initializing create_model()
2023-04-20 11:48:44,729:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF803FD0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:48:44,729:INFO:Checking exceptions
2023-04-20 11:48:44,729:INFO:Importing libraries
2023-04-20 11:48:44,729:INFO:Copying training dataset
2023-04-20 11:48:44,745:INFO:Defining folds
2023-04-20 11:48:44,745:INFO:Declaring metric variables
2023-04-20 11:48:44,761:INFO:Importing untrained model
2023-04-20 11:48:44,761:INFO:Dummy Classifier Imported successfully
2023-04-20 11:48:44,776:INFO:Starting cross validation
2023-04-20 11:48:44,792:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:48:46,407:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:48:46,412:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:48:46,490:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:48:46,567:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:48:53,735:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:48:53,766:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:48:53,860:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:48:54,094:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:49:00,858:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:49:01,100:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:49:19,832:INFO:Calculating mean and std
2023-04-20 11:49:19,834:INFO:Creating metrics dataframe
2023-04-20 11:49:23,473:INFO:Uploading results into container
2023-04-20 11:49:23,473:INFO:Uploading model into container now
2023-04-20 11:49:23,473:INFO:_master_model_container: 16
2023-04-20 11:49:23,489:INFO:_display_container: 2
2023-04-20 11:49:23,489:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-04-20 11:49:23,489:INFO:create_model() successfully completed......................................
2023-04-20 11:49:23,687:INFO:SubProcess create_model() end ==================================
2023-04-20 11:49:23,687:INFO:Creating metrics dataframe
2023-04-20 11:49:23,749:INFO:Initializing create_model()
2023-04-20 11:49:23,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAFB50>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1DFB80100>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:49:23,750:INFO:Checking exceptions
2023-04-20 11:49:23,754:INFO:Importing libraries
2023-04-20 11:49:23,755:INFO:Copying training dataset
2023-04-20 11:49:23,767:INFO:Defining folds
2023-04-20 11:49:23,767:INFO:Declaring metric variables
2023-04-20 11:49:23,767:INFO:Importing untrained model
2023-04-20 11:49:23,768:INFO:Declaring custom model
2023-04-20 11:49:23,769:INFO:CatBoost Classifier Imported successfully
2023-04-20 11:49:23,774:INFO:Cross validation set to False
2023-04-20 11:49:23,775:INFO:Fitting Model
2023-04-20 11:49:31,178:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DFDE7EE0>
2023-04-20 11:49:31,178:INFO:create_model() successfully completed......................................
2023-04-20 11:49:31,467:INFO:_master_model_container: 16
2023-04-20 11:49:31,467:INFO:_display_container: 2
2023-04-20 11:49:31,468:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DFDE7EE0>
2023-04-20 11:49:31,468:INFO:compare_models() successfully completed......................................
2023-04-20 11:49:34,361:INFO:PyCaret ClassificationExperiment
2023-04-20 11:49:34,361:INFO:Logging name: clf-default-name
2023-04-20 11:49:34,361:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-20 11:49:34,361:INFO:version 3.0.0
2023-04-20 11:49:34,362:INFO:Initializing setup()
2023-04-20 11:49:34,362:INFO:self.USI: d90a
2023-04-20 11:49:34,362:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'memory', 'USI', 'X_train', 'seed', 'log_plots_param', 'gpu_param', 'html_param', 'exp_id', 'gpu_n_jobs_param', 'target_param', 'is_multiclass', 'data', 'y_train', 'y_test', 'X_test', 'y', '_ml_usecase', 'n_jobs_param', 'fix_imbalance', 'fold_groups_param', 'idx', 'exp_name_log', 'fold_generator', 'logging_param', 'X', '_available_plots'}
2023-04-20 11:49:34,362:INFO:Checking environment
2023-04-20 11:49:34,362:INFO:python_version: 3.10.9
2023-04-20 11:49:34,363:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-04-20 11:49:34,363:INFO:machine: AMD64
2023-04-20 11:49:34,363:INFO:platform: Windows-10-10.0.19044-SP0
2023-04-20 11:49:34,363:INFO:Memory: svmem(total=8483184640, available=3466166272, percent=59.1, used=5017018368, free=3466166272)
2023-04-20 11:49:34,363:INFO:Physical Core: 2
2023-04-20 11:49:34,364:INFO:Logical Core: 4
2023-04-20 11:49:34,364:INFO:Checking libraries
2023-04-20 11:49:34,364:INFO:System:
2023-04-20 11:49:34,364:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-04-20 11:49:34,364:INFO:executable: C:\Users\User\.conda\envs\My_envI\python.exe
2023-04-20 11:49:34,364:INFO:   machine: Windows-10-10.0.19044-SP0
2023-04-20 11:49:34,364:INFO:PyCaret required dependencies:
2023-04-20 11:49:34,364:INFO:                 pip: 22.3.1
2023-04-20 11:49:34,364:INFO:          setuptools: 66.0.0
2023-04-20 11:49:34,364:INFO:             pycaret: 3.0.0
2023-04-20 11:49:34,365:INFO:             IPython: 8.12.0
2023-04-20 11:49:34,365:INFO:          ipywidgets: 7.6.5
2023-04-20 11:49:34,365:INFO:                tqdm: 4.64.1
2023-04-20 11:49:34,365:INFO:               numpy: 1.23.5
2023-04-20 11:49:34,365:INFO:              pandas: 1.5.3
2023-04-20 11:49:34,365:INFO:              jinja2: 3.1.2
2023-04-20 11:49:34,365:INFO:               scipy: 1.10.1
2023-04-20 11:49:34,365:INFO:              joblib: 1.2.0
2023-04-20 11:49:34,365:INFO:             sklearn: 1.2.1
2023-04-20 11:49:34,365:INFO:                pyod: 1.0.9
2023-04-20 11:49:34,365:INFO:            imblearn: 0.10.1
2023-04-20 11:49:34,366:INFO:   category_encoders: 2.6.0
2023-04-20 11:49:34,366:INFO:            lightgbm: 3.3.5
2023-04-20 11:49:34,366:INFO:               numba: 0.56.4
2023-04-20 11:49:34,366:INFO:            requests: 2.28.1
2023-04-20 11:49:34,366:INFO:          matplotlib: 3.7.0
2023-04-20 11:49:34,366:INFO:          scikitplot: 0.3.7
2023-04-20 11:49:34,366:INFO:         yellowbrick: 1.5
2023-04-20 11:49:34,366:INFO:              plotly: 5.14.1
2023-04-20 11:49:34,366:INFO:             kaleido: 0.2.1
2023-04-20 11:49:34,366:INFO:         statsmodels: 0.13.5
2023-04-20 11:49:34,366:INFO:              sktime: 0.17.0
2023-04-20 11:49:34,366:INFO:               tbats: 1.1.2
2023-04-20 11:49:34,367:INFO:            pmdarima: 2.0.3
2023-04-20 11:49:34,367:INFO:              psutil: 5.9.0
2023-04-20 11:49:34,367:INFO:PyCaret optional dependencies:
2023-04-20 11:49:34,367:INFO:                shap: 0.41.0
2023-04-20 11:49:34,367:INFO:           interpret: 0.3.2
2023-04-20 11:49:34,367:INFO:                umap: 0.5.3
2023-04-20 11:49:34,367:INFO:    pandas_profiling: 4.1.2
2023-04-20 11:49:34,367:INFO:  explainerdashboard: 0.4.2.1
2023-04-20 11:49:34,367:INFO:             autoviz: 0.1.58
2023-04-20 11:49:34,367:INFO:           fairlearn: 0.7.0
2023-04-20 11:49:34,367:INFO:             xgboost: 1.7.5
2023-04-20 11:49:34,368:INFO:            catboost: 1.1.1
2023-04-20 11:49:34,368:INFO:              kmodes: 0.12.2
2023-04-20 11:49:34,368:INFO:             mlxtend: 0.22.0
2023-04-20 11:49:34,368:INFO:       statsforecast: 1.5.0
2023-04-20 11:49:34,368:INFO:        tune_sklearn: 0.4.5
2023-04-20 11:49:34,368:INFO:                 ray: 2.3.1
2023-04-20 11:49:34,368:INFO:            hyperopt: 0.2.7
2023-04-20 11:49:34,368:INFO:              optuna: 3.1.0
2023-04-20 11:49:34,369:INFO:               skopt: 0.9.0
2023-04-20 11:49:34,369:INFO:              mlflow: 1.30.1
2023-04-20 11:49:34,369:INFO:              gradio: Not installed
2023-04-20 11:49:34,369:INFO:             fastapi: 0.89.1
2023-04-20 11:49:34,369:INFO:             uvicorn: 0.21.1
2023-04-20 11:49:34,369:INFO:              m2cgen: 0.10.0
2023-04-20 11:49:34,369:INFO:           evidently: 0.2.8
2023-04-20 11:49:34,369:INFO:               fugue: 0.8.3
2023-04-20 11:49:34,369:INFO:           streamlit: Not installed
2023-04-20 11:49:34,370:INFO:             prophet: Not installed
2023-04-20 11:49:34,370:INFO:None
2023-04-20 11:49:34,370:INFO:Set up data.
2023-04-20 11:49:34,392:INFO:Set up train/test split.
2023-04-20 11:49:34,423:INFO:Set up index.
2023-04-20 11:49:34,423:INFO:Set up folding strategy.
2023-04-20 11:49:34,423:INFO:Assigning column types.
2023-04-20 11:49:34,439:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-20 11:49:34,548:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-20 11:49:34,548:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 11:49:34,626:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:49:34,626:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:49:34,735:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-20 11:49:34,751:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 11:49:34,814:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:49:34,814:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:49:34,814:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-20 11:49:34,939:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 11:49:35,001:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:49:35,017:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:49:35,126:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 11:49:35,189:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:49:35,189:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:49:35,204:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-20 11:49:35,408:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:49:35,408:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:49:35,580:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:49:35,596:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:49:35,596:INFO:Preparing preprocessing pipeline...
2023-04-20 11:49:35,596:INFO:Set up label encoding.
2023-04-20 11:49:35,596:INFO:Set up simple imputation.
2023-04-20 11:49:35,611:INFO:Set up encoding of ordinal features.
2023-04-20 11:49:35,627:INFO:Set up encoding of categorical features.
2023-04-20 11:49:35,627:INFO:Set up feature normalization.
2023-04-20 11:49:35,958:INFO:Finished creating preprocessing pipeline.
2023-04-20 11:49:36,028:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                                    'other_parties',
                                                                    'property_magnitude',
                                                                    'other_payment_plans',
                                                                    'housing',
                                                                    'job',
                                                                    'marital_status'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2023-04-20 11:49:36,028:INFO:Creating final display dataframe.
2023-04-20 11:49:37,246:INFO:Setup _display_container:                     Description                      Value
0                    Session id                        123
1                        Target                      class
2                   Target type                     Binary
3                Target mapping  Aprovado: 0, Reprovado: 1
4           Original data shape                  (950, 22)
5        Transformed data shape                  (950, 50)
6   Transformed train set shape                  (665, 50)
7    Transformed test set shape                  (285, 50)
8              Ordinal features                          3
9              Numeric features                         10
10         Categorical features                         11
11                   Preprocess                       True
12              Imputation type                     simple
13           Numeric imputation                       mean
14       Categorical imputation                       mode
15     Maximum one-hot encoding                         25
16              Encoding method                       None
17                    Normalize                       True
18             Normalize method                     minmax
19               Fold Generator            StratifiedKFold
20                  Fold Number                         10
21                     CPU Jobs                         -1
22                      Use GPU                      False
23               Log Experiment                      False
24              Experiment Name           clf-default-name
25                          USI                       d90a
2023-04-20 11:49:37,436:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:49:37,436:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:49:37,608:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 11:49:37,608:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 11:49:37,623:INFO:setup() successfully completed in 6.04s...............
2023-04-20 11:49:53,863:INFO:Initializing get_config()
2023-04-20 11:49:53,864:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, variable=X_transformed)
2023-04-20 11:49:54,034:INFO:Variable: X returned as      checking_status  duration  credit_history_existing paid  \
266         0.333333  0.294118                           1.0   
400         0.666667  0.073529                           1.0   
395         0.333333  0.029412                           0.0   
553         0.000000  0.382353                           0.0   
560         0.333333  0.117647                           1.0   
..               ...       ...                           ...   
290         0.333333  0.294118                           0.0   
770         0.000000  0.161765                           1.0   
257         0.666667  0.073529                           1.0   
878         0.666667  0.205882                           0.0   
278         0.666667  0.176471                           0.0   

     credit_history_critical/other existing credit  \
266                                            0.0   
400                                            0.0   
395                                            1.0   
553                                            0.0   
560                                            0.0   
..                                             ...   
290                                            1.0   
770                                            0.0   
257                                            0.0   
878                                            0.0   
278                                            1.0   

     credit_history_delayed previously  credit_history_no credits/all paid  \
266                                0.0                                 0.0   
400                                0.0                                 0.0   
395                                0.0                                 0.0   
553                                1.0                                 0.0   
560                                0.0                                 0.0   
..                                 ...                                 ...   
290                                0.0                                 0.0   
770                                0.0                                 0.0   
257                                0.0                                 0.0   
878                                1.0                                 0.0   
278                                0.0                                 0.0   

     credit_history_all paid  purpose_new car  purpose_radio/tv  \
266                      0.0              1.0               0.0   
400                      0.0              1.0               0.0   
395                      0.0              0.0               1.0   
553                      0.0              0.0               0.0   
560                      0.0              1.0               0.0   
..                       ...              ...               ...   
290                      0.0              0.0               0.0   
770                      0.0              0.0               1.0   
257                      0.0              0.0               0.0   
878                      0.0              1.0               0.0   
278                      0.0              1.0               0.0   

     purpose_business  ...  job_high qualif/self emp/mgmt  \
266               0.0  ...                            0.0   
400               0.0  ...                            0.0   
395               0.0  ...                            0.0   
553               1.0  ...                            0.0   
560               0.0  ...                            0.0   
..                ...  ...                            ...   
290               0.0  ...                            1.0   
770               0.0  ...                            0.0   
257               0.0  ...                            1.0   
878               0.0  ...                            0.0   
278               0.0  ...                            0.0   

     job_unemp/unskilled non res  num_dependents  own_telephone  \
266                          0.0             0.0            0.0   
400                          0.0             0.0            0.0   
395                          0.0             0.0            0.0   
553                          0.0             0.0            0.0   
560                          0.0             0.0            0.0   
..                           ...             ...            ...   
290                          0.0             1.0            1.0   
770                          0.0             0.0            0.0   
257                          0.0             0.0            1.0   
878                          0.0             1.0            0.0   
278                          1.0             0.0            1.0   

     foreign_worker  sex  marital_status_div/dep/mar  marital_status_single  \
266             1.0  0.0                         1.0                    0.0   
400             1.0  0.0                         1.0                    0.0   
395             1.0  0.0                         1.0                    0.0   
553             1.0  1.0                         0.0                    1.0   
560             1.0  0.0                         1.0                    0.0   
..              ...  ...                         ...                    ...   
290             1.0  0.0                         1.0                    0.0   
770             1.0  1.0                         0.0                    1.0   
257             1.0  0.0                         1.0                    0.0   
878             1.0  1.0                         0.0                    1.0   
278             1.0  1.0                         0.0                    1.0   

     marital_status_mar/wid  marital_status_div/sep  
266                     0.0                     0.0  
400                     0.0                     0.0  
395                     0.0                     0.0  
553                     0.0                     0.0  
560                     0.0                     0.0  
..                      ...                     ...  
290                     0.0                     0.0  
770                     0.0                     0.0  
257                     0.0                     0.0  
878                     0.0                     0.0  
278                     0.0                     0.0  

[950 rows x 49 columns]
2023-04-20 11:49:54,034:INFO:get_config() successfully completed......................................
2023-04-20 11:50:00,711:INFO:Initializing compare_models()
2023-04-20 11:50:00,712:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-20 11:50:00,713:INFO:Checking exceptions
2023-04-20 11:50:00,725:INFO:Preparing display monitor
2023-04-20 11:50:00,796:INFO:Initializing Logistic Regression
2023-04-20 11:50:00,796:INFO:Total runtime is 0.0 minutes
2023-04-20 11:50:00,806:INFO:SubProcess create_model() called ==================================
2023-04-20 11:50:00,808:INFO:Initializing create_model()
2023-04-20 11:50:00,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DC7542B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:50:00,809:INFO:Checking exceptions
2023-04-20 11:50:00,809:INFO:Importing libraries
2023-04-20 11:50:00,809:INFO:Copying training dataset
2023-04-20 11:50:00,827:INFO:Defining folds
2023-04-20 11:50:00,827:INFO:Declaring metric variables
2023-04-20 11:50:00,837:INFO:Importing untrained model
2023-04-20 11:50:00,847:INFO:Logistic Regression Imported successfully
2023-04-20 11:50:00,875:INFO:Starting cross validation
2023-04-20 11:50:00,882:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:50:33,170:INFO:Calculating mean and std
2023-04-20 11:50:33,170:INFO:Creating metrics dataframe
2023-04-20 11:50:37,400:INFO:Uploading results into container
2023-04-20 11:50:37,400:INFO:Uploading model into container now
2023-04-20 11:50:37,400:INFO:_master_model_container: 1
2023-04-20 11:50:37,400:INFO:_display_container: 2
2023-04-20 11:50:37,400:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-20 11:50:37,400:INFO:create_model() successfully completed......................................
2023-04-20 11:50:37,610:INFO:SubProcess create_model() end ==================================
2023-04-20 11:50:37,610:INFO:Creating metrics dataframe
2023-04-20 11:50:37,626:INFO:Initializing K Neighbors Classifier
2023-04-20 11:50:37,626:INFO:Total runtime is 0.6138259212176005 minutes
2023-04-20 11:50:37,642:INFO:SubProcess create_model() called ==================================
2023-04-20 11:50:37,642:INFO:Initializing create_model()
2023-04-20 11:50:37,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DC7542B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:50:37,642:INFO:Checking exceptions
2023-04-20 11:50:37,642:INFO:Importing libraries
2023-04-20 11:50:37,642:INFO:Copying training dataset
2023-04-20 11:50:37,679:INFO:Defining folds
2023-04-20 11:50:37,680:INFO:Declaring metric variables
2023-04-20 11:50:37,692:INFO:Importing untrained model
2023-04-20 11:50:37,711:INFO:K Neighbors Classifier Imported successfully
2023-04-20 11:50:37,736:INFO:Starting cross validation
2023-04-20 11:50:37,754:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:50:46,712:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:51:10,457:INFO:Calculating mean and std
2023-04-20 11:51:10,457:INFO:Creating metrics dataframe
2023-04-20 11:51:14,375:INFO:Uploading results into container
2023-04-20 11:51:14,375:INFO:Uploading model into container now
2023-04-20 11:51:14,375:INFO:_master_model_container: 2
2023-04-20 11:51:14,375:INFO:_display_container: 2
2023-04-20 11:51:14,375:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-20 11:51:14,375:INFO:create_model() successfully completed......................................
2023-04-20 11:51:14,536:INFO:SubProcess create_model() end ==================================
2023-04-20 11:51:14,536:INFO:Creating metrics dataframe
2023-04-20 11:51:14,552:INFO:Initializing Naive Bayes
2023-04-20 11:51:14,552:INFO:Total runtime is 1.2292518258094787 minutes
2023-04-20 11:51:14,574:INFO:SubProcess create_model() called ==================================
2023-04-20 11:51:14,574:INFO:Initializing create_model()
2023-04-20 11:51:14,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DC7542B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:51:14,574:INFO:Checking exceptions
2023-04-20 11:51:14,574:INFO:Importing libraries
2023-04-20 11:51:14,574:INFO:Copying training dataset
2023-04-20 11:51:14,591:INFO:Defining folds
2023-04-20 11:51:14,591:INFO:Declaring metric variables
2023-04-20 11:51:14,603:INFO:Importing untrained model
2023-04-20 11:51:14,613:INFO:Naive Bayes Imported successfully
2023-04-20 11:51:14,632:INFO:Starting cross validation
2023-04-20 11:51:14,649:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:51:46,198:INFO:Calculating mean and std
2023-04-20 11:51:46,198:INFO:Creating metrics dataframe
2023-04-20 11:51:49,366:INFO:Uploading results into container
2023-04-20 11:51:49,366:INFO:Uploading model into container now
2023-04-20 11:51:49,366:INFO:_master_model_container: 3
2023-04-20 11:51:49,382:INFO:_display_container: 2
2023-04-20 11:51:49,382:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-20 11:51:49,382:INFO:create_model() successfully completed......................................
2023-04-20 11:51:49,542:INFO:SubProcess create_model() end ==================================
2023-04-20 11:51:49,542:INFO:Creating metrics dataframe
2023-04-20 11:51:49,558:INFO:Initializing Decision Tree Classifier
2023-04-20 11:51:49,558:INFO:Total runtime is 1.812690202395121 minutes
2023-04-20 11:51:49,579:INFO:SubProcess create_model() called ==================================
2023-04-20 11:51:49,581:INFO:Initializing create_model()
2023-04-20 11:51:49,582:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DC7542B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:51:49,582:INFO:Checking exceptions
2023-04-20 11:51:49,582:INFO:Importing libraries
2023-04-20 11:51:49,582:INFO:Copying training dataset
2023-04-20 11:51:49,600:INFO:Defining folds
2023-04-20 11:51:49,600:INFO:Declaring metric variables
2023-04-20 11:51:49,619:INFO:Importing untrained model
2023-04-20 11:51:49,624:INFO:Decision Tree Classifier Imported successfully
2023-04-20 11:51:49,651:INFO:Starting cross validation
2023-04-20 11:51:49,658:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:52:21,220:INFO:Calculating mean and std
2023-04-20 11:52:21,220:INFO:Creating metrics dataframe
2023-04-20 11:52:24,404:INFO:Uploading results into container
2023-04-20 11:52:24,404:INFO:Uploading model into container now
2023-04-20 11:52:24,404:INFO:_master_model_container: 4
2023-04-20 11:52:24,404:INFO:_display_container: 2
2023-04-20 11:52:24,404:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-04-20 11:52:24,404:INFO:create_model() successfully completed......................................
2023-04-20 11:52:24,583:INFO:SubProcess create_model() end ==================================
2023-04-20 11:52:24,583:INFO:Creating metrics dataframe
2023-04-20 11:52:24,599:INFO:Initializing SVM - Linear Kernel
2023-04-20 11:52:24,599:INFO:Total runtime is 2.3967110355695085 minutes
2023-04-20 11:52:24,615:INFO:SubProcess create_model() called ==================================
2023-04-20 11:52:24,615:INFO:Initializing create_model()
2023-04-20 11:52:24,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DC7542B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:52:24,615:INFO:Checking exceptions
2023-04-20 11:52:24,615:INFO:Importing libraries
2023-04-20 11:52:24,615:INFO:Copying training dataset
2023-04-20 11:52:24,634:INFO:Defining folds
2023-04-20 11:52:24,634:INFO:Declaring metric variables
2023-04-20 11:52:24,645:INFO:Importing untrained model
2023-04-20 11:52:24,659:INFO:SVM - Linear Kernel Imported successfully
2023-04-20 11:52:24,681:INFO:Starting cross validation
2023-04-20 11:52:24,694:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:52:25,934:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:52:25,934:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:52:25,934:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:52:26,028:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:52:33,115:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:52:33,131:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:52:33,209:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:52:33,225:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:52:39,748:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:52:39,810:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 11:52:56,604:INFO:Calculating mean and std
2023-04-20 11:52:56,604:INFO:Creating metrics dataframe
2023-04-20 11:53:00,630:INFO:Uploading results into container
2023-04-20 11:53:00,646:INFO:Uploading model into container now
2023-04-20 11:53:00,646:INFO:_master_model_container: 5
2023-04-20 11:53:00,646:INFO:_display_container: 2
2023-04-20 11:53:00,646:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-20 11:53:00,646:INFO:create_model() successfully completed......................................
2023-04-20 11:53:00,839:INFO:SubProcess create_model() end ==================================
2023-04-20 11:53:00,839:INFO:Creating metrics dataframe
2023-04-20 11:53:00,883:INFO:Initializing Ridge Classifier
2023-04-20 11:53:00,884:INFO:Total runtime is 3.0014536460240677 minutes
2023-04-20 11:53:00,898:INFO:SubProcess create_model() called ==================================
2023-04-20 11:53:00,898:INFO:Initializing create_model()
2023-04-20 11:53:00,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DC7542B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:53:00,898:INFO:Checking exceptions
2023-04-20 11:53:00,898:INFO:Importing libraries
2023-04-20 11:53:00,898:INFO:Copying training dataset
2023-04-20 11:53:00,924:INFO:Defining folds
2023-04-20 11:53:00,925:INFO:Declaring metric variables
2023-04-20 11:53:00,939:INFO:Importing untrained model
2023-04-20 11:53:00,953:INFO:Ridge Classifier Imported successfully
2023-04-20 11:53:00,988:INFO:Starting cross validation
2023-04-20 11:53:01,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:53:02,311:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:53:02,358:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:53:02,373:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:53:02,405:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:53:09,647:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:53:09,662:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:53:09,662:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:53:09,787:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:53:09,850:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:53:16,519:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:53:16,660:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 11:53:33,828:INFO:Calculating mean and std
2023-04-20 11:53:33,828:INFO:Creating metrics dataframe
2023-04-20 11:53:38,068:INFO:Uploading results into container
2023-04-20 11:53:38,068:INFO:Uploading model into container now
2023-04-20 11:53:38,083:INFO:_master_model_container: 6
2023-04-20 11:53:38,083:INFO:_display_container: 2
2023-04-20 11:53:38,083:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-04-20 11:53:38,083:INFO:create_model() successfully completed......................................
2023-04-20 11:53:38,260:INFO:SubProcess create_model() end ==================================
2023-04-20 11:53:38,260:INFO:Creating metrics dataframe
2023-04-20 11:53:38,276:INFO:Initializing Random Forest Classifier
2023-04-20 11:53:38,276:INFO:Total runtime is 3.6246595660845435 minutes
2023-04-20 11:53:38,289:INFO:SubProcess create_model() called ==================================
2023-04-20 11:53:38,290:INFO:Initializing create_model()
2023-04-20 11:53:38,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DC7542B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:53:38,291:INFO:Checking exceptions
2023-04-20 11:53:38,291:INFO:Importing libraries
2023-04-20 11:53:38,291:INFO:Copying training dataset
2023-04-20 11:53:38,306:INFO:Defining folds
2023-04-20 11:53:38,306:INFO:Declaring metric variables
2023-04-20 11:53:38,317:INFO:Importing untrained model
2023-04-20 11:53:38,329:INFO:Random Forest Classifier Imported successfully
2023-04-20 11:53:38,357:INFO:Starting cross validation
2023-04-20 11:53:38,357:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:53:41,132:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:53:41,148:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:53:41,195:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:53:41,226:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:53:48,682:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:53:48,713:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:53:48,775:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:53:50,263:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:53:50,263:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:53:50,372:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:53:50,997:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:53:59,657:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:53:59,875:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:54:16,327:INFO:Calculating mean and std
2023-04-20 11:54:16,327:INFO:Creating metrics dataframe
2023-04-20 11:54:20,197:INFO:Uploading results into container
2023-04-20 11:54:20,197:INFO:Uploading model into container now
2023-04-20 11:54:20,197:INFO:_master_model_container: 7
2023-04-20 11:54:20,197:INFO:_display_container: 2
2023-04-20 11:54:20,197:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-20 11:54:20,197:INFO:create_model() successfully completed......................................
2023-04-20 11:54:20,427:INFO:SubProcess create_model() end ==================================
2023-04-20 11:54:20,427:INFO:Creating metrics dataframe
2023-04-20 11:54:20,485:INFO:Initializing Quadratic Discriminant Analysis
2023-04-20 11:54:20,485:INFO:Total runtime is 4.328138367335002 minutes
2023-04-20 11:54:20,499:INFO:SubProcess create_model() called ==================================
2023-04-20 11:54:20,500:INFO:Initializing create_model()
2023-04-20 11:54:20,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DC7542B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:54:20,501:INFO:Checking exceptions
2023-04-20 11:54:20,502:INFO:Importing libraries
2023-04-20 11:54:20,502:INFO:Copying training dataset
2023-04-20 11:54:20,522:INFO:Defining folds
2023-04-20 11:54:20,523:INFO:Declaring metric variables
2023-04-20 11:54:20,536:INFO:Importing untrained model
2023-04-20 11:54:20,550:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-20 11:54:20,582:INFO:Starting cross validation
2023-04-20 11:54:20,592:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:54:21,291:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:54:21,307:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:54:21,370:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:54:21,370:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:54:28,757:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:54:28,820:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:54:28,985:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:54:28,985:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:54:36,133:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:54:36,289:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 11:54:54,096:INFO:Calculating mean and std
2023-04-20 11:54:54,096:INFO:Creating metrics dataframe
2023-04-20 11:54:58,154:INFO:Uploading results into container
2023-04-20 11:54:58,154:INFO:Uploading model into container now
2023-04-20 11:54:58,154:INFO:_master_model_container: 8
2023-04-20 11:54:58,154:INFO:_display_container: 2
2023-04-20 11:54:58,154:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-20 11:54:58,154:INFO:create_model() successfully completed......................................
2023-04-20 11:54:58,333:INFO:SubProcess create_model() end ==================================
2023-04-20 11:54:58,333:INFO:Creating metrics dataframe
2023-04-20 11:54:58,348:INFO:Initializing Ada Boost Classifier
2023-04-20 11:54:58,348:INFO:Total runtime is 4.959199718634287 minutes
2023-04-20 11:54:58,364:INFO:SubProcess create_model() called ==================================
2023-04-20 11:54:58,364:INFO:Initializing create_model()
2023-04-20 11:54:58,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DC7542B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:54:58,372:INFO:Checking exceptions
2023-04-20 11:54:58,372:INFO:Importing libraries
2023-04-20 11:54:58,372:INFO:Copying training dataset
2023-04-20 11:54:58,387:INFO:Defining folds
2023-04-20 11:54:58,387:INFO:Declaring metric variables
2023-04-20 11:54:58,398:INFO:Importing untrained model
2023-04-20 11:54:58,410:INFO:Ada Boost Classifier Imported successfully
2023-04-20 11:54:58,444:INFO:Starting cross validation
2023-04-20 11:54:58,450:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:55:08,521:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:55:08,568:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:55:08,615:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:55:08,787:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:55:16,992:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:55:33,646:INFO:Calculating mean and std
2023-04-20 11:55:33,646:INFO:Creating metrics dataframe
2023-04-20 11:55:36,785:INFO:Uploading results into container
2023-04-20 11:55:36,785:INFO:Uploading model into container now
2023-04-20 11:55:36,785:INFO:_master_model_container: 9
2023-04-20 11:55:36,785:INFO:_display_container: 2
2023-04-20 11:55:36,785:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-04-20 11:55:36,785:INFO:create_model() successfully completed......................................
2023-04-20 11:55:36,970:INFO:SubProcess create_model() end ==================================
2023-04-20 11:55:36,970:INFO:Creating metrics dataframe
2023-04-20 11:55:37,002:INFO:Initializing Gradient Boosting Classifier
2023-04-20 11:55:37,002:INFO:Total runtime is 5.603417642911275 minutes
2023-04-20 11:55:37,002:INFO:SubProcess create_model() called ==================================
2023-04-20 11:55:37,002:INFO:Initializing create_model()
2023-04-20 11:55:37,002:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DC7542B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:55:37,002:INFO:Checking exceptions
2023-04-20 11:55:37,002:INFO:Importing libraries
2023-04-20 11:55:37,002:INFO:Copying training dataset
2023-04-20 11:55:37,031:INFO:Defining folds
2023-04-20 11:55:37,032:INFO:Declaring metric variables
2023-04-20 11:55:37,043:INFO:Importing untrained model
2023-04-20 11:55:37,061:INFO:Gradient Boosting Classifier Imported successfully
2023-04-20 11:55:37,084:INFO:Starting cross validation
2023-04-20 11:55:37,098:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:55:39,554:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:55:39,570:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:55:39,570:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:55:47,304:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:55:47,367:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:55:47,664:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:55:48,724:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:55:48,739:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:55:48,786:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:55:49,160:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:55:57,355:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:55:57,448:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:56:13,991:INFO:Calculating mean and std
2023-04-20 11:56:14,006:INFO:Creating metrics dataframe
2023-04-20 11:56:18,158:INFO:Uploading results into container
2023-04-20 11:56:18,158:INFO:Uploading model into container now
2023-04-20 11:56:18,158:INFO:_master_model_container: 10
2023-04-20 11:56:18,158:INFO:_display_container: 2
2023-04-20 11:56:18,158:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-20 11:56:18,158:INFO:create_model() successfully completed......................................
2023-04-20 11:56:18,338:INFO:SubProcess create_model() end ==================================
2023-04-20 11:56:18,338:INFO:Creating metrics dataframe
2023-04-20 11:56:18,384:INFO:Initializing Linear Discriminant Analysis
2023-04-20 11:56:18,384:INFO:Total runtime is 6.293123451868692 minutes
2023-04-20 11:56:18,391:INFO:SubProcess create_model() called ==================================
2023-04-20 11:56:18,393:INFO:Initializing create_model()
2023-04-20 11:56:18,393:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DC7542B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:56:18,394:INFO:Checking exceptions
2023-04-20 11:56:18,395:INFO:Importing libraries
2023-04-20 11:56:18,395:INFO:Copying training dataset
2023-04-20 11:56:18,414:INFO:Defining folds
2023-04-20 11:56:18,414:INFO:Declaring metric variables
2023-04-20 11:56:18,424:INFO:Importing untrained model
2023-04-20 11:56:18,437:INFO:Linear Discriminant Analysis Imported successfully
2023-04-20 11:56:18,461:INFO:Starting cross validation
2023-04-20 11:56:18,477:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:56:50,438:INFO:Calculating mean and std
2023-04-20 11:56:50,438:INFO:Creating metrics dataframe
2023-04-20 11:56:53,656:INFO:Uploading results into container
2023-04-20 11:56:53,656:INFO:Uploading model into container now
2023-04-20 11:56:53,656:INFO:_master_model_container: 11
2023-04-20 11:56:53,656:INFO:_display_container: 2
2023-04-20 11:56:53,656:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-20 11:56:53,656:INFO:create_model() successfully completed......................................
2023-04-20 11:56:53,829:INFO:SubProcess create_model() end ==================================
2023-04-20 11:56:53,829:INFO:Creating metrics dataframe
2023-04-20 11:56:53,867:INFO:Initializing Extra Trees Classifier
2023-04-20 11:56:53,867:INFO:Total runtime is 6.884503869215647 minutes
2023-04-20 11:56:53,867:INFO:SubProcess create_model() called ==================================
2023-04-20 11:56:53,867:INFO:Initializing create_model()
2023-04-20 11:56:53,867:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DC7542B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:56:53,867:INFO:Checking exceptions
2023-04-20 11:56:53,867:INFO:Importing libraries
2023-04-20 11:56:53,867:INFO:Copying training dataset
2023-04-20 11:56:53,895:INFO:Defining folds
2023-04-20 11:56:53,896:INFO:Declaring metric variables
2023-04-20 11:56:53,907:INFO:Importing untrained model
2023-04-20 11:56:53,920:INFO:Extra Trees Classifier Imported successfully
2023-04-20 11:56:53,954:INFO:Starting cross validation
2023-04-20 11:56:53,954:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:56:56,644:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:56:56,644:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:56:56,659:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:56:56,659:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:57:04,718:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:57:04,749:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:57:04,998:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:57:05,373:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:57:06,230:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:57:06,246:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:57:06,277:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:57:06,852:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:57:14,470:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 11:57:15,815:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:57:16,236:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:57:31,665:INFO:Calculating mean and std
2023-04-20 11:57:31,665:INFO:Creating metrics dataframe
2023-04-20 11:57:36,508:INFO:Uploading results into container
2023-04-20 11:57:36,508:INFO:Uploading model into container now
2023-04-20 11:57:36,508:INFO:_master_model_container: 12
2023-04-20 11:57:36,508:INFO:_display_container: 2
2023-04-20 11:57:36,508:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-04-20 11:57:36,508:INFO:create_model() successfully completed......................................
2023-04-20 11:57:36,679:INFO:SubProcess create_model() end ==================================
2023-04-20 11:57:36,679:INFO:Creating metrics dataframe
2023-04-20 11:57:36,720:INFO:Initializing Extreme Gradient Boosting
2023-04-20 11:57:36,721:INFO:Total runtime is 7.598747241497039 minutes
2023-04-20 11:57:36,728:INFO:SubProcess create_model() called ==================================
2023-04-20 11:57:36,728:INFO:Initializing create_model()
2023-04-20 11:57:36,729:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DC7542B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:57:36,729:INFO:Checking exceptions
2023-04-20 11:57:36,729:INFO:Importing libraries
2023-04-20 11:57:36,730:INFO:Copying training dataset
2023-04-20 11:57:36,749:INFO:Defining folds
2023-04-20 11:57:36,749:INFO:Declaring metric variables
2023-04-20 11:57:36,760:INFO:Importing untrained model
2023-04-20 11:57:36,774:INFO:Extreme Gradient Boosting Imported successfully
2023-04-20 11:57:36,802:INFO:Starting cross validation
2023-04-20 11:57:36,830:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:57:46,563:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:57:46,881:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:58:11,063:INFO:Calculating mean and std
2023-04-20 11:58:11,063:INFO:Creating metrics dataframe
2023-04-20 11:58:14,310:INFO:Uploading results into container
2023-04-20 11:58:14,310:INFO:Uploading model into container now
2023-04-20 11:58:14,310:INFO:_master_model_container: 13
2023-04-20 11:58:14,310:INFO:_display_container: 2
2023-04-20 11:58:14,325:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-20 11:58:14,325:INFO:create_model() successfully completed......................................
2023-04-20 11:58:14,500:INFO:SubProcess create_model() end ==================================
2023-04-20 11:58:14,500:INFO:Creating metrics dataframe
2023-04-20 11:58:14,531:INFO:Initializing Light Gradient Boosting Machine
2023-04-20 11:58:14,531:INFO:Total runtime is 8.22891498406728 minutes
2023-04-20 11:58:14,544:INFO:SubProcess create_model() called ==================================
2023-04-20 11:58:14,545:INFO:Initializing create_model()
2023-04-20 11:58:14,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DC7542B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:58:14,546:INFO:Checking exceptions
2023-04-20 11:58:14,546:INFO:Importing libraries
2023-04-20 11:58:14,546:INFO:Copying training dataset
2023-04-20 11:58:14,565:INFO:Defining folds
2023-04-20 11:58:14,565:INFO:Declaring metric variables
2023-04-20 11:58:14,576:INFO:Importing untrained model
2023-04-20 11:58:14,592:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-20 11:58:14,614:INFO:Starting cross validation
2023-04-20 11:58:14,626:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:58:24,236:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:58:48,884:INFO:Calculating mean and std
2023-04-20 11:58:48,886:INFO:Creating metrics dataframe
2023-04-20 11:58:53,203:INFO:Uploading results into container
2023-04-20 11:58:53,203:INFO:Uploading model into container now
2023-04-20 11:58:53,219:INFO:_master_model_container: 14
2023-04-20 11:58:53,219:INFO:_display_container: 2
2023-04-20 11:58:53,219:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-20 11:58:53,219:INFO:create_model() successfully completed......................................
2023-04-20 11:58:53,418:INFO:SubProcess create_model() end ==================================
2023-04-20 11:58:53,418:INFO:Creating metrics dataframe
2023-04-20 11:58:53,449:INFO:Initializing CatBoost Classifier
2023-04-20 11:58:53,449:INFO:Total runtime is 8.877549199263255 minutes
2023-04-20 11:58:53,465:INFO:SubProcess create_model() called ==================================
2023-04-20 11:58:53,465:INFO:Initializing create_model()
2023-04-20 11:58:53,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DC7542B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:58:53,465:INFO:Checking exceptions
2023-04-20 11:58:53,465:INFO:Importing libraries
2023-04-20 11:58:53,465:INFO:Copying training dataset
2023-04-20 11:58:53,490:INFO:Defining folds
2023-04-20 11:58:53,490:INFO:Declaring metric variables
2023-04-20 11:58:53,507:INFO:Importing untrained model
2023-04-20 11:58:53,520:INFO:CatBoost Classifier Imported successfully
2023-04-20 11:58:53,555:INFO:Starting cross validation
2023-04-20 11:58:53,555:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:59:03,941:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:59:23,093:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:59:47,501:INFO:Calculating mean and std
2023-04-20 11:59:47,501:INFO:Creating metrics dataframe
2023-04-20 11:59:51,060:INFO:Uploading results into container
2023-04-20 11:59:51,060:INFO:Uploading model into container now
2023-04-20 11:59:51,060:INFO:_master_model_container: 15
2023-04-20 11:59:51,060:INFO:_display_container: 2
2023-04-20 11:59:51,060:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DFDE4130>
2023-04-20 11:59:51,060:INFO:create_model() successfully completed......................................
2023-04-20 11:59:51,234:INFO:SubProcess create_model() end ==================================
2023-04-20 11:59:51,234:INFO:Creating metrics dataframe
2023-04-20 11:59:51,266:INFO:Initializing Dummy Classifier
2023-04-20 11:59:51,266:INFO:Total runtime is 9.84115213950475 minutes
2023-04-20 11:59:51,281:INFO:SubProcess create_model() called ==================================
2023-04-20 11:59:51,281:INFO:Initializing create_model()
2023-04-20 11:59:51,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DC7542B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 11:59:51,281:INFO:Checking exceptions
2023-04-20 11:59:51,281:INFO:Importing libraries
2023-04-20 11:59:51,281:INFO:Copying training dataset
2023-04-20 11:59:51,302:INFO:Defining folds
2023-04-20 11:59:51,302:INFO:Declaring metric variables
2023-04-20 11:59:51,314:INFO:Importing untrained model
2023-04-20 11:59:51,326:INFO:Dummy Classifier Imported successfully
2023-04-20 11:59:51,355:INFO:Starting cross validation
2023-04-20 11:59:51,373:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 11:59:52,702:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:59:52,796:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:59:52,811:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 11:59:59,818:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 11:59:59,973:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 12:00:00,051:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 12:00:00,130:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 12:00:00,208:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 12:00:00,255:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 12:00:00,317:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 12:00:07,246:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 12:00:07,434:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 12:00:24,351:INFO:Calculating mean and std
2023-04-20 12:00:24,351:INFO:Creating metrics dataframe
2023-04-20 12:00:28,221:INFO:Uploading results into container
2023-04-20 12:00:28,221:INFO:Uploading model into container now
2023-04-20 12:00:28,221:INFO:_master_model_container: 16
2023-04-20 12:00:28,221:INFO:_display_container: 2
2023-04-20 12:00:28,221:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-04-20 12:00:28,221:INFO:create_model() successfully completed......................................
2023-04-20 12:00:28,421:INFO:SubProcess create_model() end ==================================
2023-04-20 12:00:28,421:INFO:Creating metrics dataframe
2023-04-20 12:00:28,494:INFO:Initializing create_model()
2023-04-20 12:00:28,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1DFDE4130>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-20 12:00:28,496:INFO:Checking exceptions
2023-04-20 12:00:28,501:INFO:Importing libraries
2023-04-20 12:00:28,502:INFO:Copying training dataset
2023-04-20 12:00:28,522:INFO:Defining folds
2023-04-20 12:00:28,522:INFO:Declaring metric variables
2023-04-20 12:00:28,523:INFO:Importing untrained model
2023-04-20 12:00:28,523:INFO:Declaring custom model
2023-04-20 12:00:28,524:INFO:CatBoost Classifier Imported successfully
2023-04-20 12:00:28,529:INFO:Cross validation set to False
2023-04-20 12:00:28,529:INFO:Fitting Model
2023-04-20 12:00:36,634:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DFCCEAA0>
2023-04-20 12:00:36,634:INFO:create_model() successfully completed......................................
2023-04-20 12:00:36,906:INFO:_master_model_container: 16
2023-04-20 12:00:36,906:INFO:_display_container: 2
2023-04-20 12:00:36,907:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DFCCEAA0>
2023-04-20 12:00:36,907:INFO:compare_models() successfully completed......................................
2023-04-20 12:01:29,887:INFO:Initializing create_model()
2023-04-20 12:01:29,887:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1DFCCEAA0>, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-20 12:01:29,887:INFO:Checking exceptions
2023-04-20 12:01:29,945:INFO:Importing libraries
2023-04-20 12:01:29,945:INFO:Copying training dataset
2023-04-20 12:01:29,964:INFO:Defining folds
2023-04-20 12:01:29,964:INFO:Declaring metric variables
2023-04-20 12:01:29,970:INFO:Importing untrained model
2023-04-20 12:01:29,971:INFO:Declaring custom model
2023-04-20 12:01:29,989:INFO:CatBoost Classifier Imported successfully
2023-04-20 12:01:30,010:INFO:Starting cross validation
2023-04-20 12:01:30,020:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 12:02:01,947:INFO:Calculating mean and std
2023-04-20 12:02:01,947:INFO:Creating metrics dataframe
2023-04-20 12:02:01,962:INFO:Finalizing model
2023-04-20 12:02:07,213:INFO:Uploading results into container
2023-04-20 12:02:07,231:INFO:Uploading model into container now
2023-04-20 12:02:07,276:INFO:_master_model_container: 17
2023-04-20 12:02:07,276:INFO:_display_container: 3
2023-04-20 12:02:07,277:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DFD5D150>
2023-04-20 12:02:07,277:INFO:create_model() successfully completed......................................
2023-04-20 12:02:23,574:INFO:Initializing tune_model()
2023-04-20 12:02:23,575:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x000001D1DFD5D150>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>)
2023-04-20 12:02:23,575:INFO:Checking exceptions
2023-04-20 12:02:23,639:INFO:Copying training dataset
2023-04-20 12:02:23,660:INFO:Checking base model
2023-04-20 12:02:23,660:INFO:Base model : CatBoost Classifier
2023-04-20 12:02:23,682:INFO:Declaring metric variables
2023-04-20 12:02:23,691:INFO:Defining Hyperparameters
2023-04-20 12:02:23,984:INFO:Tuning with n_jobs=-1
2023-04-20 12:02:23,984:INFO:Initializing RandomizedSearchCV
2023-04-20 12:08:37,244:INFO:best_params: {'actual_estimator__random_strength': 0.2, 'actual_estimator__n_estimators': 180, 'actual_estimator__l2_leaf_reg': 30, 'actual_estimator__eta': 0.4, 'actual_estimator__depth': 8}
2023-04-20 12:08:37,244:INFO:Hyperparameter search completed
2023-04-20 12:08:37,244:INFO:SubProcess create_model() called ==================================
2023-04-20 12:08:37,244:INFO:Initializing create_model()
2023-04-20 12:08:37,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E0202D10>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CDAB0>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.2, 'n_estimators': 180, 'l2_leaf_reg': 30, 'eta': 0.4, 'depth': 8})
2023-04-20 12:08:37,244:INFO:Checking exceptions
2023-04-20 12:08:37,244:INFO:Importing libraries
2023-04-20 12:08:37,244:INFO:Copying training dataset
2023-04-20 12:08:37,260:INFO:Defining folds
2023-04-20 12:08:37,260:INFO:Declaring metric variables
2023-04-20 12:08:37,260:INFO:Importing untrained model
2023-04-20 12:08:37,260:INFO:Declaring custom model
2023-04-20 12:08:37,260:INFO:CatBoost Classifier Imported successfully
2023-04-20 12:08:37,291:INFO:Starting cross validation
2023-04-20 12:08:37,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 12:08:45,861:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 12:09:11,971:INFO:Calculating mean and std
2023-04-20 12:09:11,971:INFO:Creating metrics dataframe
2023-04-20 12:09:12,004:INFO:Finalizing model
2023-04-20 12:09:18,615:INFO:Uploading results into container
2023-04-20 12:09:18,618:INFO:Uploading model into container now
2023-04-20 12:09:18,619:INFO:_master_model_container: 18
2023-04-20 12:09:18,619:INFO:_display_container: 4
2023-04-20 12:09:18,619:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DFC6DF00>
2023-04-20 12:09:18,619:INFO:create_model() successfully completed......................................
2023-04-20 12:09:18,822:INFO:SubProcess create_model() end ==================================
2023-04-20 12:09:18,822:INFO:choose_better activated
2023-04-20 12:09:18,838:INFO:SubProcess create_model() called ==================================
2023-04-20 12:09:18,838:INFO:Initializing create_model()
2023-04-20 12:09:18,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1DFFAF400>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1DFD5D150>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-20 12:09:18,838:INFO:Checking exceptions
2023-04-20 12:09:18,838:INFO:Importing libraries
2023-04-20 12:09:18,838:INFO:Copying training dataset
2023-04-20 12:09:18,861:INFO:Defining folds
2023-04-20 12:09:18,861:INFO:Declaring metric variables
2023-04-20 12:09:18,861:INFO:Importing untrained model
2023-04-20 12:09:18,861:INFO:Declaring custom model
2023-04-20 12:09:18,861:INFO:CatBoost Classifier Imported successfully
2023-04-20 12:09:18,861:INFO:Starting cross validation
2023-04-20 12:09:18,861:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 12:09:52,254:INFO:Calculating mean and std
2023-04-20 12:09:52,254:INFO:Creating metrics dataframe
2023-04-20 12:09:52,254:INFO:Finalizing model
2023-04-20 12:09:56,264:INFO:Uploading results into container
2023-04-20 12:09:56,264:INFO:Uploading model into container now
2023-04-20 12:09:56,264:INFO:_master_model_container: 19
2023-04-20 12:09:56,264:INFO:_display_container: 5
2023-04-20 12:09:56,264:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DCAB7D00>
2023-04-20 12:09:56,264:INFO:create_model() successfully completed......................................
2023-04-20 12:09:56,421:INFO:SubProcess create_model() end ==================================
2023-04-20 12:09:56,436:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DCAB7D00> result for Accuracy is 0.7669
2023-04-20 12:09:56,436:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DFC6DF00> result for Accuracy is 0.7549
2023-04-20 12:09:56,436:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DCAB7D00> is best model
2023-04-20 12:09:56,436:INFO:choose_better completed
2023-04-20 12:09:56,436:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-20 12:09:56,460:INFO:_master_model_container: 19
2023-04-20 12:09:56,461:INFO:_display_container: 4
2023-04-20 12:09:56,462:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DCAB7D00>
2023-04-20 12:09:56,462:INFO:tune_model() successfully completed......................................
2023-04-20 15:22:54,475:INFO:PyCaret ClassificationExperiment
2023-04-20 15:22:54,475:INFO:Logging name: clf-default-name
2023-04-20 15:22:54,475:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-20 15:22:54,475:INFO:version 3.0.0
2023-04-20 15:22:54,475:INFO:Initializing setup()
2023-04-20 15:22:54,475:INFO:self.USI: fc34
2023-04-20 15:22:54,475:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'memory', 'USI', 'X_train', 'seed', 'log_plots_param', 'gpu_param', 'html_param', 'exp_id', 'gpu_n_jobs_param', 'target_param', 'is_multiclass', 'data', 'y_train', 'y_test', 'X_test', 'y', '_ml_usecase', 'n_jobs_param', 'fix_imbalance', 'fold_groups_param', 'idx', 'exp_name_log', 'fold_generator', 'logging_param', 'X', '_available_plots'}
2023-04-20 15:22:54,475:INFO:Checking environment
2023-04-20 15:22:54,475:INFO:python_version: 3.10.9
2023-04-20 15:22:54,475:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-04-20 15:22:54,475:INFO:machine: AMD64
2023-04-20 15:22:54,475:INFO:platform: Windows-10-10.0.19044-SP0
2023-04-20 15:22:54,475:INFO:Memory: svmem(total=8483184640, available=3899785216, percent=54.0, used=4583399424, free=3899785216)
2023-04-20 15:22:54,475:INFO:Physical Core: 2
2023-04-20 15:22:54,475:INFO:Logical Core: 4
2023-04-20 15:22:54,475:INFO:Checking libraries
2023-04-20 15:22:54,475:INFO:System:
2023-04-20 15:22:54,475:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-04-20 15:22:54,475:INFO:executable: C:\Users\User\.conda\envs\My_envI\python.exe
2023-04-20 15:22:54,475:INFO:   machine: Windows-10-10.0.19044-SP0
2023-04-20 15:22:54,475:INFO:PyCaret required dependencies:
2023-04-20 15:22:54,475:INFO:                 pip: 22.3.1
2023-04-20 15:22:54,475:INFO:          setuptools: 66.0.0
2023-04-20 15:22:54,475:INFO:             pycaret: 3.0.0
2023-04-20 15:22:54,475:INFO:             IPython: 8.12.0
2023-04-20 15:22:54,475:INFO:          ipywidgets: 7.6.5
2023-04-20 15:22:54,475:INFO:                tqdm: 4.64.1
2023-04-20 15:22:54,475:INFO:               numpy: 1.23.5
2023-04-20 15:22:54,475:INFO:              pandas: 1.5.3
2023-04-20 15:22:54,475:INFO:              jinja2: 3.1.2
2023-04-20 15:22:54,475:INFO:               scipy: 1.10.1
2023-04-20 15:22:54,475:INFO:              joblib: 1.2.0
2023-04-20 15:22:54,475:INFO:             sklearn: 1.2.1
2023-04-20 15:22:54,475:INFO:                pyod: 1.0.9
2023-04-20 15:22:54,475:INFO:            imblearn: 0.10.1
2023-04-20 15:22:54,475:INFO:   category_encoders: 2.6.0
2023-04-20 15:22:54,475:INFO:            lightgbm: 3.3.5
2023-04-20 15:22:54,475:INFO:               numba: 0.56.4
2023-04-20 15:22:54,475:INFO:            requests: 2.28.1
2023-04-20 15:22:54,475:INFO:          matplotlib: 3.7.0
2023-04-20 15:22:54,475:INFO:          scikitplot: 0.3.7
2023-04-20 15:22:54,475:INFO:         yellowbrick: 1.5
2023-04-20 15:22:54,475:INFO:              plotly: 5.14.1
2023-04-20 15:22:54,475:INFO:             kaleido: 0.2.1
2023-04-20 15:22:54,475:INFO:         statsmodels: 0.13.5
2023-04-20 15:22:54,475:INFO:              sktime: 0.17.0
2023-04-20 15:22:54,475:INFO:               tbats: 1.1.2
2023-04-20 15:22:54,480:INFO:            pmdarima: 2.0.3
2023-04-20 15:22:54,480:INFO:              psutil: 5.9.0
2023-04-20 15:22:54,480:INFO:PyCaret optional dependencies:
2023-04-20 15:22:54,480:INFO:                shap: 0.41.0
2023-04-20 15:22:54,480:INFO:           interpret: 0.3.2
2023-04-20 15:22:54,480:INFO:                umap: 0.5.3
2023-04-20 15:22:54,480:INFO:    pandas_profiling: 4.1.2
2023-04-20 15:22:54,480:INFO:  explainerdashboard: 0.4.2.1
2023-04-20 15:22:54,480:INFO:             autoviz: 0.1.58
2023-04-20 15:22:54,480:INFO:           fairlearn: 0.7.0
2023-04-20 15:22:54,480:INFO:             xgboost: 1.7.5
2023-04-20 15:22:54,480:INFO:            catboost: 1.1.1
2023-04-20 15:22:54,480:INFO:              kmodes: 0.12.2
2023-04-20 15:22:54,480:INFO:             mlxtend: 0.22.0
2023-04-20 15:22:54,480:INFO:       statsforecast: 1.5.0
2023-04-20 15:22:54,480:INFO:        tune_sklearn: 0.4.5
2023-04-20 15:22:54,480:INFO:                 ray: 2.3.1
2023-04-20 15:22:54,480:INFO:            hyperopt: 0.2.7
2023-04-20 15:22:54,480:INFO:              optuna: 3.1.0
2023-04-20 15:22:54,480:INFO:               skopt: 0.9.0
2023-04-20 15:22:54,480:INFO:              mlflow: 1.30.1
2023-04-20 15:22:54,480:INFO:              gradio: Not installed
2023-04-20 15:22:54,480:INFO:             fastapi: 0.89.1
2023-04-20 15:22:54,480:INFO:             uvicorn: 0.21.1
2023-04-20 15:22:54,480:INFO:              m2cgen: 0.10.0
2023-04-20 15:22:54,480:INFO:           evidently: 0.2.8
2023-04-20 15:22:54,480:INFO:               fugue: 0.8.3
2023-04-20 15:22:54,480:INFO:           streamlit: Not installed
2023-04-20 15:22:54,480:INFO:             prophet: Not installed
2023-04-20 15:22:54,480:INFO:None
2023-04-20 15:22:54,480:INFO:Set up data.
2023-04-20 15:22:54,505:INFO:Set up train/test split.
2023-04-20 15:22:54,520:INFO:Set up index.
2023-04-20 15:22:54,520:INFO:Set up folding strategy.
2023-04-20 15:22:54,520:INFO:Assigning column types.
2023-04-20 15:22:54,530:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-20 15:22:54,635:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-20 15:22:54,635:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 15:22:54,685:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 15:22:54,690:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 15:22:54,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-20 15:22:54,775:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 15:22:54,821:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 15:22:54,830:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 15:22:54,830:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-20 15:22:54,913:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 15:22:54,963:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 15:22:54,972:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 15:22:55,055:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-20 15:22:55,108:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 15:22:55,110:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 15:22:55,115:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-20 15:22:55,250:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 15:22:55,255:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 15:22:55,380:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 15:22:55,390:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 15:22:55,395:INFO:Preparing preprocessing pipeline...
2023-04-20 15:22:55,395:INFO:Set up label encoding.
2023-04-20 15:22:55,395:INFO:Set up simple imputation.
2023-04-20 15:22:55,403:INFO:Set up encoding of ordinal features.
2023-04-20 15:22:55,410:INFO:Set up encoding of categorical features.
2023-04-20 15:22:55,410:INFO:Set up imbalanced handling.
2023-04-20 15:22:55,410:INFO:Set up feature normalization.
2023-04-20 15:22:55,760:INFO:Finished creating preprocessing pipeline.
2023-04-20 15:22:55,825:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2023-04-20 15:22:55,825:INFO:Creating final display dataframe.
2023-04-20 15:22:57,000:INFO:Setup _display_container:                     Description                      Value
0                    Session id                        123
1                        Target                      class
2                   Target type                     Binary
3                Target mapping  Aprovado: 0, Reprovado: 1
4           Original data shape                  (950, 22)
5        Transformed data shape                 (1217, 50)
6   Transformed train set shape                  (932, 50)
7    Transformed test set shape                  (285, 50)
8              Ordinal features                          3
9              Numeric features                         10
10         Categorical features                         11
11                   Preprocess                       True
12              Imputation type                     simple
13           Numeric imputation                       mean
14       Categorical imputation                       mode
15     Maximum one-hot encoding                         25
16              Encoding method                       None
17                Fix imbalance                       True
18         Fix imbalance method                      SMOTE
19                    Normalize                       True
20             Normalize method                     minmax
21               Fold Generator            StratifiedKFold
22                  Fold Number                         10
23                     CPU Jobs                         -1
24                      Use GPU                      False
25               Log Experiment                      False
26              Experiment Name           clf-default-name
27                          USI                       fc34
2023-04-20 15:22:57,215:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 15:22:57,220:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 15:22:57,395:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-20 15:22:57,404:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-20 15:22:57,404:INFO:setup() successfully completed in 6.45s...............
2023-04-20 15:23:16,650:INFO:Initializing get_config()
2023-04-20 15:23:16,650:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, variable=X_transformed)
2023-04-20 15:23:16,890:INFO:Variable: X returned as      checking_status  duration  credit_history_existing paid  \
266         0.333333  0.294118                           1.0   
400         0.666667  0.073529                           1.0   
395         0.333333  0.029412                           0.0   
553         0.000000  0.382353                           0.0   
560         0.333333  0.117647                           1.0   
..               ...       ...                           ...   
290         0.333333  0.294118                           0.0   
770         0.000000  0.161765                           1.0   
257         0.666667  0.073529                           1.0   
878         0.666667  0.205882                           0.0   
278         0.666667  0.176471                           0.0   

     credit_history_critical/other existing credit  \
266                                            0.0   
400                                            0.0   
395                                            1.0   
553                                            0.0   
560                                            0.0   
..                                             ...   
290                                            1.0   
770                                            0.0   
257                                            0.0   
878                                            0.0   
278                                            1.0   

     credit_history_delayed previously  credit_history_no credits/all paid  \
266                                0.0                                 0.0   
400                                0.0                                 0.0   
395                                0.0                                 0.0   
553                                1.0                                 0.0   
560                                0.0                                 0.0   
..                                 ...                                 ...   
290                                0.0                                 0.0   
770                                0.0                                 0.0   
257                                0.0                                 0.0   
878                                1.0                                 0.0   
278                                0.0                                 0.0   

     credit_history_all paid  purpose_new car  purpose_radio/tv  \
266                      0.0              1.0               0.0   
400                      0.0              1.0               0.0   
395                      0.0              0.0               1.0   
553                      0.0              0.0               0.0   
560                      0.0              1.0               0.0   
..                       ...              ...               ...   
290                      0.0              0.0               0.0   
770                      0.0              0.0               1.0   
257                      0.0              0.0               0.0   
878                      0.0              1.0               0.0   
278                      0.0              1.0               0.0   

     purpose_business  ...  job_high qualif/self emp/mgmt  \
266               0.0  ...                            0.0   
400               0.0  ...                            0.0   
395               0.0  ...                            0.0   
553               1.0  ...                            0.0   
560               0.0  ...                            0.0   
..                ...  ...                            ...   
290               0.0  ...                            1.0   
770               0.0  ...                            0.0   
257               0.0  ...                            1.0   
878               0.0  ...                            0.0   
278               0.0  ...                            0.0   

     job_unemp/unskilled non res  num_dependents  own_telephone  \
266                          0.0             0.0            0.0   
400                          0.0             0.0            0.0   
395                          0.0             0.0            0.0   
553                          0.0             0.0            0.0   
560                          0.0             0.0            0.0   
..                           ...             ...            ...   
290                          0.0             1.0            1.0   
770                          0.0             0.0            0.0   
257                          0.0             0.0            1.0   
878                          0.0             1.0            0.0   
278                          1.0             0.0            1.0   

     foreign_worker  sex  marital_status_div/dep/mar  marital_status_single  \
266             1.0  0.0                         1.0                    0.0   
400             1.0  0.0                         1.0                    0.0   
395             1.0  0.0                         1.0                    0.0   
553             1.0  1.0                         0.0                    1.0   
560             1.0  0.0                         1.0                    0.0   
..              ...  ...                         ...                    ...   
290             1.0  0.0                         1.0                    0.0   
770             1.0  1.0                         0.0                    1.0   
257             1.0  0.0                         1.0                    0.0   
878             1.0  1.0                         0.0                    1.0   
278             1.0  1.0                         0.0                    1.0   

     marital_status_mar/wid  marital_status_div/sep  
266                     0.0                     0.0  
400                     0.0                     0.0  
395                     0.0                     0.0  
553                     0.0                     0.0  
560                     0.0                     0.0  
..                      ...                     ...  
290                     0.0                     0.0  
770                     0.0                     0.0  
257                     0.0                     0.0  
878                     0.0                     0.0  
278                     0.0                     0.0  

[1217 rows x 49 columns]
2023-04-20 15:23:16,890:INFO:get_config() successfully completed......................................
2023-04-20 15:23:23,408:INFO:Initializing compare_models()
2023-04-20 15:23:23,409:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-20 15:23:23,409:INFO:Checking exceptions
2023-04-20 15:23:23,420:INFO:Preparing display monitor
2023-04-20 15:23:23,509:INFO:Initializing Logistic Regression
2023-04-20 15:23:23,510:INFO:Total runtime is 1.66932741800944e-05 minutes
2023-04-20 15:23:23,520:INFO:SubProcess create_model() called ==================================
2023-04-20 15:23:23,521:INFO:Initializing create_model()
2023-04-20 15:23:23,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CDAB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:23:23,522:INFO:Checking exceptions
2023-04-20 15:23:23,523:INFO:Importing libraries
2023-04-20 15:23:23,523:INFO:Copying training dataset
2023-04-20 15:23:23,540:INFO:Defining folds
2023-04-20 15:23:23,541:INFO:Declaring metric variables
2023-04-20 15:23:23,551:INFO:Importing untrained model
2023-04-20 15:23:23,566:INFO:Logistic Regression Imported successfully
2023-04-20 15:23:23,593:INFO:Starting cross validation
2023-04-20 15:23:23,600:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:24:03,406:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:24:03,530:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:24:03,537:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:24:30,120:INFO:Calculating mean and std
2023-04-20 15:24:30,120:INFO:Creating metrics dataframe
2023-04-20 15:24:34,275:INFO:Uploading results into container
2023-04-20 15:24:34,275:INFO:Uploading model into container now
2023-04-20 15:24:34,279:INFO:_master_model_container: 1
2023-04-20 15:24:34,280:INFO:_display_container: 2
2023-04-20 15:24:34,280:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-20 15:24:34,280:INFO:create_model() successfully completed......................................
2023-04-20 15:24:34,510:INFO:SubProcess create_model() end ==================================
2023-04-20 15:24:34,510:INFO:Creating metrics dataframe
2023-04-20 15:24:34,530:INFO:Initializing K Neighbors Classifier
2023-04-20 15:24:34,530:INFO:Total runtime is 1.183683971563975 minutes
2023-04-20 15:24:34,542:INFO:SubProcess create_model() called ==================================
2023-04-20 15:24:34,542:INFO:Initializing create_model()
2023-04-20 15:24:34,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CDAB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:24:34,542:INFO:Checking exceptions
2023-04-20 15:24:34,542:INFO:Importing libraries
2023-04-20 15:24:34,542:INFO:Copying training dataset
2023-04-20 15:24:34,576:INFO:Defining folds
2023-04-20 15:24:34,577:INFO:Declaring metric variables
2023-04-20 15:24:34,592:INFO:Importing untrained model
2023-04-20 15:24:34,612:INFO:K Neighbors Classifier Imported successfully
2023-04-20 15:24:34,645:INFO:Starting cross validation
2023-04-20 15:24:34,654:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:24:44,700:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:24:44,735:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:24:44,775:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:24:45,010:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:24:53,470:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:25:14,330:INFO:Calculating mean and std
2023-04-20 15:25:14,330:INFO:Creating metrics dataframe
2023-04-20 15:25:20,575:INFO:Uploading results into container
2023-04-20 15:25:20,577:INFO:Uploading model into container now
2023-04-20 15:25:20,578:INFO:_master_model_container: 2
2023-04-20 15:25:20,579:INFO:_display_container: 2
2023-04-20 15:25:20,580:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-20 15:25:20,581:INFO:create_model() successfully completed......................................
2023-04-20 15:25:20,873:INFO:SubProcess create_model() end ==================================
2023-04-20 15:25:20,874:INFO:Creating metrics dataframe
2023-04-20 15:25:20,916:INFO:Initializing Naive Bayes
2023-04-20 15:25:20,927:INFO:Total runtime is 1.956973453362783 minutes
2023-04-20 15:25:20,940:INFO:SubProcess create_model() called ==================================
2023-04-20 15:25:20,941:INFO:Initializing create_model()
2023-04-20 15:25:20,942:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CDAB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:25:20,942:INFO:Checking exceptions
2023-04-20 15:25:20,943:INFO:Importing libraries
2023-04-20 15:25:20,943:INFO:Copying training dataset
2023-04-20 15:25:20,965:INFO:Defining folds
2023-04-20 15:25:20,966:INFO:Declaring metric variables
2023-04-20 15:25:20,979:INFO:Importing untrained model
2023-04-20 15:25:20,994:INFO:Naive Bayes Imported successfully
2023-04-20 15:25:21,020:INFO:Starting cross validation
2023-04-20 15:25:21,030:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:25:24,414:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:25:24,583:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:25:24,689:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:25:24,999:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:25:37,377:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:25:37,676:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:25:37,842:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:25:38,209:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:25:51,200:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:25:51,351:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:26:34,450:INFO:Calculating mean and std
2023-04-20 15:26:34,452:INFO:Creating metrics dataframe
2023-04-20 15:26:38,368:INFO:Uploading results into container
2023-04-20 15:26:38,368:INFO:Uploading model into container now
2023-04-20 15:26:38,368:INFO:_master_model_container: 3
2023-04-20 15:26:38,368:INFO:_display_container: 2
2023-04-20 15:26:38,368:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-20 15:26:38,368:INFO:create_model() successfully completed......................................
2023-04-20 15:26:38,559:INFO:SubProcess create_model() end ==================================
2023-04-20 15:26:38,560:INFO:Creating metrics dataframe
2023-04-20 15:26:38,583:INFO:Initializing Decision Tree Classifier
2023-04-20 15:26:38,584:INFO:Total runtime is 3.2512352387110397 minutes
2023-04-20 15:26:38,594:INFO:SubProcess create_model() called ==================================
2023-04-20 15:26:38,595:INFO:Initializing create_model()
2023-04-20 15:26:38,595:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CDAB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:26:38,595:INFO:Checking exceptions
2023-04-20 15:26:38,595:INFO:Importing libraries
2023-04-20 15:26:38,595:INFO:Copying training dataset
2023-04-20 15:26:38,610:INFO:Defining folds
2023-04-20 15:26:38,610:INFO:Declaring metric variables
2023-04-20 15:26:38,618:INFO:Importing untrained model
2023-04-20 15:26:38,628:INFO:Decision Tree Classifier Imported successfully
2023-04-20 15:26:38,654:INFO:Starting cross validation
2023-04-20 15:26:38,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:26:48,760:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:26:48,911:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:26:48,941:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:26:48,948:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:27:18,993:INFO:Calculating mean and std
2023-04-20 15:27:18,998:INFO:Creating metrics dataframe
2023-04-20 15:27:22,745:INFO:Uploading results into container
2023-04-20 15:27:22,747:INFO:Uploading model into container now
2023-04-20 15:27:22,748:INFO:_master_model_container: 4
2023-04-20 15:27:22,748:INFO:_display_container: 2
2023-04-20 15:27:22,749:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-04-20 15:27:22,750:INFO:create_model() successfully completed......................................
2023-04-20 15:27:22,928:INFO:SubProcess create_model() end ==================================
2023-04-20 15:27:22,928:INFO:Creating metrics dataframe
2023-04-20 15:27:22,954:INFO:Initializing SVM - Linear Kernel
2023-04-20 15:27:22,955:INFO:Total runtime is 3.990774321556092 minutes
2023-04-20 15:27:22,968:INFO:SubProcess create_model() called ==================================
2023-04-20 15:27:22,971:INFO:Initializing create_model()
2023-04-20 15:27:22,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CDAB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:27:22,973:INFO:Checking exceptions
2023-04-20 15:27:22,973:INFO:Importing libraries
2023-04-20 15:27:22,973:INFO:Copying training dataset
2023-04-20 15:27:22,990:INFO:Defining folds
2023-04-20 15:27:22,990:INFO:Declaring metric variables
2023-04-20 15:27:23,003:INFO:Importing untrained model
2023-04-20 15:27:23,028:INFO:SVM - Linear Kernel Imported successfully
2023-04-20 15:27:23,055:INFO:Starting cross validation
2023-04-20 15:27:23,074:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:27:24,616:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 15:27:24,616:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 15:27:24,616:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 15:27:32,928:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:27:32,933:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:27:32,947:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 15:27:32,965:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 15:27:33,114:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:27:33,142:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 15:27:33,195:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:27:33,206:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 15:27:41,962:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 15:27:42,026:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-20 15:28:09,293:INFO:Calculating mean and std
2023-04-20 15:28:09,295:INFO:Creating metrics dataframe
2023-04-20 15:28:13,041:INFO:Uploading results into container
2023-04-20 15:28:13,042:INFO:Uploading model into container now
2023-04-20 15:28:13,043:INFO:_master_model_container: 5
2023-04-20 15:28:13,044:INFO:_display_container: 2
2023-04-20 15:28:13,045:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-20 15:28:13,046:INFO:create_model() successfully completed......................................
2023-04-20 15:28:13,235:INFO:SubProcess create_model() end ==================================
2023-04-20 15:28:13,235:INFO:Creating metrics dataframe
2023-04-20 15:28:13,258:INFO:Initializing Ridge Classifier
2023-04-20 15:28:13,258:INFO:Total runtime is 4.829146190484366 minutes
2023-04-20 15:28:13,266:INFO:SubProcess create_model() called ==================================
2023-04-20 15:28:13,267:INFO:Initializing create_model()
2023-04-20 15:28:13,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CDAB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:28:13,267:INFO:Checking exceptions
2023-04-20 15:28:13,268:INFO:Importing libraries
2023-04-20 15:28:13,268:INFO:Copying training dataset
2023-04-20 15:28:13,288:INFO:Defining folds
2023-04-20 15:28:13,289:INFO:Declaring metric variables
2023-04-20 15:28:13,301:INFO:Importing untrained model
2023-04-20 15:28:13,310:INFO:Ridge Classifier Imported successfully
2023-04-20 15:28:13,349:INFO:Starting cross validation
2023-04-20 15:28:13,358:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:28:14,734:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 15:28:14,742:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 15:28:14,768:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 15:28:14,838:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 15:28:23,153:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:28:23,164:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 15:28:23,243:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:28:23,262:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 15:28:23,312:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:28:23,321:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 15:28:23,465:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:28:23,475:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 15:28:31,097:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 15:28:31,191:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-20 15:28:56,122:INFO:Calculating mean and std
2023-04-20 15:28:56,125:INFO:Creating metrics dataframe
2023-04-20 15:29:00,511:INFO:Uploading results into container
2023-04-20 15:29:00,513:INFO:Uploading model into container now
2023-04-20 15:29:00,514:INFO:_master_model_container: 6
2023-04-20 15:29:00,514:INFO:_display_container: 2
2023-04-20 15:29:00,515:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-04-20 15:29:00,515:INFO:create_model() successfully completed......................................
2023-04-20 15:29:00,699:INFO:SubProcess create_model() end ==================================
2023-04-20 15:29:00,699:INFO:Creating metrics dataframe
2023-04-20 15:29:00,719:INFO:Initializing Random Forest Classifier
2023-04-20 15:29:00,719:INFO:Total runtime is 5.620163782437643 minutes
2023-04-20 15:29:00,729:INFO:SubProcess create_model() called ==================================
2023-04-20 15:29:00,729:INFO:Initializing create_model()
2023-04-20 15:29:00,729:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CDAB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:29:00,729:INFO:Checking exceptions
2023-04-20 15:29:00,729:INFO:Importing libraries
2023-04-20 15:29:00,729:INFO:Copying training dataset
2023-04-20 15:29:00,743:INFO:Defining folds
2023-04-20 15:29:00,743:INFO:Declaring metric variables
2023-04-20 15:29:00,759:INFO:Importing untrained model
2023-04-20 15:29:00,769:INFO:Random Forest Classifier Imported successfully
2023-04-20 15:29:00,779:INFO:Starting cross validation
2023-04-20 15:29:00,789:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:29:03,488:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:29:03,580:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:29:03,843:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:29:05,119:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:29:05,136:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:29:05,244:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:29:05,394:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:29:16,849:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:29:16,959:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:29:17,394:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:29:17,402:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:29:18,829:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:29:18,832:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:29:19,279:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:29:19,444:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:29:29,912:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:29:30,099:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:29:31,299:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:29:31,569:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:29:50,149:INFO:Calculating mean and std
2023-04-20 15:29:50,149:INFO:Creating metrics dataframe
2023-04-20 15:29:54,555:INFO:Uploading results into container
2023-04-20 15:29:54,559:INFO:Uploading model into container now
2023-04-20 15:29:54,559:INFO:_master_model_container: 7
2023-04-20 15:29:54,559:INFO:_display_container: 2
2023-04-20 15:29:54,564:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-20 15:29:54,564:INFO:create_model() successfully completed......................................
2023-04-20 15:29:54,839:INFO:SubProcess create_model() end ==================================
2023-04-20 15:29:54,841:INFO:Creating metrics dataframe
2023-04-20 15:29:54,882:INFO:Initializing Quadratic Discriminant Analysis
2023-04-20 15:29:54,882:INFO:Total runtime is 6.522876755396526 minutes
2023-04-20 15:29:54,894:INFO:SubProcess create_model() called ==================================
2023-04-20 15:29:54,894:INFO:Initializing create_model()
2023-04-20 15:29:54,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CDAB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:29:54,894:INFO:Checking exceptions
2023-04-20 15:29:54,894:INFO:Importing libraries
2023-04-20 15:29:54,899:INFO:Copying training dataset
2023-04-20 15:29:54,914:INFO:Defining folds
2023-04-20 15:29:54,919:INFO:Declaring metric variables
2023-04-20 15:29:54,929:INFO:Importing untrained model
2023-04-20 15:29:54,944:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-20 15:29:54,979:INFO:Starting cross validation
2023-04-20 15:29:54,989:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:29:55,753:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 15:29:55,762:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 15:29:55,764:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 15:29:55,769:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 15:30:03,977:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 15:30:04,200:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 15:30:04,280:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 15:30:04,300:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 15:30:05,274:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:30:05,403:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:30:05,465:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:30:05,515:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:30:16,296:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 15:30:17,113:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-20 15:30:17,180:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-20 15:30:17,930:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:30:40,154:INFO:Calculating mean and std
2023-04-20 15:30:40,159:INFO:Creating metrics dataframe
2023-04-20 15:30:45,544:INFO:Uploading results into container
2023-04-20 15:30:45,544:INFO:Uploading model into container now
2023-04-20 15:30:45,544:INFO:_master_model_container: 8
2023-04-20 15:30:45,544:INFO:_display_container: 2
2023-04-20 15:30:45,549:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-20 15:30:45,549:INFO:create_model() successfully completed......................................
2023-04-20 15:30:45,764:INFO:SubProcess create_model() end ==================================
2023-04-20 15:30:45,769:INFO:Creating metrics dataframe
2023-04-20 15:30:45,801:INFO:Initializing Ada Boost Classifier
2023-04-20 15:30:45,801:INFO:Total runtime is 7.37153835296631 minutes
2023-04-20 15:30:45,825:INFO:SubProcess create_model() called ==================================
2023-04-20 15:30:45,825:INFO:Initializing create_model()
2023-04-20 15:30:45,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CDAB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:30:45,826:INFO:Checking exceptions
2023-04-20 15:30:45,826:INFO:Importing libraries
2023-04-20 15:30:45,827:INFO:Copying training dataset
2023-04-20 15:30:45,854:INFO:Defining folds
2023-04-20 15:30:45,866:INFO:Declaring metric variables
2023-04-20 15:30:45,884:INFO:Importing untrained model
2023-04-20 15:30:45,899:INFO:Ada Boost Classifier Imported successfully
2023-04-20 15:30:45,914:INFO:Starting cross validation
2023-04-20 15:30:45,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:30:49,319:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:30:49,355:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:30:49,399:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:30:49,447:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:30:59,456:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:30:59,471:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:30:59,829:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:31:00,000:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:31:01,083:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:31:01,334:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:31:01,490:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:31:01,747:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:31:11,489:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:31:12,022:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:31:35,580:INFO:Calculating mean and std
2023-04-20 15:31:35,580:INFO:Creating metrics dataframe
2023-04-20 15:31:39,704:INFO:Uploading results into container
2023-04-20 15:31:39,709:INFO:Uploading model into container now
2023-04-20 15:31:39,709:INFO:_master_model_container: 9
2023-04-20 15:31:39,709:INFO:_display_container: 2
2023-04-20 15:31:39,714:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-04-20 15:31:39,714:INFO:create_model() successfully completed......................................
2023-04-20 15:31:39,924:INFO:SubProcess create_model() end ==================================
2023-04-20 15:31:39,924:INFO:Creating metrics dataframe
2023-04-20 15:31:39,949:INFO:Initializing Gradient Boosting Classifier
2023-04-20 15:31:39,949:INFO:Total runtime is 8.273998713493349 minutes
2023-04-20 15:31:39,959:INFO:SubProcess create_model() called ==================================
2023-04-20 15:31:39,959:INFO:Initializing create_model()
2023-04-20 15:31:39,959:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CDAB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:31:39,959:INFO:Checking exceptions
2023-04-20 15:31:39,959:INFO:Importing libraries
2023-04-20 15:31:39,959:INFO:Copying training dataset
2023-04-20 15:31:39,969:INFO:Defining folds
2023-04-20 15:31:39,969:INFO:Declaring metric variables
2023-04-20 15:31:39,989:INFO:Importing untrained model
2023-04-20 15:31:39,999:INFO:Gradient Boosting Classifier Imported successfully
2023-04-20 15:31:40,009:INFO:Starting cross validation
2023-04-20 15:31:40,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:31:43,246:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:31:43,265:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:31:43,311:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:31:43,320:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:31:52,989:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:31:53,010:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:31:53,165:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:31:53,183:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:31:54,571:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:31:54,579:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:31:54,793:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:31:54,799:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:32:05,629:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:32:05,717:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:32:25,054:INFO:Calculating mean and std
2023-04-20 15:32:25,062:INFO:Creating metrics dataframe
2023-04-20 15:32:28,973:INFO:Uploading results into container
2023-04-20 15:32:28,973:INFO:Uploading model into container now
2023-04-20 15:32:28,973:INFO:_master_model_container: 10
2023-04-20 15:32:28,979:INFO:_display_container: 2
2023-04-20 15:32:28,979:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-20 15:32:28,979:INFO:create_model() successfully completed......................................
2023-04-20 15:32:29,179:INFO:SubProcess create_model() end ==================================
2023-04-20 15:32:29,179:INFO:Creating metrics dataframe
2023-04-20 15:32:29,209:INFO:Initializing Linear Discriminant Analysis
2023-04-20 15:32:29,209:INFO:Total runtime is 9.094997088114422 minutes
2023-04-20 15:32:29,219:INFO:SubProcess create_model() called ==================================
2023-04-20 15:32:29,219:INFO:Initializing create_model()
2023-04-20 15:32:29,219:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CDAB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:32:29,223:INFO:Checking exceptions
2023-04-20 15:32:29,223:INFO:Importing libraries
2023-04-20 15:32:29,223:INFO:Copying training dataset
2023-04-20 15:32:29,244:INFO:Defining folds
2023-04-20 15:32:29,244:INFO:Declaring metric variables
2023-04-20 15:32:29,249:INFO:Importing untrained model
2023-04-20 15:32:29,260:INFO:Linear Discriminant Analysis Imported successfully
2023-04-20 15:32:29,295:INFO:Starting cross validation
2023-04-20 15:32:29,306:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:32:40,922:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:32:40,944:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:32:41,012:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:32:41,414:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:33:10,979:INFO:Calculating mean and std
2023-04-20 15:33:10,979:INFO:Creating metrics dataframe
2023-04-20 15:33:14,779:INFO:Uploading results into container
2023-04-20 15:33:14,779:INFO:Uploading model into container now
2023-04-20 15:33:14,779:INFO:_master_model_container: 11
2023-04-20 15:33:14,779:INFO:_display_container: 2
2023-04-20 15:33:14,784:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-20 15:33:14,784:INFO:create_model() successfully completed......................................
2023-04-20 15:33:14,974:INFO:SubProcess create_model() end ==================================
2023-04-20 15:33:14,974:INFO:Creating metrics dataframe
2023-04-20 15:33:14,999:INFO:Initializing Extra Trees Classifier
2023-04-20 15:33:14,999:INFO:Total runtime is 9.858167409896852 minutes
2023-04-20 15:33:15,009:INFO:SubProcess create_model() called ==================================
2023-04-20 15:33:15,009:INFO:Initializing create_model()
2023-04-20 15:33:15,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CDAB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:33:15,009:INFO:Checking exceptions
2023-04-20 15:33:15,009:INFO:Importing libraries
2023-04-20 15:33:15,009:INFO:Copying training dataset
2023-04-20 15:33:15,030:INFO:Defining folds
2023-04-20 15:33:15,030:INFO:Declaring metric variables
2023-04-20 15:33:15,042:INFO:Importing untrained model
2023-04-20 15:33:15,052:INFO:Extra Trees Classifier Imported successfully
2023-04-20 15:33:15,085:INFO:Starting cross validation
2023-04-20 15:33:15,096:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:33:18,352:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:33:18,372:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:33:18,479:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:33:18,609:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:33:28,045:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:33:28,055:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:33:28,364:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:33:28,538:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:33:29,700:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:33:29,740:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:33:30,049:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:33:30,250:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:33:39,049:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:33:39,241:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-20 15:33:40,604:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:33:40,927:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:34:01,929:INFO:Calculating mean and std
2023-04-20 15:34:01,939:INFO:Creating metrics dataframe
2023-04-20 15:34:06,577:INFO:Uploading results into container
2023-04-20 15:34:06,579:INFO:Uploading model into container now
2023-04-20 15:34:06,580:INFO:_master_model_container: 12
2023-04-20 15:34:06,580:INFO:_display_container: 2
2023-04-20 15:34:06,581:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-04-20 15:34:06,582:INFO:create_model() successfully completed......................................
2023-04-20 15:34:06,759:INFO:SubProcess create_model() end ==================================
2023-04-20 15:34:06,759:INFO:Creating metrics dataframe
2023-04-20 15:34:06,779:INFO:Initializing Extreme Gradient Boosting
2023-04-20 15:34:06,779:INFO:Total runtime is 10.721165164311728 minutes
2023-04-20 15:34:06,789:INFO:SubProcess create_model() called ==================================
2023-04-20 15:34:06,789:INFO:Initializing create_model()
2023-04-20 15:34:06,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CDAB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:34:06,789:INFO:Checking exceptions
2023-04-20 15:34:06,789:INFO:Importing libraries
2023-04-20 15:34:06,789:INFO:Copying training dataset
2023-04-20 15:34:06,799:INFO:Defining folds
2023-04-20 15:34:06,809:INFO:Declaring metric variables
2023-04-20 15:34:06,814:INFO:Importing untrained model
2023-04-20 15:34:06,824:INFO:Extreme Gradient Boosting Imported successfully
2023-04-20 15:34:06,844:INFO:Starting cross validation
2023-04-20 15:34:06,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:34:20,208:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:34:20,312:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:34:20,420:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:34:20,517:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:34:31,431:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:34:32,089:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:34:54,205:INFO:Calculating mean and std
2023-04-20 15:34:54,207:INFO:Creating metrics dataframe
2023-04-20 15:34:59,661:INFO:Uploading results into container
2023-04-20 15:34:59,663:INFO:Uploading model into container now
2023-04-20 15:34:59,663:INFO:_master_model_container: 13
2023-04-20 15:34:59,664:INFO:_display_container: 2
2023-04-20 15:34:59,667:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-20 15:34:59,667:INFO:create_model() successfully completed......................................
2023-04-20 15:34:59,883:INFO:SubProcess create_model() end ==================================
2023-04-20 15:34:59,883:INFO:Creating metrics dataframe
2023-04-20 15:34:59,919:INFO:Initializing Light Gradient Boosting Machine
2023-04-20 15:34:59,919:INFO:Total runtime is 11.606831308205923 minutes
2023-04-20 15:34:59,929:INFO:SubProcess create_model() called ==================================
2023-04-20 15:34:59,934:INFO:Initializing create_model()
2023-04-20 15:34:59,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CDAB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:34:59,934:INFO:Checking exceptions
2023-04-20 15:34:59,934:INFO:Importing libraries
2023-04-20 15:34:59,934:INFO:Copying training dataset
2023-04-20 15:34:59,954:INFO:Defining folds
2023-04-20 15:34:59,954:INFO:Declaring metric variables
2023-04-20 15:34:59,964:INFO:Importing untrained model
2023-04-20 15:34:59,979:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-20 15:35:00,003:INFO:Starting cross validation
2023-04-20 15:35:00,009:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:35:08,037:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:35:08,088:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:35:08,145:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:35:19,542:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:35:19,599:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:35:19,599:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:35:19,614:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:35:28,484:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:35:49,029:INFO:Calculating mean and std
2023-04-20 15:35:49,034:INFO:Creating metrics dataframe
2023-04-20 15:35:53,644:INFO:Uploading results into container
2023-04-20 15:35:53,644:INFO:Uploading model into container now
2023-04-20 15:35:53,644:INFO:_master_model_container: 14
2023-04-20 15:35:53,644:INFO:_display_container: 2
2023-04-20 15:35:53,649:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-20 15:35:53,649:INFO:create_model() successfully completed......................................
2023-04-20 15:35:53,819:INFO:SubProcess create_model() end ==================================
2023-04-20 15:35:53,819:INFO:Creating metrics dataframe
2023-04-20 15:35:53,849:INFO:Initializing CatBoost Classifier
2023-04-20 15:35:53,849:INFO:Total runtime is 12.505665878454844 minutes
2023-04-20 15:35:53,859:INFO:SubProcess create_model() called ==================================
2023-04-20 15:35:53,859:INFO:Initializing create_model()
2023-04-20 15:35:53,859:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CDAB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:35:53,859:INFO:Checking exceptions
2023-04-20 15:35:53,859:INFO:Importing libraries
2023-04-20 15:35:53,859:INFO:Copying training dataset
2023-04-20 15:35:53,884:INFO:Defining folds
2023-04-20 15:35:53,884:INFO:Declaring metric variables
2023-04-20 15:35:53,894:INFO:Importing untrained model
2023-04-20 15:35:53,909:INFO:CatBoost Classifier Imported successfully
2023-04-20 15:35:53,939:INFO:Starting cross validation
2023-04-20 15:35:53,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:36:20,989:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:36:21,302:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:36:23,575:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:36:30,464:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:37:02,509:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:37:05,884:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:37:12,524:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:37:42,830:INFO:Calculating mean and std
2023-04-20 15:37:42,836:INFO:Creating metrics dataframe
2023-04-20 15:37:48,014:INFO:Uploading results into container
2023-04-20 15:37:48,014:INFO:Uploading model into container now
2023-04-20 15:37:48,014:INFO:_master_model_container: 15
2023-04-20 15:37:48,014:INFO:_display_container: 2
2023-04-20 15:37:48,014:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E00F1A20>
2023-04-20 15:37:48,014:INFO:create_model() successfully completed......................................
2023-04-20 15:37:48,204:INFO:SubProcess create_model() end ==================================
2023-04-20 15:37:48,204:INFO:Creating metrics dataframe
2023-04-20 15:37:48,246:INFO:Initializing Dummy Classifier
2023-04-20 15:37:48,247:INFO:Total runtime is 14.412297721703847 minutes
2023-04-20 15:37:48,258:INFO:SubProcess create_model() called ==================================
2023-04-20 15:37:48,259:INFO:Initializing create_model()
2023-04-20 15:37:48,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D94CDAB0>, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:37:48,260:INFO:Checking exceptions
2023-04-20 15:37:48,260:INFO:Importing libraries
2023-04-20 15:37:48,260:INFO:Copying training dataset
2023-04-20 15:37:48,279:INFO:Defining folds
2023-04-20 15:37:48,279:INFO:Declaring metric variables
2023-04-20 15:37:48,289:INFO:Importing untrained model
2023-04-20 15:37:48,298:INFO:Dummy Classifier Imported successfully
2023-04-20 15:37:48,327:INFO:Starting cross validation
2023-04-20 15:37:48,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:37:49,936:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 15:37:49,949:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 15:37:49,959:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 15:37:58,413:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:37:58,505:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:37:58,544:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:37:58,556:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:37:58,710:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 15:37:58,714:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 15:37:58,730:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 15:37:58,734:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 15:38:07,366:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 15:38:07,434:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-20 15:38:30,589:INFO:Calculating mean and std
2023-04-20 15:38:30,589:INFO:Creating metrics dataframe
2023-04-20 15:38:34,908:INFO:Uploading results into container
2023-04-20 15:38:34,908:INFO:Uploading model into container now
2023-04-20 15:38:34,908:INFO:_master_model_container: 16
2023-04-20 15:38:34,908:INFO:_display_container: 2
2023-04-20 15:38:34,908:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-04-20 15:38:34,908:INFO:create_model() successfully completed......................................
2023-04-20 15:38:35,094:INFO:SubProcess create_model() end ==================================
2023-04-20 15:38:35,094:INFO:Creating metrics dataframe
2023-04-20 15:38:35,148:INFO:Initializing create_model()
2023-04-20 15:38:35,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E00F1A20>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:38:35,149:INFO:Checking exceptions
2023-04-20 15:38:35,155:INFO:Importing libraries
2023-04-20 15:38:35,155:INFO:Copying training dataset
2023-04-20 15:38:35,174:INFO:Defining folds
2023-04-20 15:38:35,174:INFO:Declaring metric variables
2023-04-20 15:38:35,175:INFO:Importing untrained model
2023-04-20 15:38:35,175:INFO:Declaring custom model
2023-04-20 15:38:35,176:INFO:CatBoost Classifier Imported successfully
2023-04-20 15:38:35,185:INFO:Cross validation set to False
2023-04-20 15:38:35,186:INFO:Fitting Model
2023-04-20 15:38:48,222:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DFB53AF0>
2023-04-20 15:38:48,222:INFO:create_model() successfully completed......................................
2023-04-20 15:38:48,543:INFO:_master_model_container: 16
2023-04-20 15:38:48,543:INFO:_display_container: 2
2023-04-20 15:38:48,543:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1DFB53AF0>
2023-04-20 15:38:48,543:INFO:compare_models() successfully completed......................................
2023-04-20 15:39:01,771:INFO:Initializing create_model()
2023-04-20 15:39:01,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1DFB53AF0>, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:39:01,772:INFO:Checking exceptions
2023-04-20 15:39:01,831:INFO:Importing libraries
2023-04-20 15:39:01,832:INFO:Copying training dataset
2023-04-20 15:39:01,857:INFO:Defining folds
2023-04-20 15:39:01,858:INFO:Declaring metric variables
2023-04-20 15:39:01,874:INFO:Importing untrained model
2023-04-20 15:39:01,874:INFO:Declaring custom model
2023-04-20 15:39:01,889:INFO:CatBoost Classifier Imported successfully
2023-04-20 15:39:01,915:INFO:Starting cross validation
2023-04-20 15:39:01,953:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:39:56,914:INFO:Initializing create_model()
2023-04-20 15:39:56,914:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1DFB53AF0>, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'iter': 50})
2023-04-20 15:39:56,915:INFO:Checking exceptions
2023-04-20 15:39:56,970:INFO:Importing libraries
2023-04-20 15:39:56,971:INFO:Copying training dataset
2023-04-20 15:39:56,988:INFO:Defining folds
2023-04-20 15:39:56,988:INFO:Declaring metric variables
2023-04-20 15:39:57,004:INFO:Importing untrained model
2023-04-20 15:39:57,005:INFO:Declaring custom model
2023-04-20 15:43:03,646:INFO:Initializing create_model()
2023-04-20 15:43:03,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1DFB53AF0>, fold=10, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:43:03,647:INFO:Checking exceptions
2023-04-20 15:43:03,710:INFO:Importing libraries
2023-04-20 15:43:03,711:INFO:Copying training dataset
2023-04-20 15:43:03,733:INFO:Defining folds
2023-04-20 15:43:03,734:INFO:Declaring metric variables
2023-04-20 15:43:03,746:INFO:Importing untrained model
2023-04-20 15:43:03,747:INFO:Declaring custom model
2023-04-20 15:43:03,758:INFO:CatBoost Classifier Imported successfully
2023-04-20 15:43:03,774:INFO:Starting cross validation
2023-04-20 15:43:03,779:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:43:57,999:INFO:Calculating mean and std
2023-04-20 15:43:58,004:INFO:Creating metrics dataframe
2023-04-20 15:43:58,021:INFO:Finalizing model
2023-04-20 15:44:02,839:INFO:Uploading results into container
2023-04-20 15:44:02,844:INFO:Uploading model into container now
2023-04-20 15:44:02,896:INFO:_master_model_container: 17
2023-04-20 15:44:02,897:INFO:_display_container: 3
2023-04-20 15:44:02,897:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2A78640>
2023-04-20 15:44:02,898:INFO:create_model() successfully completed......................................
2023-04-20 15:44:46,382:INFO:Initializing create_model()
2023-04-20 15:44:46,383:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1DFB53AF0>, fold=50, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:44:46,384:INFO:Checking exceptions
2023-04-20 15:44:46,436:INFO:Importing libraries
2023-04-20 15:44:46,437:INFO:Copying training dataset
2023-04-20 15:44:46,454:INFO:Defining folds
2023-04-20 15:44:46,454:INFO:Declaring metric variables
2023-04-20 15:44:46,462:INFO:Importing untrained model
2023-04-20 15:44:46,462:INFO:Declaring custom model
2023-04-20 15:44:46,481:INFO:CatBoost Classifier Imported successfully
2023-04-20 15:44:46,508:INFO:Starting cross validation
2023-04-20 15:44:46,516:INFO:Cross validating with StratifiedKFold(n_splits=50, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:45:14,284:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:45:14,549:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:45:51,261:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:45:51,285:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:46:33,127:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:46:33,519:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:47:16,083:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:47:16,584:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:47:16,811:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:47:17,371:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:47:27,848:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-20 15:47:28,926:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-20 15:47:28,947:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-20 15:47:29,764:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-20 15:48:11,840:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:48:12,072:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:48:12,330:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:48:13,785:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:48:26,226:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-20 15:48:26,436:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-20 15:48:26,549:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-20 15:48:28,005:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-20 15:49:02,355:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:49:03,579:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:49:03,589:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:49:04,205:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:49:50,404:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:49:51,285:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:49:52,109:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:49:53,165:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:50:42,267:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:50:43,917:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:50:45,282:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:50:45,586:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:51:30,211:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:51:31,049:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:51:59,806:INFO:Initializing create_model()
2023-04-20 15:51:59,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1DFB53AF0>, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-20 15:51:59,807:INFO:Checking exceptions
2023-04-20 15:51:59,886:INFO:Importing libraries
2023-04-20 15:51:59,887:INFO:Copying training dataset
2023-04-20 15:51:59,906:INFO:Defining folds
2023-04-20 15:51:59,906:INFO:Declaring metric variables
2023-04-20 15:51:59,972:INFO:Importing untrained model
2023-04-20 15:51:59,972:INFO:Declaring custom model
2023-04-20 15:51:59,983:INFO:CatBoost Classifier Imported successfully
2023-04-20 15:52:00,007:INFO:Starting cross validation
2023-04-20 15:52:00,016:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 15:53:02,253:INFO:Calculating mean and std
2023-04-20 15:53:02,261:INFO:Creating metrics dataframe
2023-04-20 15:53:02,271:INFO:Finalizing model
2023-04-20 15:53:07,621:INFO:Uploading results into container
2023-04-20 15:53:07,626:INFO:Uploading model into container now
2023-04-20 15:53:07,668:INFO:_master_model_container: 18
2023-04-20 15:53:07,669:INFO:_display_container: 4
2023-04-20 15:53:07,670:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2CFB640>
2023-04-20 15:53:07,670:INFO:create_model() successfully completed......................................
2023-04-20 15:53:54,933:INFO:Initializing plot_model()
2023-04-20 15:53:54,933:INFO:plot_model(plot=paramet, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E2CFB640>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, system=True)
2023-04-20 15:53:54,934:INFO:Checking exceptions
2023-04-20 15:54:09,685:INFO:Initializing plot_model()
2023-04-20 15:54:09,686:INFO:plot_model(plot=parameter, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E2CFB640>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, system=True)
2023-04-20 15:54:09,686:INFO:Checking exceptions
2023-04-20 15:54:09,699:INFO:Preloading libraries
2023-04-20 15:54:09,704:INFO:Copying training dataset
2023-04-20 15:54:09,704:INFO:Plot type: parameter
2023-04-20 15:54:09,720:INFO:Visual Rendered Successfully
2023-04-20 15:54:28,829:INFO:plot_model() successfully completed......................................
2023-04-20 15:56:00,272:INFO:Initializing tune_model()
2023-04-20 15:56:00,273:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E2CFB640>, fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>)
2023-04-20 15:56:00,273:INFO:Checking exceptions
2023-04-20 15:56:00,334:INFO:Copying training dataset
2023-04-20 15:56:00,348:INFO:Checking base model
2023-04-20 15:56:00,349:INFO:Base model : CatBoost Classifier
2023-04-20 15:56:00,368:INFO:Declaring metric variables
2023-04-20 15:56:00,376:INFO:Defining Hyperparameters
2023-04-20 15:56:00,776:INFO:Tuning with n_jobs=-1
2023-04-20 15:56:00,776:INFO:Initializing RandomizedSearchCV
2023-04-20 15:56:04,845:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:56:04,961:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:56:05,151:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:56:17,006:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:56:17,135:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:56:17,512:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:56:28,904:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:56:29,599:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:56:36,066:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:57:04,541:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:57:15,986:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:57:30,403:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:58:12,134:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:58:14,721:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 15:58:19,252:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:00:13,691:INFO:best_params: {'actual_estimator__random_strength': 0.2, 'actual_estimator__n_estimators': 180, 'actual_estimator__l2_leaf_reg': 30, 'actual_estimator__eta': 0.4, 'actual_estimator__depth': 8}
2023-04-20 16:00:13,696:INFO:Hyperparameter search completed
2023-04-20 16:00:13,696:INFO:SubProcess create_model() called ==================================
2023-04-20 16:00:13,696:INFO:Initializing create_model()
2023-04-20 16:00:13,696:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E2D11150>, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1D6B47AC0>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.2, 'n_estimators': 180, 'l2_leaf_reg': 30, 'eta': 0.4, 'depth': 8})
2023-04-20 16:00:13,696:INFO:Checking exceptions
2023-04-20 16:00:13,696:INFO:Importing libraries
2023-04-20 16:00:13,696:INFO:Copying training dataset
2023-04-20 16:00:13,721:INFO:Defining folds
2023-04-20 16:00:13,721:INFO:Declaring metric variables
2023-04-20 16:00:13,733:INFO:Importing untrained model
2023-04-20 16:00:13,734:INFO:Declaring custom model
2023-04-20 16:00:13,745:INFO:CatBoost Classifier Imported successfully
2023-04-20 16:00:13,767:INFO:Starting cross validation
2023-04-20 16:00:13,778:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 16:00:33,341:INFO:Calculating mean and std
2023-04-20 16:00:33,341:INFO:Creating metrics dataframe
2023-04-20 16:00:33,374:INFO:Finalizing model
2023-04-20 16:00:43,146:INFO:Uploading results into container
2023-04-20 16:00:43,153:INFO:Uploading model into container now
2023-04-20 16:00:43,154:INFO:_master_model_container: 19
2023-04-20 16:00:43,155:INFO:_display_container: 5
2023-04-20 16:00:43,155:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2CFB670>
2023-04-20 16:00:43,155:INFO:create_model() successfully completed......................................
2023-04-20 16:00:43,414:INFO:SubProcess create_model() end ==================================
2023-04-20 16:00:43,415:INFO:choose_better activated
2023-04-20 16:00:43,421:INFO:SubProcess create_model() called ==================================
2023-04-20 16:00:43,422:INFO:Initializing create_model()
2023-04-20 16:00:43,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E2CFB640>, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-20 16:00:43,422:INFO:Checking exceptions
2023-04-20 16:00:43,427:INFO:Importing libraries
2023-04-20 16:00:43,427:INFO:Copying training dataset
2023-04-20 16:00:43,431:INFO:Defining folds
2023-04-20 16:00:43,431:INFO:Declaring metric variables
2023-04-20 16:00:43,431:INFO:Importing untrained model
2023-04-20 16:00:43,431:INFO:Declaring custom model
2023-04-20 16:00:43,431:INFO:CatBoost Classifier Imported successfully
2023-04-20 16:00:43,431:INFO:Starting cross validation
2023-04-20 16:00:43,441:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 16:01:06,227:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:01:06,256:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:01:30,226:INFO:Calculating mean and std
2023-04-20 16:01:30,227:INFO:Creating metrics dataframe
2023-04-20 16:01:30,234:INFO:Finalizing model
2023-04-20 16:01:35,921:INFO:Uploading results into container
2023-04-20 16:01:35,921:INFO:Uploading model into container now
2023-04-20 16:01:35,921:INFO:_master_model_container: 20
2023-04-20 16:01:35,921:INFO:_display_container: 6
2023-04-20 16:01:35,921:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2A79EA0>
2023-04-20 16:01:35,921:INFO:create_model() successfully completed......................................
2023-04-20 16:01:36,141:INFO:SubProcess create_model() end ==================================
2023-04-20 16:01:36,151:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2A79EA0> result for Accuracy is 0.7714
2023-04-20 16:01:36,151:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2CFB670> result for Accuracy is 0.7519
2023-04-20 16:01:36,151:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2A79EA0> is best model
2023-04-20 16:01:36,151:INFO:choose_better completed
2023-04-20 16:01:36,151:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-20 16:01:36,175:INFO:_master_model_container: 20
2023-04-20 16:01:36,176:INFO:_display_container: 5
2023-04-20 16:01:36,176:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2A79EA0>
2023-04-20 16:01:36,176:INFO:tune_model() successfully completed......................................
2023-04-20 16:01:58,984:INFO:Initializing tune_model()
2023-04-20 16:01:58,984:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E2CFB640>, fold=20, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>)
2023-04-20 16:01:58,985:INFO:Checking exceptions
2023-04-20 16:01:59,038:INFO:Copying training dataset
2023-04-20 16:01:59,054:INFO:Checking base model
2023-04-20 16:01:59,054:INFO:Base model : CatBoost Classifier
2023-04-20 16:01:59,072:INFO:Declaring metric variables
2023-04-20 16:01:59,083:INFO:Defining Hyperparameters
2023-04-20 16:01:59,519:INFO:Tuning with n_jobs=-1
2023-04-20 16:01:59,519:INFO:Initializing RandomizedSearchCV
2023-04-20 16:02:02,896:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:02:03,076:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:02:03,079:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:02:13,773:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:02:14,113:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:02:14,133:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:02:14,311:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:02:25,798:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:02:28,323:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:02:33,572:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-20 16:02:36,219:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:05:40,886:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:06:27,136:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:10:13,556:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:10:33,753:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:10:48,595:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:11:01,532:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:11:08,887:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:11:16,468:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:11:30,251:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:11:36,137:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:11:50,399:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:11:51,570:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:18:14,032:INFO:best_params: {'actual_estimator__random_strength': 0.6, 'actual_estimator__n_estimators': 40, 'actual_estimator__l2_leaf_reg': 7, 'actual_estimator__eta': 0.3, 'actual_estimator__depth': 1}
2023-04-20 16:18:14,032:INFO:Hyperparameter search completed
2023-04-20 16:18:14,032:INFO:SubProcess create_model() called ==================================
2023-04-20 16:18:14,032:INFO:Initializing create_model()
2023-04-20 16:18:14,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E2CE98A0>, fold=StratifiedKFold(n_splits=20, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DC71F3D0>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.6, 'n_estimators': 40, 'l2_leaf_reg': 7, 'eta': 0.3, 'depth': 1})
2023-04-20 16:18:14,032:INFO:Checking exceptions
2023-04-20 16:18:14,047:INFO:Importing libraries
2023-04-20 16:18:14,047:INFO:Copying training dataset
2023-04-20 16:18:14,070:INFO:Defining folds
2023-04-20 16:18:14,070:INFO:Declaring metric variables
2023-04-20 16:18:14,070:INFO:Importing untrained model
2023-04-20 16:18:14,070:INFO:Declaring custom model
2023-04-20 16:18:14,085:INFO:CatBoost Classifier Imported successfully
2023-04-20 16:18:14,122:INFO:Starting cross validation
2023-04-20 16:18:14,133:INFO:Cross validating with StratifiedKFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 16:19:41,849:INFO:Calculating mean and std
2023-04-20 16:19:41,849:INFO:Creating metrics dataframe
2023-04-20 16:19:41,864:INFO:Finalizing model
2023-04-20 16:19:46,992:INFO:Uploading results into container
2023-04-20 16:19:47,005:INFO:Uploading model into container now
2023-04-20 16:19:47,007:INFO:_master_model_container: 21
2023-04-20 16:19:47,007:INFO:_display_container: 6
2023-04-20 16:19:47,008:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2CEB490>
2023-04-20 16:19:47,008:INFO:create_model() successfully completed......................................
2023-04-20 16:19:47,301:INFO:SubProcess create_model() end ==================================
2023-04-20 16:19:47,301:INFO:choose_better activated
2023-04-20 16:19:47,301:INFO:SubProcess create_model() called ==================================
2023-04-20 16:19:47,301:INFO:Initializing create_model()
2023-04-20 16:19:47,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E2CFB640>, fold=StratifiedKFold(n_splits=20, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-20 16:19:47,301:INFO:Checking exceptions
2023-04-20 16:19:47,317:INFO:Importing libraries
2023-04-20 16:19:47,317:INFO:Copying training dataset
2023-04-20 16:19:47,332:INFO:Defining folds
2023-04-20 16:19:47,332:INFO:Declaring metric variables
2023-04-20 16:19:47,333:INFO:Importing untrained model
2023-04-20 16:19:47,333:INFO:Declaring custom model
2023-04-20 16:19:47,334:INFO:CatBoost Classifier Imported successfully
2023-04-20 16:19:47,334:INFO:Starting cross validation
2023-04-20 16:19:47,341:INFO:Cross validating with StratifiedKFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 16:20:44,444:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:20:44,971:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:20:46,809:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:21:23,392:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:21:25,565:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:21:26,227:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:21:28,350:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:22:04,962:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:22:07,317:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:22:08,435:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:22:46,325:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:22:47,347:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:22:49,598:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:22:51,762:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:23:12,785:INFO:Calculating mean and std
2023-04-20 16:23:12,786:INFO:Creating metrics dataframe
2023-04-20 16:23:12,790:INFO:Finalizing model
2023-04-20 16:23:19,367:INFO:Uploading results into container
2023-04-20 16:23:19,368:INFO:Uploading model into container now
2023-04-20 16:23:19,369:INFO:_master_model_container: 22
2023-04-20 16:23:19,370:INFO:_display_container: 7
2023-04-20 16:23:19,370:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E1F395A0>
2023-04-20 16:23:19,370:INFO:create_model() successfully completed......................................
2023-04-20 16:23:19,700:INFO:SubProcess create_model() end ==================================
2023-04-20 16:23:19,701:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E1F395A0> result for Accuracy is 0.7549
2023-04-20 16:23:19,701:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2CEB490> result for Accuracy is 0.7457
2023-04-20 16:23:19,701:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E1F395A0> is best model
2023-04-20 16:23:19,701:INFO:choose_better completed
2023-04-20 16:23:19,702:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-20 16:23:19,744:INFO:_master_model_container: 22
2023-04-20 16:23:19,745:INFO:_display_container: 6
2023-04-20 16:23:19,745:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E1F395A0>
2023-04-20 16:23:19,746:INFO:tune_model() successfully completed......................................
2023-04-20 16:32:24,371:INFO:Initializing tune_model()
2023-04-20 16:32:24,371:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E2CFB640>, fold=20, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>)
2023-04-20 16:32:24,372:INFO:Checking exceptions
2023-04-20 16:32:24,430:INFO:Copying training dataset
2023-04-20 16:32:24,441:INFO:Checking base model
2023-04-20 16:32:24,442:INFO:Base model : CatBoost Classifier
2023-04-20 16:32:24,459:INFO:Declaring metric variables
2023-04-20 16:32:24,470:INFO:Defining Hyperparameters
2023-04-20 16:32:24,785:INFO:Tuning with n_jobs=-1
2023-04-20 16:32:24,785:INFO:Initializing RandomizedSearchCV
2023-04-20 16:32:41,942:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:32:52,352:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:32:52,358:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:32:52,370:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:32:52,698:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-20 16:46:39,081:INFO:best_params: {'actual_estimator__random_strength': 0.6, 'actual_estimator__n_estimators': 40, 'actual_estimator__l2_leaf_reg': 7, 'actual_estimator__eta': 0.3, 'actual_estimator__depth': 1}
2023-04-20 16:46:39,083:INFO:Hyperparameter search completed
2023-04-20 16:46:39,083:INFO:SubProcess create_model() called ==================================
2023-04-20 16:46:39,084:INFO:Initializing create_model()
2023-04-20 16:46:39,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E1F39390>, fold=StratifiedKFold(n_splits=20, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1E2A63E80>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.6, 'n_estimators': 40, 'l2_leaf_reg': 7, 'eta': 0.3, 'depth': 1})
2023-04-20 16:46:39,085:INFO:Checking exceptions
2023-04-20 16:46:39,085:INFO:Importing libraries
2023-04-20 16:46:39,085:INFO:Copying training dataset
2023-04-20 16:46:39,103:INFO:Defining folds
2023-04-20 16:46:39,104:INFO:Declaring metric variables
2023-04-20 16:46:39,114:INFO:Importing untrained model
2023-04-20 16:46:39,115:INFO:Declaring custom model
2023-04-20 16:46:39,134:INFO:CatBoost Classifier Imported successfully
2023-04-20 16:46:39,154:INFO:Starting cross validation
2023-04-20 16:46:39,167:INFO:Cross validating with StratifiedKFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 16:48:05,741:INFO:Calculating mean and std
2023-04-20 16:48:05,744:INFO:Creating metrics dataframe
2023-04-20 16:48:05,766:INFO:Finalizing model
2023-04-20 16:48:11,685:INFO:Uploading results into container
2023-04-20 16:48:11,689:INFO:Uploading model into container now
2023-04-20 16:48:11,691:INFO:_master_model_container: 23
2023-04-20 16:48:11,692:INFO:_display_container: 7
2023-04-20 16:48:11,692:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2A63850>
2023-04-20 16:48:11,692:INFO:create_model() successfully completed......................................
2023-04-20 16:48:11,938:INFO:SubProcess create_model() end ==================================
2023-04-20 16:48:11,938:INFO:choose_better activated
2023-04-20 16:48:11,944:INFO:SubProcess create_model() called ==================================
2023-04-20 16:48:11,945:INFO:Initializing create_model()
2023-04-20 16:48:11,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E2CFB640>, fold=StratifiedKFold(n_splits=20, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-20 16:48:11,945:INFO:Checking exceptions
2023-04-20 16:48:11,948:INFO:Importing libraries
2023-04-20 16:48:11,948:INFO:Copying training dataset
2023-04-20 16:48:11,959:INFO:Defining folds
2023-04-20 16:48:11,960:INFO:Declaring metric variables
2023-04-20 16:48:11,960:INFO:Importing untrained model
2023-04-20 16:48:11,961:INFO:Declaring custom model
2023-04-20 16:48:11,962:INFO:CatBoost Classifier Imported successfully
2023-04-20 16:48:11,963:INFO:Starting cross validation
2023-04-20 16:48:11,970:INFO:Cross validating with StratifiedKFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 16:49:37,694:INFO:Calculating mean and std
2023-04-20 16:49:37,695:INFO:Creating metrics dataframe
2023-04-20 16:49:37,699:INFO:Finalizing model
2023-04-20 16:49:44,192:INFO:Uploading results into container
2023-04-20 16:49:44,194:INFO:Uploading model into container now
2023-04-20 16:49:44,195:INFO:_master_model_container: 24
2023-04-20 16:49:44,195:INFO:_display_container: 8
2023-04-20 16:49:44,195:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2A304F0>
2023-04-20 16:49:44,195:INFO:create_model() successfully completed......................................
2023-04-20 16:49:44,445:INFO:SubProcess create_model() end ==================================
2023-04-20 16:49:44,445:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2A304F0> result for Accuracy is 0.7549
2023-04-20 16:49:44,446:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2A63850> result for Accuracy is 0.7457
2023-04-20 16:49:44,446:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2A304F0> is best model
2023-04-20 16:49:44,446:INFO:choose_better completed
2023-04-20 16:49:44,446:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-20 16:49:44,483:INFO:_master_model_container: 24
2023-04-20 16:49:44,484:INFO:_display_container: 7
2023-04-20 16:49:44,484:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2A304F0>
2023-04-20 16:49:44,485:INFO:tune_model() successfully completed......................................
2023-04-20 17:24:06,367:INFO:Initializing tune_model()
2023-04-20 17:24:06,367:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E2CFB640>, fold=20, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=False, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>)
2023-04-20 17:24:06,368:INFO:Checking exceptions
2023-04-20 17:24:06,436:INFO:Copying training dataset
2023-04-20 17:24:06,452:INFO:Checking base model
2023-04-20 17:24:06,453:INFO:Base model : CatBoost Classifier
2023-04-20 17:24:06,465:INFO:Declaring metric variables
2023-04-20 17:24:06,486:INFO:Defining Hyperparameters
2023-04-20 17:24:06,861:INFO:Tuning with n_jobs=-1
2023-04-20 17:24:06,861:INFO:Initializing RandomizedSearchCV
2023-04-20 17:39:03,759:INFO:best_params: {'actual_estimator__random_strength': 0.6, 'actual_estimator__n_estimators': 40, 'actual_estimator__l2_leaf_reg': 7, 'actual_estimator__eta': 0.3, 'actual_estimator__depth': 1}
2023-04-20 17:39:03,759:INFO:Hyperparameter search completed
2023-04-20 17:39:03,759:INFO:SubProcess create_model() called ==================================
2023-04-20 17:39:03,759:INFO:Initializing create_model()
2023-04-20 17:39:03,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E2794070>, fold=StratifiedKFold(n_splits=20, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF774F70>, model_only=True, return_train_score=True, kwargs={'random_strength': 0.6, 'n_estimators': 40, 'l2_leaf_reg': 7, 'eta': 0.3, 'depth': 1})
2023-04-20 17:39:03,759:INFO:Checking exceptions
2023-04-20 17:39:03,764:INFO:Importing libraries
2023-04-20 17:39:03,764:INFO:Copying training dataset
2023-04-20 17:39:03,794:INFO:Defining folds
2023-04-20 17:39:03,794:INFO:Declaring metric variables
2023-04-20 17:39:03,809:INFO:Importing untrained model
2023-04-20 17:39:03,809:INFO:Declaring custom model
2023-04-20 17:39:03,826:INFO:CatBoost Classifier Imported successfully
2023-04-20 17:39:03,844:INFO:Starting cross validation
2023-04-20 17:39:03,862:INFO:Cross validating with StratifiedKFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 17:40:34,808:INFO:Calculating mean and std
2023-04-20 17:40:34,808:INFO:Creating metrics dataframe
2023-04-20 17:40:34,828:INFO:Finalizing model
2023-04-20 17:40:35,251:INFO:Initializing predict_model()
2023-04-20 17:40:35,251:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001D1E27D4D00>)],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D1E2CB4280>)
2023-04-20 17:40:35,251:INFO:Checking exceptions
2023-04-20 17:40:35,251:INFO:Preloading libraries
2023-04-20 17:40:35,251:INFO:Set up data.
2023-04-20 17:40:35,267:INFO:Set up index.
2023-04-20 17:40:42,051:INFO:Uploading results into container
2023-04-20 17:40:42,067:INFO:Uploading model into container now
2023-04-20 17:40:42,067:INFO:_master_model_container: 25
2023-04-20 17:40:42,067:INFO:_display_container: 8
2023-04-20 17:40:42,067:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E27D4D00>
2023-04-20 17:40:42,067:INFO:create_model() successfully completed......................................
2023-04-20 17:40:42,332:INFO:SubProcess create_model() end ==================================
2023-04-20 17:40:42,364:INFO:_master_model_container: 25
2023-04-20 17:40:42,379:INFO:_display_container: 8
2023-04-20 17:40:42,379:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E27D4D00>
2023-04-20 17:40:42,379:INFO:tune_model() successfully completed......................................
2023-04-20 17:42:07,890:INFO:Initializing tune_model()
2023-04-20 17:42:07,890:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E2CFB640>, fold=20, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>)
2023-04-20 17:42:07,890:INFO:Checking exceptions
2023-04-20 17:42:07,942:INFO:Copying training dataset
2023-04-20 17:42:07,953:INFO:Checking base model
2023-04-20 17:42:07,953:INFO:Base model : CatBoost Classifier
2023-04-20 17:42:07,971:INFO:Declaring metric variables
2023-04-20 17:42:07,983:INFO:Defining Hyperparameters
2023-04-20 17:42:08,275:INFO:Tuning with n_jobs=-1
2023-04-20 17:42:08,275:INFO:Initializing RandomizedSearchCV
2023-04-20 17:55:37,530:INFO:best_params: {'actual_estimator__random_strength': 0.6, 'actual_estimator__n_estimators': 40, 'actual_estimator__l2_leaf_reg': 7, 'actual_estimator__eta': 0.3, 'actual_estimator__depth': 1}
2023-04-20 17:55:37,530:INFO:Hyperparameter search completed
2023-04-20 17:55:37,530:INFO:SubProcess create_model() called ==================================
2023-04-20 17:55:37,530:INFO:Initializing create_model()
2023-04-20 17:55:37,530:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E27FC160>, fold=StratifiedKFold(n_splits=20, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1DF22A980>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.6, 'n_estimators': 40, 'l2_leaf_reg': 7, 'eta': 0.3, 'depth': 1})
2023-04-20 17:55:37,530:INFO:Checking exceptions
2023-04-20 17:55:37,530:INFO:Importing libraries
2023-04-20 17:55:37,530:INFO:Copying training dataset
2023-04-20 17:55:37,571:INFO:Defining folds
2023-04-20 17:55:37,571:INFO:Declaring metric variables
2023-04-20 17:55:37,588:INFO:Importing untrained model
2023-04-20 17:55:37,594:INFO:Declaring custom model
2023-04-20 17:55:37,608:INFO:CatBoost Classifier Imported successfully
2023-04-20 17:55:37,629:INFO:Starting cross validation
2023-04-20 17:55:37,648:INFO:Cross validating with StratifiedKFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 17:57:01,889:INFO:Calculating mean and std
2023-04-20 17:57:01,889:INFO:Creating metrics dataframe
2023-04-20 17:57:01,905:INFO:Finalizing model
2023-04-20 17:57:06,500:INFO:Uploading results into container
2023-04-20 17:57:06,502:INFO:Uploading model into container now
2023-04-20 17:57:06,504:INFO:_master_model_container: 26
2023-04-20 17:57:06,505:INFO:_display_container: 9
2023-04-20 17:57:06,505:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2A784C0>
2023-04-20 17:57:06,505:INFO:create_model() successfully completed......................................
2023-04-20 17:57:06,728:INFO:SubProcess create_model() end ==================================
2023-04-20 17:57:06,728:INFO:choose_better activated
2023-04-20 17:57:06,744:INFO:SubProcess create_model() called ==================================
2023-04-20 17:57:06,744:INFO:Initializing create_model()
2023-04-20 17:57:06,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E2CFB640>, fold=StratifiedKFold(n_splits=20, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-20 17:57:06,744:INFO:Checking exceptions
2023-04-20 17:57:06,744:INFO:Importing libraries
2023-04-20 17:57:06,744:INFO:Copying training dataset
2023-04-20 17:57:06,760:INFO:Defining folds
2023-04-20 17:57:06,760:INFO:Declaring metric variables
2023-04-20 17:57:06,760:INFO:Importing untrained model
2023-04-20 17:57:06,765:INFO:Declaring custom model
2023-04-20 17:57:06,766:INFO:CatBoost Classifier Imported successfully
2023-04-20 17:57:06,767:INFO:Starting cross validation
2023-04-20 17:57:06,776:INFO:Cross validating with StratifiedKFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2023-04-20 17:58:32,787:INFO:Calculating mean and std
2023-04-20 17:58:32,802:INFO:Creating metrics dataframe
2023-04-20 17:58:32,802:INFO:Finalizing model
2023-04-20 17:58:38,405:INFO:Uploading results into container
2023-04-20 17:58:38,405:INFO:Uploading model into container now
2023-04-20 17:58:38,405:INFO:_master_model_container: 27
2023-04-20 17:58:38,405:INFO:_display_container: 10
2023-04-20 17:58:38,405:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E27ADA80>
2023-04-20 17:58:38,405:INFO:create_model() successfully completed......................................
2023-04-20 17:58:38,624:INFO:SubProcess create_model() end ==================================
2023-04-20 17:58:38,624:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E27ADA80> result for Accuracy is 0.7549
2023-04-20 17:58:38,624:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E2A784C0> result for Accuracy is 0.7457
2023-04-20 17:58:38,624:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E27ADA80> is best model
2023-04-20 17:58:38,624:INFO:choose_better completed
2023-04-20 17:58:38,624:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-20 17:58:38,664:INFO:_master_model_container: 27
2023-04-20 17:58:38,664:INFO:_display_container: 9
2023-04-20 17:58:38,665:INFO:<catboost.core.CatBoostClassifier object at 0x000001D1E27ADA80>
2023-04-20 17:58:38,666:INFO:tune_model() successfully completed......................................
2023-04-20 19:01:30,004:INFO:Initializing evaluate_model()
2023-04-20 19:01:30,004:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E2CFB640>, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-04-20 19:01:30,061:INFO:Initializing plot_model()
2023-04-20 19:01:30,061:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E2CFB640>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, system=True)
2023-04-20 19:01:30,061:INFO:Checking exceptions
2023-04-20 19:01:30,070:INFO:Preloading libraries
2023-04-20 19:01:30,075:INFO:Copying training dataset
2023-04-20 19:01:30,075:INFO:Plot type: pipeline
2023-04-20 19:01:30,716:INFO:Visual Rendered Successfully
2023-04-20 19:01:30,951:INFO:plot_model() successfully completed......................................
2023-04-20 19:01:34,483:INFO:Initializing plot_model()
2023-04-20 19:01:34,483:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001D1E2CFB640>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1E0202D10>, system=True)
2023-04-20 19:01:34,484:INFO:Checking exceptions
2023-04-20 19:01:34,491:INFO:Preloading libraries
2023-04-20 19:01:34,497:INFO:Copying training dataset
2023-04-20 19:01:34,497:INFO:Plot type: parameter
2023-04-20 19:01:34,511:INFO:Visual Rendered Successfully
2023-04-20 19:01:34,728:INFO:plot_model() successfully completed......................................
2023-04-24 11:08:07,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 11:08:07,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 11:08:07,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 11:08:07,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 11:08:10,540:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-24 11:10:31,526:INFO:PyCaret ClassificationExperiment
2023-04-24 11:10:31,526:INFO:Logging name: clf-default-name
2023-04-24 11:10:31,526:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-24 11:10:31,526:INFO:version 3.0.0
2023-04-24 11:10:31,526:INFO:Initializing setup()
2023-04-24 11:10:31,526:INFO:self.USI: 767a
2023-04-24 11:10:31,526:INFO:self._variable_keys: {'html_param', 'n_jobs_param', 'X', 'y_train', 'memory', 'log_plots_param', 'exp_id', 'gpu_n_jobs_param', '_ml_usecase', 'is_multiclass', '_available_plots', 'y_test', 'target_param', 'X_train', 'fix_imbalance', 'y', 'X_test', 'pipeline', 'exp_name_log', 'fold_groups_param', 'USI', 'fold_generator', 'logging_param', 'fold_shuffle_param', 'gpu_param', 'data', 'idx', 'seed'}
2023-04-24 11:10:31,526:INFO:Checking environment
2023-04-24 11:10:31,526:INFO:python_version: 3.10.9
2023-04-24 11:10:31,526:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-04-24 11:10:31,526:INFO:machine: AMD64
2023-04-24 11:10:31,526:INFO:platform: Windows-10-10.0.19044-SP0
2023-04-24 11:10:31,526:INFO:Memory: svmem(total=8483184640, available=3682484224, percent=56.6, used=4800700416, free=3682484224)
2023-04-24 11:10:31,526:INFO:Physical Core: 2
2023-04-24 11:10:31,526:INFO:Logical Core: 4
2023-04-24 11:10:31,526:INFO:Checking libraries
2023-04-24 11:10:31,526:INFO:System:
2023-04-24 11:10:31,526:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-04-24 11:10:31,526:INFO:executable: C:\Users\User\.conda\envs\My_envI\python.exe
2023-04-24 11:10:31,526:INFO:   machine: Windows-10-10.0.19044-SP0
2023-04-24 11:10:31,526:INFO:PyCaret required dependencies:
2023-04-24 11:10:31,526:INFO:                 pip: 22.3.1
2023-04-24 11:10:31,526:INFO:          setuptools: 66.0.0
2023-04-24 11:10:31,526:INFO:             pycaret: 3.0.0
2023-04-24 11:10:31,526:INFO:             IPython: 8.12.0
2023-04-24 11:10:31,526:INFO:          ipywidgets: 7.6.5
2023-04-24 11:10:31,526:INFO:                tqdm: 4.64.1
2023-04-24 11:10:31,526:INFO:               numpy: 1.23.5
2023-04-24 11:10:31,526:INFO:              pandas: 1.5.3
2023-04-24 11:10:31,526:INFO:              jinja2: 3.1.2
2023-04-24 11:10:31,526:INFO:               scipy: 1.10.1
2023-04-24 11:10:31,526:INFO:              joblib: 1.2.0
2023-04-24 11:10:31,526:INFO:             sklearn: 1.2.1
2023-04-24 11:10:31,526:INFO:                pyod: 1.0.9
2023-04-24 11:10:31,526:INFO:            imblearn: 0.10.1
2023-04-24 11:10:31,526:INFO:   category_encoders: 2.6.0
2023-04-24 11:10:31,526:INFO:            lightgbm: 3.3.5
2023-04-24 11:10:31,526:INFO:               numba: 0.56.4
2023-04-24 11:10:31,526:INFO:            requests: 2.28.1
2023-04-24 11:10:31,526:INFO:          matplotlib: 3.7.0
2023-04-24 11:10:31,526:INFO:          scikitplot: 0.3.7
2023-04-24 11:10:31,526:INFO:         yellowbrick: 1.5
2023-04-24 11:10:31,526:INFO:              plotly: 5.14.1
2023-04-24 11:10:31,526:INFO:             kaleido: 0.2.1
2023-04-24 11:10:31,526:INFO:         statsmodels: 0.13.5
2023-04-24 11:10:31,526:INFO:              sktime: 0.17.0
2023-04-24 11:10:31,526:INFO:               tbats: 1.1.2
2023-04-24 11:10:31,526:INFO:            pmdarima: 2.0.3
2023-04-24 11:10:31,526:INFO:              psutil: 5.9.0
2023-04-24 11:10:31,526:INFO:PyCaret optional dependencies:
2023-04-24 11:10:32,775:INFO:                shap: 0.41.0
2023-04-24 11:10:32,775:INFO:           interpret: 0.3.2
2023-04-24 11:10:32,775:INFO:                umap: 0.5.3
2023-04-24 11:10:32,775:INFO:    pandas_profiling: 4.1.2
2023-04-24 11:10:32,775:INFO:  explainerdashboard: 0.4.2.1
2023-04-24 11:10:32,775:INFO:             autoviz: 0.1.58
2023-04-24 11:10:32,775:INFO:           fairlearn: 0.7.0
2023-04-24 11:10:32,775:INFO:             xgboost: 1.7.5
2023-04-24 11:10:32,775:INFO:            catboost: 1.1.1
2023-04-24 11:10:32,775:INFO:              kmodes: 0.12.2
2023-04-24 11:10:32,775:INFO:             mlxtend: 0.22.0
2023-04-24 11:10:32,775:INFO:       statsforecast: 1.5.0
2023-04-24 11:10:32,775:INFO:        tune_sklearn: 0.4.5
2023-04-24 11:10:32,775:INFO:                 ray: 2.3.1
2023-04-24 11:10:32,775:INFO:            hyperopt: 0.2.7
2023-04-24 11:10:32,775:INFO:              optuna: 3.1.0
2023-04-24 11:10:32,775:INFO:               skopt: 0.9.0
2023-04-24 11:10:32,775:INFO:              mlflow: 1.30.1
2023-04-24 11:10:32,775:INFO:              gradio: Not installed
2023-04-24 11:10:32,775:INFO:             fastapi: 0.89.1
2023-04-24 11:10:32,775:INFO:             uvicorn: 0.21.1
2023-04-24 11:10:32,775:INFO:              m2cgen: 0.10.0
2023-04-24 11:10:32,775:INFO:           evidently: 0.2.8
2023-04-24 11:10:32,775:INFO:               fugue: 0.8.3
2023-04-24 11:10:32,775:INFO:           streamlit: Not installed
2023-04-24 11:10:32,775:INFO:             prophet: Not installed
2023-04-24 11:10:32,775:INFO:None
2023-04-24 11:10:32,775:INFO:Set up data.
2023-04-24 11:10:32,791:INFO:Set up train/test split.
2023-04-24 11:10:32,807:INFO:Set up index.
2023-04-24 11:10:32,822:INFO:Set up folding strategy.
2023-04-24 11:10:32,822:INFO:Assigning column types.
2023-04-24 11:10:32,822:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-24 11:10:32,900:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 11:10:32,900:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-24 11:10:32,963:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 11:10:33,665:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 11:10:33,946:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 11:10:33,946:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-24 11:10:33,993:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 11:10:33,993:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 11:10:33,993:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-24 11:10:34,070:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-24 11:10:34,117:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 11:10:34,117:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 11:10:34,179:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-24 11:10:34,226:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 11:10:34,226:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 11:10:34,226:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-24 11:10:34,351:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 11:10:34,351:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 11:10:34,476:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 11:10:34,476:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 11:10:34,492:INFO:Preparing preprocessing pipeline...
2023-04-24 11:10:34,492:INFO:Set up label encoding.
2023-04-24 11:10:34,492:INFO:Set up simple imputation.
2023-04-24 11:10:34,492:INFO:Set up encoding of ordinal features.
2023-04-24 11:10:34,507:INFO:Set up encoding of categorical features.
2023-04-24 11:10:34,507:INFO:Set up imbalanced handling.
2023-04-24 11:10:34,507:INFO:Set up feature normalization.
2023-04-24 11:10:35,334:INFO:Finished creating preprocessing pipeline.
2023-04-24 11:10:35,397:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2023-04-24 11:10:35,397:INFO:Creating final display dataframe.
2023-04-24 11:10:36,489:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             class
2                   Target type            Binary
3                Target mapping   bad: 0, good: 1
4           Original data shape         (950, 22)
5        Transformed data shape        (1217, 50)
6   Transformed train set shape         (932, 50)
7    Transformed test set shape         (285, 50)
8              Ordinal features                 3
9              Numeric features                10
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19                    Normalize              True
20             Normalize method            minmax
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              767a
2023-04-24 11:10:36,633:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 11:10:36,649:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 11:10:36,758:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 11:10:36,774:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 11:10:36,774:INFO:setup() successfully completed in 8.82s...............
2023-04-24 11:10:52,940:INFO:Initializing get_config()
2023-04-24 11:10:52,941:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, variable=X_transformed)
2023-04-24 11:10:53,095:INFO:Variable: X returned as      checking_status  duration  credit_history_critical/other existing credit  \
405         0.333333  0.035714                                            1.0   
802         0.000000  0.142857                                            1.0   
368         0.000000  0.250000                                            0.0   
503         0.000000  0.303571                                            1.0   
619         0.333333  0.035714                                            1.0   
..               ...       ...                                            ...   
416         0.000000  0.250000                                            1.0   
771         0.000000  0.321429                                            0.0   
319         0.000000  0.250000                                            0.0   
219         0.333333  0.142857                                            0.0   
311         0.000000  0.357143                                            0.0   

     credit_history_existing paid  credit_history_delayed previously  \
405                           0.0                                0.0   
802                           0.0                                0.0   
368                           1.0                                0.0   
503                           0.0                                0.0   
619                           0.0                                0.0   
..                            ...                                ...   
416                           0.0                                0.0   
771                           1.0                                0.0   
319                           1.0                                0.0   
219                           1.0                                0.0   
311                           1.0                                0.0   

     credit_history_all paid  credit_history_no credits/all paid  \
405                      0.0                                 0.0   
802                      0.0                                 0.0   
368                      0.0                                 0.0   
503                      0.0                                 0.0   
619                      0.0                                 0.0   
..                       ...                                 ...   
416                      0.0                                 0.0   
771                      0.0                                 0.0   
319                      0.0                                 0.0   
219                      0.0                                 0.0   
311                      0.0                                 0.0   

     purpose_radio/tv  purpose_furniture/equipment  purpose_new car  ...  \
405               1.0                          0.0              0.0  ...   
802               0.0                          1.0              0.0  ...   
368               0.0                          1.0              0.0  ...   
503               0.0                          0.0              1.0  ...   
619               0.0                          0.0              1.0  ...   
..                ...                          ...              ...  ...   
416               0.0                          0.0              1.0  ...   
771               0.0                          0.0              1.0  ...   
319               0.0                          0.0              1.0  ...   
219               1.0                          0.0              0.0  ...   
311               0.0                          0.0              1.0  ...   

     job_unskilled resident  job_unemp/unskilled non res  num_dependents  \
405                     0.0                          0.0             0.0   
802                     0.0                          0.0             0.0   
368                     0.0                          0.0             0.0   
503                     0.0                          0.0             0.0   
619                     0.0                          0.0             0.0   
..                      ...                          ...             ...   
416                     0.0                          0.0             0.0   
771                     0.0                          0.0             0.0   
319                     0.0                          0.0             0.0   
219                     1.0                          0.0             0.0   
311                     0.0                          0.0             0.0   

     own_telephone  foreign_worker  sex  marital_status_single  \
405            0.0             1.0  1.0                    1.0   
802            1.0             1.0  0.0                    0.0   
368            1.0             1.0  1.0                    1.0   
503            1.0             1.0  1.0                    1.0   
619            1.0             1.0  0.0                    0.0   
..             ...             ...  ...                    ...   
416            0.0             1.0  1.0                    1.0   
771            0.0             1.0  0.0                    0.0   
319            0.0             0.0  1.0                    1.0   
219            0.0             1.0  1.0                    0.0   
311            1.0             1.0  0.0                    0.0   

     marital_status_div/dep/mar  marital_status_mar/wid  \
405                         0.0                     0.0   
802                         1.0                     0.0   
368                         0.0                     0.0   
503                         0.0                     0.0   
619                         1.0                     0.0   
..                          ...                     ...   
416                         0.0                     0.0   
771                         1.0                     0.0   
319                         0.0                     0.0   
219                         0.0                     1.0   
311                         1.0                     0.0   

     marital_status_div/sep  
405                     0.0  
802                     0.0  
368                     0.0  
503                     0.0  
619                     0.0  
..                      ...  
416                     0.0  
771                     0.0  
319                     0.0  
219                     0.0  
311                     0.0  

[1217 rows x 49 columns]
2023-04-24 11:10:53,095:INFO:get_config() successfully completed......................................
2023-04-24 11:11:01,351:INFO:Initializing compare_models()
2023-04-24 11:11:01,352:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-24 11:11:01,352:INFO:Checking exceptions
2023-04-24 11:11:01,366:INFO:Preparing display monitor
2023-04-24 11:11:01,456:INFO:Initializing Logistic Regression
2023-04-24 11:11:01,457:INFO:Total runtime is 1.6697247823079427e-05 minutes
2023-04-24 11:11:01,466:INFO:SubProcess create_model() called ==================================
2023-04-24 11:11:01,467:INFO:Initializing create_model()
2023-04-24 11:11:01,468:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE2B1418D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:11:01,468:INFO:Checking exceptions
2023-04-24 11:11:01,469:INFO:Importing libraries
2023-04-24 11:11:01,469:INFO:Copying training dataset
2023-04-24 11:11:01,489:INFO:Defining folds
2023-04-24 11:11:01,489:INFO:Declaring metric variables
2023-04-24 11:11:01,492:INFO:Importing untrained model
2023-04-24 11:11:01,514:INFO:Logistic Regression Imported successfully
2023-04-24 11:11:01,536:INFO:Starting cross validation
2023-04-24 11:11:01,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:11:17,849:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:11:30,724:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:11:31,084:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:12:13,722:INFO:Calculating mean and std
2023-04-24 11:12:13,722:INFO:Creating metrics dataframe
2023-04-24 11:12:22,368:INFO:Uploading results into container
2023-04-24 11:12:22,368:INFO:Uploading model into container now
2023-04-24 11:12:22,368:INFO:_master_model_container: 1
2023-04-24 11:12:22,368:INFO:_display_container: 2
2023-04-24 11:12:22,368:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 11:12:22,368:INFO:create_model() successfully completed......................................
2023-04-24 11:12:22,532:INFO:SubProcess create_model() end ==================================
2023-04-24 11:12:22,532:INFO:Creating metrics dataframe
2023-04-24 11:12:22,543:INFO:Initializing K Neighbors Classifier
2023-04-24 11:12:22,543:INFO:Total runtime is 1.3514549692471822 minutes
2023-04-24 11:12:22,566:INFO:SubProcess create_model() called ==================================
2023-04-24 11:12:22,567:INFO:Initializing create_model()
2023-04-24 11:12:22,567:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE2B1418D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:12:22,568:INFO:Checking exceptions
2023-04-24 11:12:22,568:INFO:Importing libraries
2023-04-24 11:12:22,568:INFO:Copying training dataset
2023-04-24 11:12:22,584:INFO:Defining folds
2023-04-24 11:12:22,585:INFO:Declaring metric variables
2023-04-24 11:12:22,594:INFO:Importing untrained model
2023-04-24 11:12:22,610:INFO:K Neighbors Classifier Imported successfully
2023-04-24 11:12:22,627:INFO:Starting cross validation
2023-04-24 11:12:22,627:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:12:36,965:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:13:19,154:INFO:Calculating mean and std
2023-04-24 11:13:19,154:INFO:Creating metrics dataframe
2023-04-24 11:13:27,452:INFO:Uploading results into container
2023-04-24 11:13:27,452:INFO:Uploading model into container now
2023-04-24 11:13:27,468:INFO:_master_model_container: 2
2023-04-24 11:13:27,468:INFO:_display_container: 2
2023-04-24 11:13:27,471:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-24 11:13:27,471:INFO:create_model() successfully completed......................................
2023-04-24 11:13:27,608:INFO:SubProcess create_model() end ==================================
2023-04-24 11:13:27,608:INFO:Creating metrics dataframe
2023-04-24 11:13:27,624:INFO:Initializing Naive Bayes
2023-04-24 11:13:27,624:INFO:Total runtime is 2.4361337502797444 minutes
2023-04-24 11:13:27,648:INFO:SubProcess create_model() called ==================================
2023-04-24 11:13:27,649:INFO:Initializing create_model()
2023-04-24 11:13:27,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE2B1418D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:13:27,650:INFO:Checking exceptions
2023-04-24 11:13:27,651:INFO:Importing libraries
2023-04-24 11:13:27,651:INFO:Copying training dataset
2023-04-24 11:13:27,666:INFO:Defining folds
2023-04-24 11:13:27,667:INFO:Declaring metric variables
2023-04-24 11:13:27,679:INFO:Importing untrained model
2023-04-24 11:13:27,690:INFO:Naive Bayes Imported successfully
2023-04-24 11:13:27,714:INFO:Starting cross validation
2023-04-24 11:13:27,714:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:13:41,799:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:13:41,830:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:14:24,293:INFO:Calculating mean and std
2023-04-24 11:14:24,293:INFO:Creating metrics dataframe
2023-04-24 11:14:32,050:INFO:Uploading results into container
2023-04-24 11:14:32,065:INFO:Uploading model into container now
2023-04-24 11:14:32,065:INFO:_master_model_container: 3
2023-04-24 11:14:32,065:INFO:_display_container: 2
2023-04-24 11:14:32,065:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-24 11:14:32,065:INFO:create_model() successfully completed......................................
2023-04-24 11:14:32,213:INFO:SubProcess create_model() end ==================================
2023-04-24 11:14:32,213:INFO:Creating metrics dataframe
2023-04-24 11:14:32,229:INFO:Initializing Decision Tree Classifier
2023-04-24 11:14:32,229:INFO:Total runtime is 3.5128819227218626 minutes
2023-04-24 11:14:32,244:INFO:SubProcess create_model() called ==================================
2023-04-24 11:14:32,244:INFO:Initializing create_model()
2023-04-24 11:14:32,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE2B1418D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:14:32,244:INFO:Checking exceptions
2023-04-24 11:14:32,244:INFO:Importing libraries
2023-04-24 11:14:32,244:INFO:Copying training dataset
2023-04-24 11:14:32,264:INFO:Defining folds
2023-04-24 11:14:32,265:INFO:Declaring metric variables
2023-04-24 11:14:32,276:INFO:Importing untrained model
2023-04-24 11:14:32,289:INFO:Decision Tree Classifier Imported successfully
2023-04-24 11:14:32,311:INFO:Starting cross validation
2023-04-24 11:14:32,322:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:15:31,297:INFO:Calculating mean and std
2023-04-24 11:15:31,297:INFO:Creating metrics dataframe
2023-04-24 11:15:37,945:INFO:Uploading results into container
2023-04-24 11:15:37,945:INFO:Uploading model into container now
2023-04-24 11:15:37,945:INFO:_master_model_container: 4
2023-04-24 11:15:37,945:INFO:_display_container: 2
2023-04-24 11:15:37,950:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-04-24 11:15:37,951:INFO:create_model() successfully completed......................................
2023-04-24 11:15:38,086:INFO:SubProcess create_model() end ==================================
2023-04-24 11:15:38,086:INFO:Creating metrics dataframe
2023-04-24 11:15:38,117:INFO:Initializing SVM - Linear Kernel
2023-04-24 11:15:38,117:INFO:Total runtime is 4.61102522611618 minutes
2023-04-24 11:15:38,117:INFO:SubProcess create_model() called ==================================
2023-04-24 11:15:38,117:INFO:Initializing create_model()
2023-04-24 11:15:38,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE2B1418D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:15:38,117:INFO:Checking exceptions
2023-04-24 11:15:38,117:INFO:Importing libraries
2023-04-24 11:15:38,128:INFO:Copying training dataset
2023-04-24 11:15:38,145:INFO:Defining folds
2023-04-24 11:15:38,145:INFO:Declaring metric variables
2023-04-24 11:15:38,157:INFO:Importing untrained model
2023-04-24 11:15:38,166:INFO:SVM - Linear Kernel Imported successfully
2023-04-24 11:15:38,190:INFO:Starting cross validation
2023-04-24 11:15:38,208:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:15:39,787:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-24 11:15:39,943:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-24 11:15:51,495:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:15:51,495:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-24 11:15:51,495:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-24 11:15:51,511:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-24 11:15:51,713:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:15:51,760:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-24 11:16:01,436:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-24 11:16:01,452:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-24 11:16:35,693:INFO:Calculating mean and std
2023-04-24 11:16:35,693:INFO:Creating metrics dataframe
2023-04-24 11:16:42,280:INFO:Uploading results into container
2023-04-24 11:16:42,296:INFO:Uploading model into container now
2023-04-24 11:16:42,296:INFO:_master_model_container: 5
2023-04-24 11:16:42,298:INFO:_display_container: 2
2023-04-24 11:16:42,300:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-24 11:16:42,300:INFO:create_model() successfully completed......................................
2023-04-24 11:16:42,440:INFO:SubProcess create_model() end ==================================
2023-04-24 11:16:42,440:INFO:Creating metrics dataframe
2023-04-24 11:16:42,456:INFO:Initializing Ridge Classifier
2023-04-24 11:16:42,456:INFO:Total runtime is 5.683339862028757 minutes
2023-04-24 11:16:42,472:INFO:SubProcess create_model() called ==================================
2023-04-24 11:16:42,472:INFO:Initializing create_model()
2023-04-24 11:16:42,472:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE2B1418D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:16:42,472:INFO:Checking exceptions
2023-04-24 11:16:42,472:INFO:Importing libraries
2023-04-24 11:16:42,472:INFO:Copying training dataset
2023-04-24 11:16:42,494:INFO:Defining folds
2023-04-24 11:16:42,495:INFO:Declaring metric variables
2023-04-24 11:16:42,504:INFO:Importing untrained model
2023-04-24 11:16:42,517:INFO:Ridge Classifier Imported successfully
2023-04-24 11:16:42,542:INFO:Starting cross validation
2023-04-24 11:16:42,550:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:16:44,032:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-24 11:16:44,094:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-24 11:16:44,141:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-24 11:16:44,422:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-24 11:16:56,250:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-24 11:16:56,281:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-24 11:16:56,422:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:16:56,437:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-24 11:16:56,577:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-24 11:17:06,363:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-24 11:17:06,410:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-24 11:17:39,777:INFO:Calculating mean and std
2023-04-24 11:17:39,777:INFO:Creating metrics dataframe
2023-04-24 11:17:46,364:INFO:Uploading results into container
2023-04-24 11:17:46,364:INFO:Uploading model into container now
2023-04-24 11:17:46,364:INFO:_master_model_container: 6
2023-04-24 11:17:46,364:INFO:_display_container: 2
2023-04-24 11:17:46,364:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-04-24 11:17:46,364:INFO:create_model() successfully completed......................................
2023-04-24 11:17:46,522:INFO:SubProcess create_model() end ==================================
2023-04-24 11:17:46,522:INFO:Creating metrics dataframe
2023-04-24 11:17:46,536:INFO:Initializing Random Forest Classifier
2023-04-24 11:17:46,536:INFO:Total runtime is 6.751332382361094 minutes
2023-04-24 11:17:46,553:INFO:SubProcess create_model() called ==================================
2023-04-24 11:17:46,554:INFO:Initializing create_model()
2023-04-24 11:17:46,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE2B1418D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:17:46,554:INFO:Checking exceptions
2023-04-24 11:17:46,555:INFO:Importing libraries
2023-04-24 11:17:46,555:INFO:Copying training dataset
2023-04-24 11:17:46,569:INFO:Defining folds
2023-04-24 11:17:46,569:INFO:Declaring metric variables
2023-04-24 11:17:46,578:INFO:Importing untrained model
2023-04-24 11:17:46,592:INFO:Random Forest Classifier Imported successfully
2023-04-24 11:17:46,618:INFO:Starting cross validation
2023-04-24 11:17:46,629:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:17:49,877:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:17:49,908:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:17:50,143:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:17:50,236:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:18:02,238:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 11:18:02,253:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 11:18:02,316:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 11:18:02,878:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 11:18:03,877:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:18:03,986:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:18:04,033:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:18:04,546:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:18:15,659:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 11:18:17,023:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:18:17,101:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:18:49,621:INFO:Calculating mean and std
2023-04-24 11:18:49,621:INFO:Creating metrics dataframe
2023-04-24 11:18:56,566:INFO:Uploading results into container
2023-04-24 11:18:56,582:INFO:Uploading model into container now
2023-04-24 11:18:56,582:INFO:_master_model_container: 7
2023-04-24 11:18:56,582:INFO:_display_container: 2
2023-04-24 11:18:56,587:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-24 11:18:56,589:INFO:create_model() successfully completed......................................
2023-04-24 11:18:56,826:INFO:SubProcess create_model() end ==================================
2023-04-24 11:18:56,826:INFO:Creating metrics dataframe
2023-04-24 11:18:56,873:INFO:Initializing Quadratic Discriminant Analysis
2023-04-24 11:18:56,873:INFO:Total runtime is 7.92362490495046 minutes
2023-04-24 11:18:56,894:INFO:SubProcess create_model() called ==================================
2023-04-24 11:18:56,895:INFO:Initializing create_model()
2023-04-24 11:18:56,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE2B1418D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:18:56,897:INFO:Checking exceptions
2023-04-24 11:18:56,898:INFO:Importing libraries
2023-04-24 11:18:56,898:INFO:Copying training dataset
2023-04-24 11:18:56,918:INFO:Defining folds
2023-04-24 11:18:56,919:INFO:Declaring metric variables
2023-04-24 11:18:56,934:INFO:Importing untrained model
2023-04-24 11:18:56,952:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-24 11:18:56,981:INFO:Starting cross validation
2023-04-24 11:18:56,986:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:18:57,895:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-24 11:18:57,895:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-24 11:19:09,070:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-24 11:19:09,195:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-24 11:19:09,242:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-24 11:19:09,257:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-24 11:19:10,146:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:19:10,318:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:19:19,979:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-24 11:19:20,150:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-24 11:19:53,510:INFO:Calculating mean and std
2023-04-24 11:19:53,518:INFO:Creating metrics dataframe
2023-04-24 11:20:00,448:INFO:Uploading results into container
2023-04-24 11:20:00,448:INFO:Uploading model into container now
2023-04-24 11:20:00,448:INFO:_master_model_container: 8
2023-04-24 11:20:00,448:INFO:_display_container: 2
2023-04-24 11:20:00,460:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-24 11:20:00,461:INFO:create_model() successfully completed......................................
2023-04-24 11:20:00,636:INFO:SubProcess create_model() end ==================================
2023-04-24 11:20:00,636:INFO:Creating metrics dataframe
2023-04-24 11:20:00,651:INFO:Initializing Ada Boost Classifier
2023-04-24 11:20:00,651:INFO:Total runtime is 8.986596369743348 minutes
2023-04-24 11:20:00,672:INFO:SubProcess create_model() called ==================================
2023-04-24 11:20:00,673:INFO:Initializing create_model()
2023-04-24 11:20:00,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE2B1418D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:20:00,674:INFO:Checking exceptions
2023-04-24 11:20:00,675:INFO:Importing libraries
2023-04-24 11:20:00,675:INFO:Copying training dataset
2023-04-24 11:20:00,694:INFO:Defining folds
2023-04-24 11:20:00,695:INFO:Declaring metric variables
2023-04-24 11:20:00,705:INFO:Importing untrained model
2023-04-24 11:20:00,729:INFO:Ada Boost Classifier Imported successfully
2023-04-24 11:20:00,749:INFO:Starting cross validation
2023-04-24 11:20:00,765:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:20:03,492:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:20:16,633:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:20:16,727:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:20:16,821:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:20:17,227:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:20:28,556:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:20:28,791:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:21:00,520:INFO:Calculating mean and std
2023-04-24 11:21:00,520:INFO:Creating metrics dataframe
2023-04-24 11:21:08,887:INFO:Uploading results into container
2023-04-24 11:21:08,887:INFO:Uploading model into container now
2023-04-24 11:21:08,887:INFO:_master_model_container: 9
2023-04-24 11:21:08,902:INFO:_display_container: 2
2023-04-24 11:21:08,902:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-04-24 11:21:08,902:INFO:create_model() successfully completed......................................
2023-04-24 11:21:09,055:INFO:SubProcess create_model() end ==================================
2023-04-24 11:21:09,055:INFO:Creating metrics dataframe
2023-04-24 11:21:09,086:INFO:Initializing Gradient Boosting Classifier
2023-04-24 11:21:09,086:INFO:Total runtime is 10.12717382113139 minutes
2023-04-24 11:21:09,106:INFO:SubProcess create_model() called ==================================
2023-04-24 11:21:09,106:INFO:Initializing create_model()
2023-04-24 11:21:09,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE2B1418D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:21:09,108:INFO:Checking exceptions
2023-04-24 11:21:09,108:INFO:Importing libraries
2023-04-24 11:21:09,108:INFO:Copying training dataset
2023-04-24 11:21:09,121:INFO:Defining folds
2023-04-24 11:21:09,122:INFO:Declaring metric variables
2023-04-24 11:21:09,129:INFO:Importing untrained model
2023-04-24 11:21:09,144:INFO:Gradient Boosting Classifier Imported successfully
2023-04-24 11:21:09,160:INFO:Starting cross validation
2023-04-24 11:21:09,160:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:21:12,649:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:21:12,758:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:21:28,553:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:21:28,710:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:21:28,897:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:21:28,913:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:21:40,961:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:21:41,148:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:22:13,235:INFO:Calculating mean and std
2023-04-24 11:22:13,235:INFO:Creating metrics dataframe
2023-04-24 11:22:19,697:INFO:Uploading results into container
2023-04-24 11:22:19,697:INFO:Uploading model into container now
2023-04-24 11:22:19,697:INFO:_master_model_container: 10
2023-04-24 11:22:19,697:INFO:_display_container: 2
2023-04-24 11:22:19,697:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-24 11:22:19,697:INFO:create_model() successfully completed......................................
2023-04-24 11:22:19,838:INFO:SubProcess create_model() end ==================================
2023-04-24 11:22:19,838:INFO:Creating metrics dataframe
2023-04-24 11:22:19,854:INFO:Initializing Linear Discriminant Analysis
2023-04-24 11:22:19,854:INFO:Total runtime is 11.306637271245322 minutes
2023-04-24 11:22:19,878:INFO:SubProcess create_model() called ==================================
2023-04-24 11:22:19,879:INFO:Initializing create_model()
2023-04-24 11:22:19,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE2B1418D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:22:19,880:INFO:Checking exceptions
2023-04-24 11:22:19,880:INFO:Importing libraries
2023-04-24 11:22:19,880:INFO:Copying training dataset
2023-04-24 11:22:19,893:INFO:Defining folds
2023-04-24 11:22:19,893:INFO:Declaring metric variables
2023-04-24 11:22:19,903:INFO:Importing untrained model
2023-04-24 11:22:19,908:INFO:Linear Discriminant Analysis Imported successfully
2023-04-24 11:22:19,931:INFO:Starting cross validation
2023-04-24 11:22:19,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:22:33,184:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:22:33,511:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:23:19,928:INFO:Calculating mean and std
2023-04-24 11:23:19,928:INFO:Creating metrics dataframe
2023-04-24 11:23:26,283:INFO:Uploading results into container
2023-04-24 11:23:26,284:INFO:Uploading model into container now
2023-04-24 11:23:26,285:INFO:_master_model_container: 11
2023-04-24 11:23:26,286:INFO:_display_container: 2
2023-04-24 11:23:26,287:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-24 11:23:26,287:INFO:create_model() successfully completed......................................
2023-04-24 11:23:26,521:INFO:SubProcess create_model() end ==================================
2023-04-24 11:23:26,521:INFO:Creating metrics dataframe
2023-04-24 11:23:26,563:INFO:Initializing Extra Trees Classifier
2023-04-24 11:23:26,563:INFO:Total runtime is 12.41844753821691 minutes
2023-04-24 11:23:26,576:INFO:SubProcess create_model() called ==================================
2023-04-24 11:23:26,577:INFO:Initializing create_model()
2023-04-24 11:23:26,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE2B1418D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:23:26,578:INFO:Checking exceptions
2023-04-24 11:23:26,579:INFO:Importing libraries
2023-04-24 11:23:26,580:INFO:Copying training dataset
2023-04-24 11:23:26,601:INFO:Defining folds
2023-04-24 11:23:26,602:INFO:Declaring metric variables
2023-04-24 11:23:26,616:INFO:Importing untrained model
2023-04-24 11:23:26,629:INFO:Extra Trees Classifier Imported successfully
2023-04-24 11:23:26,664:INFO:Starting cross validation
2023-04-24 11:23:26,672:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:23:30,865:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:23:30,891:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:23:30,977:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:23:31,091:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:23:47,210:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 11:23:47,266:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 11:23:47,388:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 11:23:47,390:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 11:23:49,483:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:23:49,516:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:23:49,631:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:23:49,664:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:24:02,055:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 11:24:02,228:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 11:24:03,648:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:24:03,805:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:24:41,977:INFO:Calculating mean and std
2023-04-24 11:24:41,980:INFO:Creating metrics dataframe
2023-04-24 11:24:50,600:INFO:Uploading results into container
2023-04-24 11:24:50,602:INFO:Uploading model into container now
2023-04-24 11:24:50,604:INFO:_master_model_container: 12
2023-04-24 11:24:50,606:INFO:_display_container: 2
2023-04-24 11:24:50,608:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-04-24 11:24:50,608:INFO:create_model() successfully completed......................................
2023-04-24 11:24:50,903:INFO:SubProcess create_model() end ==================================
2023-04-24 11:24:50,904:INFO:Creating metrics dataframe
2023-04-24 11:24:50,976:INFO:Initializing Extreme Gradient Boosting
2023-04-24 11:24:50,977:INFO:Total runtime is 13.825358506043752 minutes
2023-04-24 11:24:50,993:INFO:SubProcess create_model() called ==================================
2023-04-24 11:24:50,996:INFO:Initializing create_model()
2023-04-24 11:24:50,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE2B1418D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:24:50,998:INFO:Checking exceptions
2023-04-24 11:24:50,998:INFO:Importing libraries
2023-04-24 11:24:50,999:INFO:Copying training dataset
2023-04-24 11:24:51,035:INFO:Defining folds
2023-04-24 11:24:51,036:INFO:Declaring metric variables
2023-04-24 11:24:51,055:INFO:Importing untrained model
2023-04-24 11:24:51,073:INFO:Extreme Gradient Boosting Imported successfully
2023-04-24 11:24:51,118:INFO:Starting cross validation
2023-04-24 11:24:51,137:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:25:10,307:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:25:10,401:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:25:10,586:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:25:10,711:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:25:25,737:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:25:25,816:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:26:01,745:INFO:Calculating mean and std
2023-04-24 11:26:01,745:INFO:Creating metrics dataframe
2023-04-24 11:26:12,107:INFO:Uploading results into container
2023-04-24 11:26:12,109:INFO:Uploading model into container now
2023-04-24 11:26:12,111:INFO:_master_model_container: 13
2023-04-24 11:26:12,111:INFO:_display_container: 2
2023-04-24 11:26:12,116:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-24 11:26:12,117:INFO:create_model() successfully completed......................................
2023-04-24 11:26:12,375:INFO:SubProcess create_model() end ==================================
2023-04-24 11:26:12,376:INFO:Creating metrics dataframe
2023-04-24 11:26:12,437:INFO:Initializing Light Gradient Boosting Machine
2023-04-24 11:26:12,438:INFO:Total runtime is 15.183038306236266 minutes
2023-04-24 11:26:12,452:INFO:SubProcess create_model() called ==================================
2023-04-24 11:26:12,454:INFO:Initializing create_model()
2023-04-24 11:26:12,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE2B1418D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:26:12,455:INFO:Checking exceptions
2023-04-24 11:26:12,456:INFO:Importing libraries
2023-04-24 11:26:12,457:INFO:Copying training dataset
2023-04-24 11:26:12,493:INFO:Defining folds
2023-04-24 11:26:12,494:INFO:Declaring metric variables
2023-04-24 11:26:12,510:INFO:Importing untrained model
2023-04-24 11:26:12,529:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 11:26:12,572:INFO:Starting cross validation
2023-04-24 11:26:12,587:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:26:19,846:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:26:35,532:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:26:35,578:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:26:35,625:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:26:36,032:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:26:51,344:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:27:31,785:INFO:Calculating mean and std
2023-04-24 11:27:31,800:INFO:Creating metrics dataframe
2023-04-24 11:27:39,230:INFO:Uploading results into container
2023-04-24 11:27:39,230:INFO:Uploading model into container now
2023-04-24 11:27:39,230:INFO:_master_model_container: 14
2023-04-24 11:27:39,230:INFO:_display_container: 2
2023-04-24 11:27:39,247:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-24 11:27:39,248:INFO:create_model() successfully completed......................................
2023-04-24 11:27:39,388:INFO:SubProcess create_model() end ==================================
2023-04-24 11:27:39,388:INFO:Creating metrics dataframe
2023-04-24 11:27:39,419:INFO:Initializing CatBoost Classifier
2023-04-24 11:27:39,419:INFO:Total runtime is 16.63271888097127 minutes
2023-04-24 11:27:39,438:INFO:SubProcess create_model() called ==================================
2023-04-24 11:27:39,439:INFO:Initializing create_model()
2023-04-24 11:27:39,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE2B1418D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:27:39,440:INFO:Checking exceptions
2023-04-24 11:27:39,440:INFO:Importing libraries
2023-04-24 11:27:39,440:INFO:Copying training dataset
2023-04-24 11:27:39,458:INFO:Defining folds
2023-04-24 11:27:39,459:INFO:Declaring metric variables
2023-04-24 11:27:39,472:INFO:Importing untrained model
2023-04-24 11:27:39,484:INFO:CatBoost Classifier Imported successfully
2023-04-24 11:27:39,517:INFO:Starting cross validation
2023-04-24 11:27:39,530:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:28:08,573:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:28:09,120:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:28:10,165:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:28:14,024:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:29:02,640:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 11:29:02,948:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 11:29:04,508:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:29:04,669:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 11:29:05,370:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:29:06,614:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:29:09,549:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 11:29:11,559:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:29:24,397:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-24 11:30:01,839:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:30:01,858:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:30:17,584:INFO:Calculating mean and std
2023-04-24 11:30:17,587:INFO:Creating metrics dataframe
2023-04-24 11:30:30,169:INFO:Uploading results into container
2023-04-24 11:30:30,169:INFO:Uploading model into container now
2023-04-24 11:30:30,169:INFO:_master_model_container: 15
2023-04-24 11:30:30,185:INFO:_display_container: 2
2023-04-24 11:30:30,185:INFO:<catboost.core.CatBoostClassifier object at 0x000001AE2E6CFFA0>
2023-04-24 11:30:30,187:INFO:create_model() successfully completed......................................
2023-04-24 11:30:30,483:INFO:SubProcess create_model() end ==================================
2023-04-24 11:30:30,483:INFO:Creating metrics dataframe
2023-04-24 11:30:30,554:INFO:Initializing Dummy Classifier
2023-04-24 11:30:30,554:INFO:Total runtime is 19.48496913512548 minutes
2023-04-24 11:30:30,574:INFO:SubProcess create_model() called ==================================
2023-04-24 11:30:30,575:INFO:Initializing create_model()
2023-04-24 11:30:30,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE2B1418D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:30:30,576:INFO:Checking exceptions
2023-04-24 11:30:30,576:INFO:Importing libraries
2023-04-24 11:30:30,576:INFO:Copying training dataset
2023-04-24 11:30:30,603:INFO:Defining folds
2023-04-24 11:30:30,604:INFO:Declaring metric variables
2023-04-24 11:30:30,619:INFO:Importing untrained model
2023-04-24 11:30:30,636:INFO:Dummy Classifier Imported successfully
2023-04-24 11:30:30,686:INFO:Starting cross validation
2023-04-24 11:30:30,700:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:30:33,171:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-24 11:30:33,171:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-24 11:30:33,187:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-24 11:30:33,218:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-24 11:30:47,571:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:30:47,688:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:30:47,865:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:30:47,903:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-24 11:30:48,005:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:30:48,020:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-24 11:30:48,170:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-24 11:30:48,270:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-24 11:31:00,370:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-24 11:31:00,422:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-24 11:31:42,886:INFO:Calculating mean and std
2023-04-24 11:31:42,886:INFO:Creating metrics dataframe
2023-04-24 11:31:53,708:INFO:Uploading results into container
2023-04-24 11:31:53,708:INFO:Uploading model into container now
2023-04-24 11:31:53,708:INFO:_master_model_container: 16
2023-04-24 11:31:53,708:INFO:_display_container: 2
2023-04-24 11:31:53,708:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-04-24 11:31:53,708:INFO:create_model() successfully completed......................................
2023-04-24 11:31:53,954:INFO:SubProcess create_model() end ==================================
2023-04-24 11:31:53,955:INFO:Creating metrics dataframe
2023-04-24 11:31:54,059:INFO:Initializing create_model()
2023-04-24 11:31:54,060:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E6CFFA0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:31:54,060:INFO:Checking exceptions
2023-04-24 11:31:54,067:INFO:Importing libraries
2023-04-24 11:31:54,067:INFO:Copying training dataset
2023-04-24 11:31:54,092:INFO:Defining folds
2023-04-24 11:31:54,092:INFO:Declaring metric variables
2023-04-24 11:31:54,094:INFO:Importing untrained model
2023-04-24 11:31:54,095:INFO:Declaring custom model
2023-04-24 11:31:54,097:INFO:CatBoost Classifier Imported successfully
2023-04-24 11:31:54,120:INFO:Cross validation set to False
2023-04-24 11:31:54,121:INFO:Fitting Model
2023-04-24 11:32:13,451:INFO:<catboost.core.CatBoostClassifier object at 0x000001AE2E43ED40>
2023-04-24 11:32:13,451:INFO:create_model() successfully completed......................................
2023-04-24 11:32:13,699:INFO:_master_model_container: 16
2023-04-24 11:32:13,700:INFO:_display_container: 2
2023-04-24 11:32:13,701:INFO:<catboost.core.CatBoostClassifier object at 0x000001AE2E43ED40>
2023-04-24 11:32:13,701:INFO:compare_models() successfully completed......................................
2023-04-24 11:37:20,547:INFO:Initializing create_model()
2023-04-24 11:37:20,547:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E43ED40>, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:37:20,548:INFO:Checking exceptions
2023-04-24 11:37:20,603:INFO:Importing libraries
2023-04-24 11:37:20,604:INFO:Copying training dataset
2023-04-24 11:37:20,645:INFO:Defining folds
2023-04-24 11:37:20,645:INFO:Declaring metric variables
2023-04-24 11:37:20,685:INFO:Importing untrained model
2023-04-24 11:37:20,685:INFO:Declaring custom model
2023-04-24 11:37:20,695:INFO:CatBoost Classifier Imported successfully
2023-04-24 11:37:20,726:INFO:Starting cross validation
2023-04-24 11:37:20,735:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:38:45,463:INFO:Calculating mean and std
2023-04-24 11:38:45,463:INFO:Creating metrics dataframe
2023-04-24 11:38:45,491:INFO:Finalizing model
2023-04-24 11:38:53,210:INFO:Uploading results into container
2023-04-24 11:38:53,213:INFO:Uploading model into container now
2023-04-24 11:38:53,248:INFO:_master_model_container: 17
2023-04-24 11:38:53,248:INFO:_display_container: 3
2023-04-24 11:38:53,249:INFO:<catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>
2023-04-24 11:38:53,249:INFO:create_model() successfully completed......................................
2023-04-24 11:40:04,101:INFO:Initializing tune_model()
2023-04-24 11:40:04,101:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>, fold=10, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>)
2023-04-24 11:40:04,101:INFO:Checking exceptions
2023-04-24 11:40:04,156:INFO:Copying training dataset
2023-04-24 11:40:04,176:INFO:Checking base model
2023-04-24 11:40:04,176:INFO:Base model : CatBoost Classifier
2023-04-24 11:40:04,183:INFO:Declaring metric variables
2023-04-24 11:40:04,194:INFO:Defining Hyperparameters
2023-04-24 11:40:04,503:INFO:Tuning with n_jobs=-1
2023-04-24 11:40:04,503:INFO:Initializing RandomizedSearchCV
2023-04-24 11:40:07,106:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:40:07,154:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:40:20,864:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:40:20,895:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:40:20,911:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:40:21,423:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:40:32,419:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:40:32,459:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:44:10,116:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:46:42,859:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:47:02,655:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:47:12,541:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:52:56,077:INFO:best_params: {'actual_estimator__random_strength': 0.7, 'actual_estimator__n_estimators': 250, 'actual_estimator__l2_leaf_reg': 50, 'actual_estimator__eta': 0.15, 'actual_estimator__depth': 3}
2023-04-24 11:52:56,093:INFO:Hyperparameter search completed
2023-04-24 11:52:56,093:INFO:SubProcess create_model() called ==================================
2023-04-24 11:52:56,093:INFO:Initializing create_model()
2023-04-24 11:52:56,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E474A90>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE2D8BAB30>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.7, 'n_estimators': 250, 'l2_leaf_reg': 50, 'eta': 0.15, 'depth': 3})
2023-04-24 11:52:56,093:INFO:Checking exceptions
2023-04-24 11:52:56,093:INFO:Importing libraries
2023-04-24 11:52:56,093:INFO:Copying training dataset
2023-04-24 11:52:56,118:INFO:Defining folds
2023-04-24 11:52:56,118:INFO:Declaring metric variables
2023-04-24 11:52:56,129:INFO:Importing untrained model
2023-04-24 11:52:56,129:INFO:Declaring custom model
2023-04-24 11:52:56,146:INFO:CatBoost Classifier Imported successfully
2023-04-24 11:52:56,182:INFO:Starting cross validation
2023-04-24 11:52:56,192:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:53:11,378:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:53:11,494:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:53:11,510:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:53:11,707:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:53:23,832:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:53:23,942:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 11:54:05,130:INFO:Calculating mean and std
2023-04-24 11:54:05,130:INFO:Creating metrics dataframe
2023-04-24 11:54:05,165:INFO:Finalizing model
2023-04-24 11:54:15,028:INFO:Uploading results into container
2023-04-24 11:54:15,031:INFO:Uploading model into container now
2023-04-24 11:54:15,033:INFO:_master_model_container: 18
2023-04-24 11:54:15,033:INFO:_display_container: 4
2023-04-24 11:54:15,035:INFO:<catboost.core.CatBoostClassifier object at 0x000001AE2F2BD210>
2023-04-24 11:54:15,036:INFO:create_model() successfully completed......................................
2023-04-24 11:54:15,190:INFO:SubProcess create_model() end ==================================
2023-04-24 11:54:15,190:INFO:choose_better activated
2023-04-24 11:54:15,190:INFO:SubProcess create_model() called ==================================
2023-04-24 11:54:15,190:INFO:Initializing create_model()
2023-04-24 11:54:15,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 11:54:15,190:INFO:Checking exceptions
2023-04-24 11:54:15,200:INFO:Importing libraries
2023-04-24 11:54:15,200:INFO:Copying training dataset
2023-04-24 11:54:15,214:INFO:Defining folds
2023-04-24 11:54:15,214:INFO:Declaring metric variables
2023-04-24 11:54:15,215:INFO:Importing untrained model
2023-04-24 11:54:15,215:INFO:Declaring custom model
2023-04-24 11:54:15,216:INFO:CatBoost Classifier Imported successfully
2023-04-24 11:54:15,218:INFO:Starting cross validation
2023-04-24 11:54:15,218:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 11:55:23,255:INFO:Calculating mean and std
2023-04-24 11:55:23,268:INFO:Creating metrics dataframe
2023-04-24 11:55:23,273:INFO:Finalizing model
2023-04-24 11:55:32,558:INFO:Uploading results into container
2023-04-24 11:55:32,558:INFO:Uploading model into container now
2023-04-24 11:55:32,558:INFO:_master_model_container: 19
2023-04-24 11:55:32,558:INFO:_display_container: 5
2023-04-24 11:55:32,558:INFO:<catboost.core.CatBoostClassifier object at 0x000001AE2E43E590>
2023-04-24 11:55:32,558:INFO:create_model() successfully completed......................................
2023-04-24 11:55:32,735:INFO:SubProcess create_model() end ==================================
2023-04-24 11:55:32,735:INFO:<catboost.core.CatBoostClassifier object at 0x000001AE2E43E590> result for Accuracy is 0.7579
2023-04-24 11:55:32,735:INFO:<catboost.core.CatBoostClassifier object at 0x000001AE2F2BD210> result for Accuracy is 0.7595
2023-04-24 11:55:32,735:INFO:<catboost.core.CatBoostClassifier object at 0x000001AE2F2BD210> is best model
2023-04-24 11:55:32,735:INFO:choose_better completed
2023-04-24 11:55:32,766:INFO:_master_model_container: 19
2023-04-24 11:55:32,766:INFO:_display_container: 4
2023-04-24 11:55:32,766:INFO:<catboost.core.CatBoostClassifier object at 0x000001AE2F2BD210>
2023-04-24 11:55:32,766:INFO:tune_model() successfully completed......................................
2023-04-24 11:57:51,338:INFO:Initializing evaluate_model()
2023-04-24 11:57:51,339:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-04-24 11:57:51,388:INFO:Initializing plot_model()
2023-04-24 11:57:51,388:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, system=True)
2023-04-24 11:57:51,389:INFO:Checking exceptions
2023-04-24 11:57:51,399:INFO:Preloading libraries
2023-04-24 11:57:51,403:INFO:Copying training dataset
2023-04-24 11:57:51,404:INFO:Plot type: pipeline
2023-04-24 11:57:52,075:INFO:Visual Rendered Successfully
2023-04-24 11:57:52,250:INFO:plot_model() successfully completed......................................
2023-04-24 11:58:06,343:INFO:Initializing plot_model()
2023-04-24 11:58:06,344:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, system=True)
2023-04-24 11:58:06,345:INFO:Checking exceptions
2023-04-24 11:58:06,351:INFO:Preloading libraries
2023-04-24 11:58:06,360:INFO:Copying training dataset
2023-04-24 11:58:06,360:INFO:Plot type: parameter
2023-04-24 11:58:06,372:INFO:Visual Rendered Successfully
2023-04-24 11:58:06,505:INFO:plot_model() successfully completed......................................
2023-04-24 11:58:24,224:INFO:Initializing plot_model()
2023-04-24 11:58:24,225:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, system=True)
2023-04-24 11:58:24,225:INFO:Checking exceptions
2023-04-24 11:58:24,236:INFO:Preloading libraries
2023-04-24 11:58:24,240:INFO:Copying training dataset
2023-04-24 11:58:24,240:INFO:Plot type: feature_all
2023-04-24 11:58:24,301:WARNING:No coef_ found. Trying feature_importances_
2023-04-24 11:58:25,588:INFO:Visual Rendered Successfully
2023-04-24 11:58:25,760:INFO:plot_model() successfully completed......................................
2023-04-24 11:58:48,578:INFO:Initializing plot_model()
2023-04-24 11:58:48,579:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, system=True)
2023-04-24 11:58:48,579:INFO:Checking exceptions
2023-04-24 11:58:48,588:INFO:Preloading libraries
2023-04-24 11:58:48,593:INFO:Copying training dataset
2023-04-24 11:58:48,593:INFO:Plot type: feature
2023-04-24 11:58:48,593:WARNING:No coef_ found. Trying feature_importances_
2023-04-24 11:58:48,973:INFO:Visual Rendered Successfully
2023-04-24 11:58:49,127:INFO:plot_model() successfully completed......................................
2023-04-24 11:59:05,801:INFO:Initializing predict_model()
2023-04-24 11:59:05,802:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001AE22BDA320>)
2023-04-24 11:59:05,803:INFO:Checking exceptions
2023-04-24 11:59:05,803:INFO:Preloading libraries
2023-04-24 11:59:37,146:INFO:Initializing predict_model()
2023-04-24 11:59:37,146:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001AE2E5781F0>)
2023-04-24 11:59:37,146:INFO:Checking exceptions
2023-04-24 11:59:37,147:INFO:Preloading libraries
2023-04-24 11:59:37,152:INFO:Set up data.
2023-04-24 11:59:37,186:INFO:Set up index.
2023-04-24 11:59:52,252:INFO:Initializing finalize_model()
2023-04-24 11:59:52,253:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>, fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-24 11:59:52,253:INFO:Finalizing <catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>
2023-04-24 11:59:52,261:INFO:Initializing create_model()
2023-04-24 11:59:52,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-24 11:59:52,263:INFO:Checking exceptions
2023-04-24 11:59:52,267:INFO:Importing libraries
2023-04-24 11:59:52,267:INFO:Copying training dataset
2023-04-24 11:59:52,268:INFO:Defining folds
2023-04-24 11:59:52,268:INFO:Declaring metric variables
2023-04-24 11:59:52,268:INFO:Importing untrained model
2023-04-24 11:59:52,268:INFO:Declaring custom model
2023-04-24 11:59:52,269:INFO:CatBoost Classifier Imported successfully
2023-04-24 11:59:52,273:INFO:Cross validation set to False
2023-04-24 11:59:52,274:INFO:Fitting Model
2023-04-24 12:00:04,521:INFO:Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001AE2E4AAAD0>)],
         verbose=False)
2023-04-24 12:00:04,521:INFO:create_model() successfully completed......................................
2023-04-24 12:00:04,677:INFO:_master_model_container: 19
2023-04-24 12:00:04,677:INFO:_display_container: 6
2023-04-24 12:00:04,802:INFO:Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001AE2E4AAAD0>)],
         verbose=False)
2023-04-24 12:00:04,802:INFO:finalize_model() successfully completed......................................
2023-04-24 12:00:26,020:INFO:Initializing save_model()
2023-04-24 12:00:26,020:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001AE2E4AAAD0>)],
         verbose=False), model_name=Final RF Model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-24 12:00:26,020:INFO:Adding model into prep_pipe
2023-04-24 12:00:26,020:WARNING:Only Model saved as it was a pipeline.
2023-04-24 12:00:26,035:INFO:Final RF Model.pkl saved in current working directory
2023-04-24 12:00:26,035:INFO:<catboost.core.CatBoostClassifier object at 0x000001AE2F2706A0>
2023-04-24 12:00:26,035:INFO:save_model() successfully completed......................................
2023-04-24 12:01:51,343:INFO:Initializing save_model()
2023-04-24 12:01:51,343:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001AE2E4AAAD0>)],
         verbose=False), model_name=Final CB Model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-24 12:01:51,343:INFO:Adding model into prep_pipe
2023-04-24 12:01:51,343:WARNING:Only Model saved as it was a pipeline.
2023-04-24 12:01:51,343:INFO:Final CB Model.pkl saved in current working directory
2023-04-24 12:01:51,358:INFO:<catboost.core.CatBoostClassifier object at 0x000001AE2E4AB7C0>
2023-04-24 12:01:51,358:INFO:save_model() successfully completed......................................
2023-04-24 12:03:21,884:INFO:Initializing plot_model()
2023-04-24 12:03:21,884:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, system=True)
2023-04-24 12:03:21,885:INFO:Checking exceptions
2023-04-24 12:03:21,891:INFO:Preloading libraries
2023-04-24 12:03:21,899:INFO:Copying training dataset
2023-04-24 12:03:21,900:INFO:Plot type: confusion_matrix
2023-04-24 12:03:22,161:INFO:Fitting Model
2023-04-24 12:03:22,176:INFO:Scoring test/hold-out set
2023-04-24 12:03:22,419:INFO:Visual Rendered Successfully
2023-04-24 12:03:22,557:INFO:plot_model() successfully completed......................................
2023-04-24 12:04:04,495:INFO:Initializing plot_model()
2023-04-24 12:04:04,496:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, system=True)
2023-04-24 12:04:04,496:INFO:Checking exceptions
2023-04-24 12:04:04,506:INFO:Preloading libraries
2023-04-24 12:04:04,512:INFO:Copying training dataset
2023-04-24 12:04:04,512:INFO:Plot type: class_report
2023-04-24 12:04:04,760:INFO:Fitting Model
2023-04-24 12:04:04,761:INFO:Scoring test/hold-out set
2023-04-24 12:04:05,349:INFO:Visual Rendered Successfully
2023-04-24 12:04:05,528:INFO:plot_model() successfully completed......................................
2023-04-24 12:04:44,693:INFO:Initializing plot_model()
2023-04-24 12:04:44,693:INFO:plot_model(plot=gain, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, system=True)
2023-04-24 12:04:44,694:INFO:Checking exceptions
2023-04-24 12:04:44,700:INFO:Preloading libraries
2023-04-24 12:04:44,700:INFO:Copying training dataset
2023-04-24 12:04:44,700:INFO:Plot type: gain
2023-04-24 12:04:44,700:INFO:Generating predictions / predict_proba on X_test
2023-04-24 12:04:45,165:INFO:Visual Rendered Successfully
2023-04-24 12:04:45,290:INFO:plot_model() successfully completed......................................
2023-04-24 12:05:19,388:INFO:Initializing plot_model()
2023-04-24 12:05:19,388:INFO:plot_model(plot=error, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, system=True)
2023-04-24 12:05:19,389:INFO:Checking exceptions
2023-04-24 12:05:19,398:INFO:Preloading libraries
2023-04-24 12:05:19,398:INFO:Copying training dataset
2023-04-24 12:05:19,398:INFO:Plot type: error
2023-04-24 12:05:19,748:INFO:Fitting Model
2023-04-24 12:05:19,748:INFO:Scoring test/hold-out set
2023-04-24 12:05:20,299:INFO:Visual Rendered Successfully
2023-04-24 12:05:20,488:INFO:plot_model() successfully completed......................................
2023-04-24 12:06:18,967:INFO:Initializing plot_model()
2023-04-24 12:06:18,967:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2E43EFB0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, system=True)
2023-04-24 12:06:18,969:INFO:Checking exceptions
2023-04-24 12:06:18,976:INFO:Preloading libraries
2023-04-24 12:06:18,976:INFO:Copying training dataset
2023-04-24 12:06:18,976:INFO:Plot type: confusion_matrix
2023-04-24 12:06:19,233:INFO:Fitting Model
2023-04-24 12:06:19,233:INFO:Scoring test/hold-out set
2023-04-24 12:06:19,460:INFO:Visual Rendered Successfully
2023-04-24 12:06:19,596:INFO:plot_model() successfully completed......................................
2023-04-24 15:40:32,055:INFO:Initializing predict_model()
2023-04-24 15:40:32,057:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2F2BD210>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001AE2E57BD90>)
2023-04-24 15:40:32,057:INFO:Checking exceptions
2023-04-24 15:40:32,057:INFO:Preloading libraries
2023-04-24 15:42:18,917:INFO:Initializing predict_model()
2023-04-24 15:42:18,918:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2F2BD210>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001AE22BDA320>)
2023-04-24 15:42:18,918:INFO:Checking exceptions
2023-04-24 15:42:18,919:INFO:Preloading libraries
2023-04-24 15:42:18,924:INFO:Set up data.
2023-04-24 15:42:18,955:INFO:Set up index.
2023-04-24 16:04:34,178:INFO:Initializing finalize_model()
2023-04-24 16:04:34,179:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2F2BD210>, fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-24 16:04:34,179:INFO:Finalizing <catboost.core.CatBoostClassifier object at 0x000001AE2F2BD210>
2023-04-24 16:04:34,193:INFO:Initializing create_model()
2023-04-24 16:04:34,194:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE2BDA3A30>, estimator=<catboost.core.CatBoostClassifier object at 0x000001AE2F2BD210>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-24 16:04:34,194:INFO:Checking exceptions
2023-04-24 16:04:34,199:INFO:Importing libraries
2023-04-24 16:04:34,200:INFO:Copying training dataset
2023-04-24 16:04:34,201:INFO:Defining folds
2023-04-24 16:04:34,201:INFO:Declaring metric variables
2023-04-24 16:04:34,202:INFO:Importing untrained model
2023-04-24 16:04:34,202:INFO:Declaring custom model
2023-04-24 16:04:34,203:INFO:CatBoost Classifier Imported successfully
2023-04-24 16:04:34,212:INFO:Cross validation set to False
2023-04-24 16:04:34,212:INFO:Fitting Model
2023-04-24 16:04:36,073:INFO:Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001AE2E489090>)],
         verbose=False)
2023-04-24 16:04:36,073:INFO:create_model() successfully completed......................................
2023-04-24 16:04:36,245:INFO:_master_model_container: 19
2023-04-24 16:04:36,245:INFO:_display_container: 8
2023-04-24 16:04:36,366:INFO:Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001AE2E489090>)],
         verbose=False)
2023-04-24 16:04:36,366:INFO:finalize_model() successfully completed......................................
2023-04-24 16:05:13,857:INFO:Initializing save_model()
2023-04-24 16:05:13,857:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001AE2E489090>)],
         verbose=False), model_name=Final CB Model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-24 16:05:13,857:INFO:Adding model into prep_pipe
2023-04-24 16:05:13,873:WARNING:Only Model saved as it was a pipeline.
2023-04-24 16:05:13,873:INFO:Final CB Model.pkl saved in current working directory
2023-04-24 16:05:13,873:INFO:<catboost.core.CatBoostClassifier object at 0x000001AE2E37B430>
2023-04-24 16:05:13,873:INFO:save_model() successfully completed......................................
2023-04-24 16:22:48,539:INFO:Soft dependency imported: fastapi: 0.89.1
2023-04-24 16:22:48,541:INFO:Soft dependency imported: uvicorn: 0.21.1
2023-04-24 16:22:48,541:INFO:Soft dependency imported: pydantic: 1.10.7
2023-04-24 16:22:48,663:INFO:Initializing save_model()
2023-04-24 16:22:48,663:INFO:save_model(model=<catboost.core.CatBoostClassifier object at 0x000001AE2E475900>, model_name=credit_api, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-24 16:22:48,664:INFO:Adding model into prep_pipe
2023-04-24 16:22:48,721:INFO:credit_api.pkl saved in current working directory
2023-04-24 16:22:48,795:INFO:Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('trained_model',
                 <catboost.core.CatBoostClassifier object at 0x000001AE2E475900>)],
         verbose=False)
2023-04-24 16:22:48,795:INFO:save_model() successfully completed......................................
2023-04-24 16:25:13,380:INFO:Initializing load_model()
2023-04-24 16:25:13,381:INFO:load_model(model_name=credit_api, platform=None, authentication=None, verbose=True)
2023-04-24 16:27:04,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 16:27:04,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 16:27:04,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 16:27:04,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 16:27:05,331:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-24 16:27:08,234:INFO:Initializing load_model()
2023-04-24 16:27:08,234:INFO:load_model(model_name=credit_api, platform=None, authentication=None, verbose=True)
2023-04-24 16:30:02,878:INFO:Initializing predict_model()
2023-04-24 16:30:02,878:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D83A219210>, estimator=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             'residence_since', 'age',
                                             'existing_credit...
                                                                    'other_parties',
                                                                    'property_magnitude',
                                                                    'other_payment_plans',
                                                                    'housing',
                                                                    'job',
                                                                    'marital_status'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model',
                 <catboost.core.CatBoostClassifier object at 0x000001D839C55330>)]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D83A1FC8B0>)
2023-04-24 16:30:02,878:INFO:Checking exceptions
2023-04-24 16:30:02,878:INFO:Preloading libraries
2023-04-24 16:30:02,878:INFO:Set up data.
2023-04-24 16:30:02,895:INFO:Set up index.
2023-04-24 16:35:48,897:INFO:Initializing predict_model()
2023-04-24 16:35:48,897:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D83A261960>, estimator=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             'residence_since', 'age',
                                             'existing_credit...
                                                                    'other_parties',
                                                                    'property_magnitude',
                                                                    'other_payment_plans',
                                                                    'housing',
                                                                    'job',
                                                                    'marital_status'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model',
                 <catboost.core.CatBoostClassifier object at 0x000001D839C55330>)]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001D83A2279A0>)
2023-04-24 16:35:48,897:INFO:Checking exceptions
2023-04-24 16:35:48,897:INFO:Preloading libraries
2023-04-24 16:35:48,897:INFO:Set up data.
2023-04-24 16:35:48,914:INFO:Set up index.
2023-04-25 10:33:00,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 10:33:00,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 10:33:00,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 10:33:00,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 10:33:04,322:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-25 10:33:25,462:WARNING:C:\Users\User\AppData\Local\Temp\ipykernel_2520\2777188505.py:3: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.
  from pandas_profiling import ProfileReport

2023-04-25 10:38:01,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 10:38:01,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 10:38:01,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 10:38:01,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 10:38:02,699:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-25 10:43:01,212:INFO:PyCaret ClassificationExperiment
2023-04-25 10:43:01,212:INFO:Logging name: clf-default-name
2023-04-25 10:43:01,212:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-25 10:43:01,212:INFO:version 3.0.0
2023-04-25 10:43:01,212:INFO:Initializing setup()
2023-04-25 10:43:01,212:INFO:self.USI: adbf
2023-04-25 10:43:01,212:INFO:self._variable_keys: {'is_multiclass', '_available_plots', 'gpu_n_jobs_param', 'exp_id', 'html_param', 'y', 'fix_imbalance', 'X_train', 'X', 'data', 'target_param', 'log_plots_param', 'exp_name_log', '_ml_usecase', 'gpu_param', 'memory', 'USI', 'logging_param', 'y_train', 'X_test', 'seed', 'pipeline', 'idx', 'fold_shuffle_param', 'fold_generator', 'y_test', 'fold_groups_param', 'n_jobs_param'}
2023-04-25 10:43:01,212:INFO:Checking environment
2023-04-25 10:43:01,212:INFO:python_version: 3.10.9
2023-04-25 10:43:01,212:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-04-25 10:43:01,212:INFO:machine: AMD64
2023-04-25 10:43:01,212:INFO:platform: Windows-10-10.0.19044-SP0
2023-04-25 10:43:01,212:INFO:Memory: svmem(total=8483184640, available=3959132160, percent=53.3, used=4524052480, free=3959132160)
2023-04-25 10:43:01,212:INFO:Physical Core: 2
2023-04-25 10:43:01,212:INFO:Logical Core: 4
2023-04-25 10:43:01,212:INFO:Checking libraries
2023-04-25 10:43:01,212:INFO:System:
2023-04-25 10:43:01,212:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-04-25 10:43:01,212:INFO:executable: C:\Users\User\.conda\envs\My_envI\python.exe
2023-04-25 10:43:01,212:INFO:   machine: Windows-10-10.0.19044-SP0
2023-04-25 10:43:01,212:INFO:PyCaret required dependencies:
2023-04-25 10:43:01,212:INFO:                 pip: 22.3.1
2023-04-25 10:43:01,212:INFO:          setuptools: 66.0.0
2023-04-25 10:43:01,212:INFO:             pycaret: 3.0.0
2023-04-25 10:43:01,212:INFO:             IPython: 8.12.0
2023-04-25 10:43:01,212:INFO:          ipywidgets: 7.6.5
2023-04-25 10:43:01,212:INFO:                tqdm: 4.64.1
2023-04-25 10:43:01,212:INFO:               numpy: 1.23.5
2023-04-25 10:43:01,212:INFO:              pandas: 1.5.3
2023-04-25 10:43:01,212:INFO:              jinja2: 3.1.2
2023-04-25 10:43:01,212:INFO:               scipy: 1.10.1
2023-04-25 10:43:01,212:INFO:              joblib: 1.2.0
2023-04-25 10:43:01,212:INFO:             sklearn: 1.2.1
2023-04-25 10:43:01,212:INFO:                pyod: 1.0.9
2023-04-25 10:43:01,212:INFO:            imblearn: 0.10.1
2023-04-25 10:43:01,212:INFO:   category_encoders: 2.6.0
2023-04-25 10:43:01,212:INFO:            lightgbm: 3.3.5
2023-04-25 10:43:01,212:INFO:               numba: 0.56.4
2023-04-25 10:43:01,212:INFO:            requests: 2.28.1
2023-04-25 10:43:01,212:INFO:          matplotlib: 3.7.0
2023-04-25 10:43:01,212:INFO:          scikitplot: 0.3.7
2023-04-25 10:43:01,212:INFO:         yellowbrick: 1.5
2023-04-25 10:43:01,212:INFO:              plotly: 5.14.1
2023-04-25 10:43:01,212:INFO:             kaleido: 0.2.1
2023-04-25 10:43:01,212:INFO:         statsmodels: 0.13.5
2023-04-25 10:43:01,212:INFO:              sktime: 0.17.0
2023-04-25 10:43:01,212:INFO:               tbats: 1.1.2
2023-04-25 10:43:01,212:INFO:            pmdarima: 2.0.3
2023-04-25 10:43:01,212:INFO:              psutil: 5.9.0
2023-04-25 10:43:01,212:INFO:PyCaret optional dependencies:
2023-04-25 10:43:02,180:INFO:                shap: 0.41.0
2023-04-25 10:43:02,180:INFO:           interpret: 0.3.2
2023-04-25 10:43:02,180:INFO:                umap: 0.5.3
2023-04-25 10:43:02,180:INFO:    pandas_profiling: 4.1.2
2023-04-25 10:43:02,180:INFO:  explainerdashboard: 0.4.2.1
2023-04-25 10:43:02,180:INFO:             autoviz: 0.1.58
2023-04-25 10:43:02,180:INFO:           fairlearn: 0.7.0
2023-04-25 10:43:02,180:INFO:             xgboost: 1.7.5
2023-04-25 10:43:02,180:INFO:            catboost: 1.1.1
2023-04-25 10:43:02,195:INFO:              kmodes: 0.12.2
2023-04-25 10:43:02,195:INFO:             mlxtend: 0.22.0
2023-04-25 10:43:02,195:INFO:       statsforecast: 1.5.0
2023-04-25 10:43:02,195:INFO:        tune_sklearn: 0.4.5
2023-04-25 10:43:02,195:INFO:                 ray: 2.3.1
2023-04-25 10:43:02,195:INFO:            hyperopt: 0.2.7
2023-04-25 10:43:02,195:INFO:              optuna: 3.1.0
2023-04-25 10:43:02,195:INFO:               skopt: 0.9.0
2023-04-25 10:43:02,195:INFO:              mlflow: 1.30.1
2023-04-25 10:43:02,195:INFO:              gradio: Not installed
2023-04-25 10:43:02,195:INFO:             fastapi: 0.89.1
2023-04-25 10:43:02,195:INFO:             uvicorn: 0.21.1
2023-04-25 10:43:02,195:INFO:              m2cgen: 0.10.0
2023-04-25 10:43:02,195:INFO:           evidently: 0.2.8
2023-04-25 10:43:02,195:INFO:               fugue: 0.8.3
2023-04-25 10:43:02,195:INFO:           streamlit: Not installed
2023-04-25 10:43:02,195:INFO:             prophet: Not installed
2023-04-25 10:43:02,195:INFO:None
2023-04-25 10:43:02,195:INFO:Set up data.
2023-04-25 10:43:02,211:INFO:Set up train/test split.
2023-04-25 10:43:02,242:INFO:Set up index.
2023-04-25 10:43:02,242:INFO:Set up folding strategy.
2023-04-25 10:43:02,242:INFO:Assigning column types.
2023-04-25 10:43:02,258:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 10:43:02,336:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 10:43:02,352:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 10:43:02,414:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 10:43:03,242:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-25 10:43:03,539:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 10:43:03,539:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 10:43:03,586:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 10:43:03,586:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-25 10:43:03,586:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 10:43:03,675:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 10:43:03,710:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 10:43:03,710:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-25 10:43:03,788:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 10:43:03,819:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 10:43:03,835:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-25 10:43:03,835:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-25 10:43:03,944:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 10:43:03,944:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-25 10:43:04,069:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 10:43:04,069:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-25 10:43:04,085:INFO:Preparing preprocessing pipeline...
2023-04-25 10:43:04,100:INFO:Set up label encoding.
2023-04-25 10:43:04,100:INFO:Set up simple imputation.
2023-04-25 10:43:04,100:INFO:Set up encoding of ordinal features.
2023-04-25 10:43:04,100:INFO:Set up encoding of categorical features.
2023-04-25 10:43:04,100:INFO:Set up imbalanced handling.
2023-04-25 10:43:04,100:INFO:Set up feature normalization.
2023-04-25 10:43:04,100:INFO:Set up feature selection.
2023-04-25 10:43:04,225:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 10:43:04,225:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-25 10:43:04,865:INFO:Finished creating preprocessing pipeline.
2023-04-25 10:43:04,990:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=10,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2023-04-25 10:43:04,990:INFO:Creating final display dataframe.
2023-04-25 10:43:06,481:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             class
2                   Target type            Binary
3                Target mapping   bad: 0, good: 1
4           Original data shape         (950, 22)
5        Transformed data shape        (1217, 11)
6   Transformed train set shape         (932, 11)
7    Transformed test set shape         (285, 11)
8              Ordinal features                 3
9              Numeric features                10
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19                    Normalize              True
20             Normalize method            minmax
21            Feature selection              True
22     Feature selection method           classic
23  Feature selection estimator          lightgbm
24  Number of features selected               0.5
25               Fold Generator   StratifiedKFold
26                  Fold Number                10
27                     CPU Jobs                -1
28                      Use GPU             False
29               Log Experiment             False
30              Experiment Name  clf-default-name
31                          USI              adbf
2023-04-25 10:43:06,691:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 10:43:06,691:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-25 10:43:06,853:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 10:43:06,853:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-25 10:43:06,853:INFO:setup() successfully completed in 10.32s...............
2023-04-25 10:43:41,664:INFO:Initializing get_config()
2023-04-25 10:43:41,664:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, variable=X_transformed)
2023-04-25 10:43:41,943:INFO:Variable: X returned as      checking_status  duration  credit_amount  savings_status  employment  \
405         0.333333  0.035714       0.004842            0.75        1.00   
802         0.000000  0.142857       0.063387            0.75        0.75   
368         0.000000  0.250000       0.124629            0.25        0.50   
503         0.000000  0.303571       0.683944            0.00        1.00   
619         0.333333  0.035714       0.033564            0.25        1.00   
..               ...       ...            ...             ...         ...   
416         0.000000  0.250000       0.138935            0.25        0.75   
771         0.000000  0.321429       0.056839            0.00        0.75   
319         0.000000  0.250000       0.132717            0.00        0.75   
219         0.333333  0.142857       0.024816            0.25        0.50   
311         0.000000  0.357143       0.192968            0.25        1.00   

     installment_commitment  residence_since       age  job_skilled  \
405                1.000000         1.000000  0.589286          1.0   
802                0.666667         1.000000  0.321429          1.0   
368                0.666667         1.000000  0.428571          1.0   
503                1.000000         1.000000  0.196429          0.0   
619                0.000000         1.000000  0.357143          1.0   
..                      ...              ...       ...          ...   
416                0.333333         0.333333  0.214286          1.0   
771                1.000000         1.000000  0.107143          1.0   
319                1.000000         0.666667  0.232143          1.0   
219                1.000000         0.333333  0.375000          0.0   
311                1.000000         1.000000  0.767857          1.0   

     own_telephone  
405            0.0  
802            1.0  
368            1.0  
503            1.0  
619            1.0  
..             ...  
416            0.0  
771            0.0  
319            0.0  
219            0.0  
311            1.0  

[1217 rows x 10 columns]
2023-04-25 10:43:41,943:INFO:get_config() successfully completed......................................
2023-04-25 10:44:09,328:INFO:Initializing compare_models()
2023-04-25 10:44:09,329:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-25 10:44:09,329:INFO:Checking exceptions
2023-04-25 10:44:09,342:INFO:Preparing display monitor
2023-04-25 10:44:09,423:INFO:Initializing Logistic Regression
2023-04-25 10:44:09,423:INFO:Total runtime is 0.0 minutes
2023-04-25 10:44:09,434:INFO:SubProcess create_model() called ==================================
2023-04-25 10:44:09,435:INFO:Initializing create_model()
2023-04-25 10:44:09,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7CD6C0820>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 10:44:09,436:INFO:Checking exceptions
2023-04-25 10:44:09,437:INFO:Importing libraries
2023-04-25 10:44:09,437:INFO:Copying training dataset
2023-04-25 10:44:09,453:INFO:Defining folds
2023-04-25 10:44:09,453:INFO:Declaring metric variables
2023-04-25 10:44:09,460:INFO:Importing untrained model
2023-04-25 10:44:09,473:INFO:Logistic Regression Imported successfully
2023-04-25 10:44:09,500:INFO:Starting cross validation
2023-04-25 10:44:09,524:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 10:44:28,829:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:44:29,391:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:44:29,438:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:44:42,636:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:44:42,777:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:44:42,777:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:44:42,808:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:44:55,473:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:45:28,983:INFO:Calculating mean and std
2023-04-25 10:45:28,998:INFO:Creating metrics dataframe
2023-04-25 10:45:36,715:INFO:Uploading results into container
2023-04-25 10:45:36,715:INFO:Uploading model into container now
2023-04-25 10:45:36,715:INFO:_master_model_container: 1
2023-04-25 10:45:36,715:INFO:_display_container: 2
2023-04-25 10:45:36,731:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-25 10:45:36,731:INFO:create_model() successfully completed......................................
2023-04-25 10:45:36,907:INFO:SubProcess create_model() end ==================================
2023-04-25 10:45:36,923:INFO:Creating metrics dataframe
2023-04-25 10:45:36,939:INFO:Initializing K Neighbors Classifier
2023-04-25 10:45:36,939:INFO:Total runtime is 1.4585997660954793 minutes
2023-04-25 10:45:36,954:INFO:SubProcess create_model() called ==================================
2023-04-25 10:45:36,955:INFO:Initializing create_model()
2023-04-25 10:45:36,956:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7CD6C0820>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 10:45:36,956:INFO:Checking exceptions
2023-04-25 10:45:36,957:INFO:Importing libraries
2023-04-25 10:45:36,957:INFO:Copying training dataset
2023-04-25 10:45:36,979:INFO:Defining folds
2023-04-25 10:45:36,979:INFO:Declaring metric variables
2023-04-25 10:45:36,989:INFO:Importing untrained model
2023-04-25 10:45:36,997:INFO:K Neighbors Classifier Imported successfully
2023-04-25 10:45:37,038:INFO:Starting cross validation
2023-04-25 10:45:37,071:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 10:45:39,039:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:45:40,215:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:45:40,433:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:45:52,776:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:45:52,870:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:45:52,901:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:45:53,105:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:45:54,213:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:45:54,213:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:45:54,228:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:45:54,929:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:46:05,763:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:46:38,381:INFO:Calculating mean and std
2023-04-25 10:46:38,381:INFO:Creating metrics dataframe
2023-04-25 10:46:47,043:INFO:Uploading results into container
2023-04-25 10:46:47,043:INFO:Uploading model into container now
2023-04-25 10:46:47,054:INFO:_master_model_container: 2
2023-04-25 10:46:47,055:INFO:_display_container: 2
2023-04-25 10:46:47,056:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-25 10:46:47,056:INFO:create_model() successfully completed......................................
2023-04-25 10:46:47,206:INFO:SubProcess create_model() end ==================================
2023-04-25 10:46:47,206:INFO:Creating metrics dataframe
2023-04-25 10:46:47,237:INFO:Initializing Naive Bayes
2023-04-25 10:46:47,237:INFO:Total runtime is 2.630238632361094 minutes
2023-04-25 10:46:47,245:INFO:SubProcess create_model() called ==================================
2023-04-25 10:46:47,245:INFO:Initializing create_model()
2023-04-25 10:46:47,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7CD6C0820>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 10:46:47,245:INFO:Checking exceptions
2023-04-25 10:46:47,245:INFO:Importing libraries
2023-04-25 10:46:47,245:INFO:Copying training dataset
2023-04-25 10:46:47,260:INFO:Defining folds
2023-04-25 10:46:47,260:INFO:Declaring metric variables
2023-04-25 10:46:47,260:INFO:Importing untrained model
2023-04-25 10:46:47,288:INFO:Naive Bayes Imported successfully
2023-04-25 10:46:47,316:INFO:Starting cross validation
2023-04-25 10:46:47,347:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 10:47:02,775:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:47:02,775:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:47:02,916:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:47:02,947:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:47:13,575:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:47:13,669:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:47:49,457:INFO:Calculating mean and std
2023-04-25 10:47:49,457:INFO:Creating metrics dataframe
2023-04-25 10:47:56,193:INFO:Uploading results into container
2023-04-25 10:47:56,193:INFO:Uploading model into container now
2023-04-25 10:47:56,193:INFO:_master_model_container: 3
2023-04-25 10:47:56,193:INFO:_display_container: 2
2023-04-25 10:47:56,193:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-25 10:47:56,200:INFO:create_model() successfully completed......................................
2023-04-25 10:47:56,358:INFO:SubProcess create_model() end ==================================
2023-04-25 10:47:56,358:INFO:Creating metrics dataframe
2023-04-25 10:47:56,374:INFO:Initializing Decision Tree Classifier
2023-04-25 10:47:56,374:INFO:Total runtime is 3.7825203418731688 minutes
2023-04-25 10:47:56,395:INFO:SubProcess create_model() called ==================================
2023-04-25 10:47:56,396:INFO:Initializing create_model()
2023-04-25 10:47:56,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7CD6C0820>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 10:47:56,397:INFO:Checking exceptions
2023-04-25 10:47:56,398:INFO:Importing libraries
2023-04-25 10:47:56,398:INFO:Copying training dataset
2023-04-25 10:47:56,413:INFO:Defining folds
2023-04-25 10:47:56,413:INFO:Declaring metric variables
2023-04-25 10:47:56,425:INFO:Importing untrained model
2023-04-25 10:47:56,443:INFO:Decision Tree Classifier Imported successfully
2023-04-25 10:47:56,471:INFO:Starting cross validation
2023-04-25 10:47:56,498:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 10:48:11,559:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:48:11,653:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:48:11,653:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:48:11,778:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:48:59,893:INFO:Calculating mean and std
2023-04-25 10:48:59,893:INFO:Creating metrics dataframe
2023-04-25 10:49:08,746:INFO:Uploading results into container
2023-04-25 10:49:08,746:INFO:Uploading model into container now
2023-04-25 10:49:08,746:INFO:_master_model_container: 4
2023-04-25 10:49:08,746:INFO:_display_container: 2
2023-04-25 10:49:08,761:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-04-25 10:49:08,761:INFO:create_model() successfully completed......................................
2023-04-25 10:49:08,967:INFO:SubProcess create_model() end ==================================
2023-04-25 10:49:08,967:INFO:Creating metrics dataframe
2023-04-25 10:49:08,998:INFO:Initializing SVM - Linear Kernel
2023-04-25 10:49:08,998:INFO:Total runtime is 4.992931000391642 minutes
2023-04-25 10:49:09,015:INFO:SubProcess create_model() called ==================================
2023-04-25 10:49:09,016:INFO:Initializing create_model()
2023-04-25 10:49:09,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7CD6C0820>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 10:49:09,016:INFO:Checking exceptions
2023-04-25 10:49:09,017:INFO:Importing libraries
2023-04-25 10:49:09,017:INFO:Copying training dataset
2023-04-25 10:49:09,033:INFO:Defining folds
2023-04-25 10:49:09,034:INFO:Declaring metric variables
2023-04-25 10:49:09,048:INFO:Importing untrained model
2023-04-25 10:49:09,068:INFO:SVM - Linear Kernel Imported successfully
2023-04-25 10:49:09,087:INFO:Starting cross validation
2023-04-25 10:49:09,135:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 10:49:11,147:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 10:49:11,147:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 10:49:11,147:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 10:49:11,209:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 10:49:25,537:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:49:25,538:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 10:49:25,773:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:49:25,773:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:49:25,788:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 10:49:25,820:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 10:49:25,960:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:49:25,960:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 10:49:36,151:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:49:36,151:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 10:49:36,167:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:49:36,183:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 10:50:12,280:INFO:Calculating mean and std
2023-04-25 10:50:12,296:INFO:Creating metrics dataframe
2023-04-25 10:50:19,086:INFO:Uploading results into container
2023-04-25 10:50:19,086:INFO:Uploading model into container now
2023-04-25 10:50:19,098:INFO:_master_model_container: 5
2023-04-25 10:50:19,099:INFO:_display_container: 2
2023-04-25 10:50:19,100:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-25 10:50:19,100:INFO:create_model() successfully completed......................................
2023-04-25 10:50:19,255:INFO:SubProcess create_model() end ==================================
2023-04-25 10:50:19,255:INFO:Creating metrics dataframe
2023-04-25 10:50:19,286:INFO:Initializing Ridge Classifier
2023-04-25 10:50:19,286:INFO:Total runtime is 6.164392101764679 minutes
2023-04-25 10:50:19,298:INFO:SubProcess create_model() called ==================================
2023-04-25 10:50:19,299:INFO:Initializing create_model()
2023-04-25 10:50:19,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7CD6C0820>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 10:50:19,300:INFO:Checking exceptions
2023-04-25 10:50:19,300:INFO:Importing libraries
2023-04-25 10:50:19,300:INFO:Copying training dataset
2023-04-25 10:50:19,312:INFO:Defining folds
2023-04-25 10:50:19,313:INFO:Declaring metric variables
2023-04-25 10:50:19,322:INFO:Importing untrained model
2023-04-25 10:50:19,333:INFO:Ridge Classifier Imported successfully
2023-04-25 10:50:19,358:INFO:Starting cross validation
2023-04-25 10:50:19,396:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 10:50:21,148:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 10:50:21,163:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 10:50:21,226:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 10:50:21,241:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 10:50:33,917:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:50:33,933:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 10:50:33,933:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:50:33,933:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 10:50:33,949:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:50:33,964:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 10:50:33,964:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:50:33,980:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 10:50:44,901:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:50:44,917:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 10:50:44,932:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:50:44,964:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 10:51:20,096:INFO:Calculating mean and std
2023-04-25 10:51:20,096:INFO:Creating metrics dataframe
2023-04-25 10:51:27,405:INFO:Uploading results into container
2023-04-25 10:51:27,405:INFO:Uploading model into container now
2023-04-25 10:51:27,420:INFO:_master_model_container: 6
2023-04-25 10:51:27,420:INFO:_display_container: 2
2023-04-25 10:51:27,423:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-04-25 10:51:27,424:INFO:create_model() successfully completed......................................
2023-04-25 10:51:27,603:INFO:SubProcess create_model() end ==================================
2023-04-25 10:51:27,603:INFO:Creating metrics dataframe
2023-04-25 10:51:27,634:INFO:Initializing Random Forest Classifier
2023-04-25 10:51:27,634:INFO:Total runtime is 7.303524708747863 minutes
2023-04-25 10:51:27,654:INFO:SubProcess create_model() called ==================================
2023-04-25 10:51:27,655:INFO:Initializing create_model()
2023-04-25 10:51:27,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7CD6C0820>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 10:51:27,656:INFO:Checking exceptions
2023-04-25 10:51:27,656:INFO:Importing libraries
2023-04-25 10:51:27,657:INFO:Copying training dataset
2023-04-25 10:51:27,678:INFO:Defining folds
2023-04-25 10:51:27,679:INFO:Declaring metric variables
2023-04-25 10:51:27,690:INFO:Importing untrained model
2023-04-25 10:51:27,700:INFO:Random Forest Classifier Imported successfully
2023-04-25 10:51:27,732:INFO:Starting cross validation
2023-04-25 10:51:27,763:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 10:51:31,461:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:51:31,496:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:51:31,537:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:51:31,740:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:51:46,988:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:51:47,103:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:51:47,275:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:51:48,658:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:52:01,207:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:52:01,395:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:52:35,542:INFO:Calculating mean and std
2023-04-25 10:52:35,558:INFO:Creating metrics dataframe
2023-04-25 10:52:42,643:INFO:Uploading results into container
2023-04-25 10:52:42,643:INFO:Uploading model into container now
2023-04-25 10:52:42,651:INFO:_master_model_container: 7
2023-04-25 10:52:42,651:INFO:_display_container: 2
2023-04-25 10:52:42,652:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-25 10:52:42,652:INFO:create_model() successfully completed......................................
2023-04-25 10:52:42,813:INFO:SubProcess create_model() end ==================================
2023-04-25 10:52:42,813:INFO:Creating metrics dataframe
2023-04-25 10:52:42,828:INFO:Initializing Quadratic Discriminant Analysis
2023-04-25 10:52:42,828:INFO:Total runtime is 8.556763509909311 minutes
2023-04-25 10:52:42,847:INFO:SubProcess create_model() called ==================================
2023-04-25 10:52:42,847:INFO:Initializing create_model()
2023-04-25 10:52:42,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7CD6C0820>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 10:52:42,848:INFO:Checking exceptions
2023-04-25 10:52:42,848:INFO:Importing libraries
2023-04-25 10:52:42,848:INFO:Copying training dataset
2023-04-25 10:52:42,861:INFO:Defining folds
2023-04-25 10:52:42,861:INFO:Declaring metric variables
2023-04-25 10:52:42,872:INFO:Importing untrained model
2023-04-25 10:52:42,883:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-25 10:52:42,909:INFO:Starting cross validation
2023-04-25 10:52:42,946:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 10:52:57,581:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:52:57,627:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:52:57,643:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:53:09,099:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:53:09,192:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:53:44,293:INFO:Calculating mean and std
2023-04-25 10:53:44,293:INFO:Creating metrics dataframe
2023-04-25 10:53:51,972:INFO:Uploading results into container
2023-04-25 10:53:51,972:INFO:Uploading model into container now
2023-04-25 10:53:51,972:INFO:_master_model_container: 8
2023-04-25 10:53:51,972:INFO:_display_container: 2
2023-04-25 10:53:51,972:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-25 10:53:51,972:INFO:create_model() successfully completed......................................
2023-04-25 10:53:52,162:INFO:SubProcess create_model() end ==================================
2023-04-25 10:53:52,162:INFO:Creating metrics dataframe
2023-04-25 10:53:52,193:INFO:Initializing Ada Boost Classifier
2023-04-25 10:53:52,193:INFO:Total runtime is 9.712843064467112 minutes
2023-04-25 10:53:52,221:INFO:SubProcess create_model() called ==================================
2023-04-25 10:53:52,222:INFO:Initializing create_model()
2023-04-25 10:53:52,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7CD6C0820>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 10:53:52,223:INFO:Checking exceptions
2023-04-25 10:53:52,224:INFO:Importing libraries
2023-04-25 10:53:52,224:INFO:Copying training dataset
2023-04-25 10:53:52,244:INFO:Defining folds
2023-04-25 10:53:52,244:INFO:Declaring metric variables
2023-04-25 10:53:52,258:INFO:Importing untrained model
2023-04-25 10:53:52,271:INFO:Ada Boost Classifier Imported successfully
2023-04-25 10:53:52,326:INFO:Starting cross validation
2023-04-25 10:53:52,391:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 10:53:55,219:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:53:55,251:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:53:55,251:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:53:55,251:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:54:09,057:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:54:09,173:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:54:09,308:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:54:09,456:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:54:21,283:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:54:21,611:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:54:55,043:INFO:Calculating mean and std
2023-04-25 10:54:55,058:INFO:Creating metrics dataframe
2023-04-25 10:55:03,626:INFO:Uploading results into container
2023-04-25 10:55:03,626:INFO:Uploading model into container now
2023-04-25 10:55:03,629:INFO:_master_model_container: 9
2023-04-25 10:55:03,630:INFO:_display_container: 2
2023-04-25 10:55:03,631:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-04-25 10:55:03,631:INFO:create_model() successfully completed......................................
2023-04-25 10:55:03,778:INFO:SubProcess create_model() end ==================================
2023-04-25 10:55:03,789:INFO:Creating metrics dataframe
2023-04-25 10:55:03,817:INFO:Initializing Gradient Boosting Classifier
2023-04-25 10:55:03,818:INFO:Total runtime is 10.906591113408407 minutes
2023-04-25 10:55:03,827:INFO:SubProcess create_model() called ==================================
2023-04-25 10:55:03,828:INFO:Initializing create_model()
2023-04-25 10:55:03,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7CD6C0820>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 10:55:03,828:INFO:Checking exceptions
2023-04-25 10:55:03,829:INFO:Importing libraries
2023-04-25 10:55:03,829:INFO:Copying training dataset
2023-04-25 10:55:03,840:INFO:Defining folds
2023-04-25 10:55:03,841:INFO:Declaring metric variables
2023-04-25 10:55:03,850:INFO:Importing untrained model
2023-04-25 10:55:03,860:INFO:Gradient Boosting Classifier Imported successfully
2023-04-25 10:55:03,883:INFO:Starting cross validation
2023-04-25 10:55:03,917:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 10:55:06,874:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:55:06,874:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:55:06,905:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:55:06,983:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:55:21,747:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:55:21,809:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:55:21,856:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:55:22,028:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:55:35,217:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:55:35,326:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:56:10,109:INFO:Calculating mean and std
2023-04-25 10:56:10,109:INFO:Creating metrics dataframe
2023-04-25 10:56:18,345:INFO:Uploading results into container
2023-04-25 10:56:18,345:INFO:Uploading model into container now
2023-04-25 10:56:18,345:INFO:_master_model_container: 10
2023-04-25 10:56:18,345:INFO:_display_container: 2
2023-04-25 10:56:18,360:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-25 10:56:18,360:INFO:create_model() successfully completed......................................
2023-04-25 10:56:18,542:INFO:SubProcess create_model() end ==================================
2023-04-25 10:56:18,542:INFO:Creating metrics dataframe
2023-04-25 10:56:18,573:INFO:Initializing Linear Discriminant Analysis
2023-04-25 10:56:18,573:INFO:Total runtime is 12.152512172857922 minutes
2023-04-25 10:56:18,592:INFO:SubProcess create_model() called ==================================
2023-04-25 10:56:18,593:INFO:Initializing create_model()
2023-04-25 10:56:18,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7CD6C0820>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 10:56:18,595:INFO:Checking exceptions
2023-04-25 10:56:18,595:INFO:Importing libraries
2023-04-25 10:56:18,596:INFO:Copying training dataset
2023-04-25 10:56:18,613:INFO:Defining folds
2023-04-25 10:56:18,614:INFO:Declaring metric variables
2023-04-25 10:56:18,628:INFO:Importing untrained model
2023-04-25 10:56:18,646:INFO:Linear Discriminant Analysis Imported successfully
2023-04-25 10:56:18,675:INFO:Starting cross validation
2023-04-25 10:56:18,716:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 10:56:33,417:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:56:33,526:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:56:33,526:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:57:18,899:INFO:Calculating mean and std
2023-04-25 10:57:18,899:INFO:Creating metrics dataframe
2023-04-25 10:57:27,542:INFO:Uploading results into container
2023-04-25 10:57:27,542:INFO:Uploading model into container now
2023-04-25 10:57:27,554:INFO:_master_model_container: 11
2023-04-25 10:57:27,554:INFO:_display_container: 2
2023-04-25 10:57:27,555:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-25 10:57:27,556:INFO:create_model() successfully completed......................................
2023-04-25 10:57:27,723:INFO:SubProcess create_model() end ==================================
2023-04-25 10:57:27,723:INFO:Creating metrics dataframe
2023-04-25 10:57:27,754:INFO:Initializing Extra Trees Classifier
2023-04-25 10:57:27,755:INFO:Total runtime is 13.305545365810396 minutes
2023-04-25 10:57:27,764:INFO:SubProcess create_model() called ==================================
2023-04-25 10:57:27,765:INFO:Initializing create_model()
2023-04-25 10:57:27,765:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7CD6C0820>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 10:57:27,766:INFO:Checking exceptions
2023-04-25 10:57:27,766:INFO:Importing libraries
2023-04-25 10:57:27,766:INFO:Copying training dataset
2023-04-25 10:57:27,781:INFO:Defining folds
2023-04-25 10:57:27,782:INFO:Declaring metric variables
2023-04-25 10:57:27,790:INFO:Importing untrained model
2023-04-25 10:57:27,803:INFO:Extra Trees Classifier Imported successfully
2023-04-25 10:57:27,832:INFO:Starting cross validation
2023-04-25 10:57:27,867:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 10:57:31,149:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:57:31,149:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:57:31,211:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:57:31,383:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:57:46,133:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 10:57:46,788:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:57:46,866:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:57:46,960:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:57:48,125:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:58:01,178:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:58:01,444:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:58:36,073:INFO:Calculating mean and std
2023-04-25 10:58:36,089:INFO:Creating metrics dataframe
2023-04-25 10:58:45,163:INFO:Uploading results into container
2023-04-25 10:58:45,163:INFO:Uploading model into container now
2023-04-25 10:58:45,163:INFO:_master_model_container: 12
2023-04-25 10:58:45,163:INFO:_display_container: 2
2023-04-25 10:58:45,163:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-04-25 10:58:45,163:INFO:create_model() successfully completed......................................
2023-04-25 10:58:45,362:INFO:SubProcess create_model() end ==================================
2023-04-25 10:58:45,362:INFO:Creating metrics dataframe
2023-04-25 10:58:45,378:INFO:Initializing Extreme Gradient Boosting
2023-04-25 10:58:45,393:INFO:Total runtime is 14.599514178435008 minutes
2023-04-25 10:58:45,404:INFO:SubProcess create_model() called ==================================
2023-04-25 10:58:45,405:INFO:Initializing create_model()
2023-04-25 10:58:45,405:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7CD6C0820>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 10:58:45,406:INFO:Checking exceptions
2023-04-25 10:58:45,406:INFO:Importing libraries
2023-04-25 10:58:45,407:INFO:Copying training dataset
2023-04-25 10:58:45,427:INFO:Defining folds
2023-04-25 10:58:45,427:INFO:Declaring metric variables
2023-04-25 10:58:45,443:INFO:Importing untrained model
2023-04-25 10:58:45,457:INFO:Extreme Gradient Boosting Imported successfully
2023-04-25 10:58:45,486:INFO:Starting cross validation
2023-04-25 10:58:45,532:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 10:59:02,656:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:59:02,672:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:59:02,703:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:59:02,766:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:59:14,049:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:59:14,096:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 10:59:50,663:INFO:Calculating mean and std
2023-04-25 10:59:50,663:INFO:Creating metrics dataframe
2023-04-25 10:59:57,718:INFO:Uploading results into container
2023-04-25 10:59:57,718:INFO:Uploading model into container now
2023-04-25 10:59:57,722:INFO:_master_model_container: 13
2023-04-25 10:59:57,722:INFO:_display_container: 2
2023-04-25 10:59:57,725:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-25 10:59:57,726:INFO:create_model() successfully completed......................................
2023-04-25 10:59:57,893:INFO:SubProcess create_model() end ==================================
2023-04-25 10:59:57,893:INFO:Creating metrics dataframe
2023-04-25 10:59:57,949:INFO:Initializing Light Gradient Boosting Machine
2023-04-25 10:59:57,950:INFO:Total runtime is 15.808797983328502 minutes
2023-04-25 10:59:57,963:INFO:SubProcess create_model() called ==================================
2023-04-25 10:59:57,965:INFO:Initializing create_model()
2023-04-25 10:59:57,965:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7CD6C0820>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 10:59:57,966:INFO:Checking exceptions
2023-04-25 10:59:57,966:INFO:Importing libraries
2023-04-25 10:59:57,967:INFO:Copying training dataset
2023-04-25 10:59:57,985:INFO:Defining folds
2023-04-25 10:59:57,986:INFO:Declaring metric variables
2023-04-25 10:59:57,997:INFO:Importing untrained model
2023-04-25 10:59:58,010:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 10:59:58,040:INFO:Starting cross validation
2023-04-25 10:59:58,082:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 11:00:00,342:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:00:00,574:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:00:00,653:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:00:00,731:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:00:14,419:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:00:14,526:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:00:14,651:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:00:14,730:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:00:26,686:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:01:01,646:INFO:Calculating mean and std
2023-04-25 11:01:01,646:INFO:Creating metrics dataframe
2023-04-25 11:01:10,824:INFO:Uploading results into container
2023-04-25 11:01:10,824:INFO:Uploading model into container now
2023-04-25 11:01:10,824:INFO:_master_model_container: 14
2023-04-25 11:01:10,824:INFO:_display_container: 2
2023-04-25 11:01:10,824:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-25 11:01:10,824:INFO:create_model() successfully completed......................................
2023-04-25 11:01:10,975:INFO:SubProcess create_model() end ==================================
2023-04-25 11:01:10,975:INFO:Creating metrics dataframe
2023-04-25 11:01:11,013:INFO:Initializing CatBoost Classifier
2023-04-25 11:01:11,014:INFO:Total runtime is 17.02651613553365 minutes
2023-04-25 11:01:11,024:INFO:SubProcess create_model() called ==================================
2023-04-25 11:01:11,024:INFO:Initializing create_model()
2023-04-25 11:01:11,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7CD6C0820>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 11:01:11,028:INFO:Checking exceptions
2023-04-25 11:01:11,028:INFO:Importing libraries
2023-04-25 11:01:11,029:INFO:Copying training dataset
2023-04-25 11:01:11,042:INFO:Defining folds
2023-04-25 11:01:11,042:INFO:Declaring metric variables
2023-04-25 11:01:11,051:INFO:Importing untrained model
2023-04-25 11:01:11,063:INFO:CatBoost Classifier Imported successfully
2023-04-25 11:01:11,086:INFO:Starting cross validation
2023-04-25 11:01:11,120:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 11:01:25,717:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:01:26,029:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:01:26,060:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:01:51,451:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:01:51,854:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:01:52,440:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:01:53,886:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:02:15,797:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:02:16,454:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:02:40,052:INFO:Calculating mean and std
2023-04-25 11:02:40,052:INFO:Creating metrics dataframe
2023-04-25 11:02:48,449:INFO:Uploading results into container
2023-04-25 11:02:48,449:INFO:Uploading model into container now
2023-04-25 11:02:48,457:INFO:_master_model_container: 15
2023-04-25 11:02:48,457:INFO:_display_container: 2
2023-04-25 11:02:48,458:INFO:<catboost.core.CatBoostClassifier object at 0x000001C7DC635090>
2023-04-25 11:02:48,458:INFO:create_model() successfully completed......................................
2023-04-25 11:02:48,621:INFO:SubProcess create_model() end ==================================
2023-04-25 11:02:48,621:INFO:Creating metrics dataframe
2023-04-25 11:02:48,637:INFO:Initializing Dummy Classifier
2023-04-25 11:02:48,637:INFO:Total runtime is 18.653572781880698 minutes
2023-04-25 11:02:48,653:INFO:SubProcess create_model() called ==================================
2023-04-25 11:02:48,653:INFO:Initializing create_model()
2023-04-25 11:02:48,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7CD6C0820>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 11:02:48,653:INFO:Checking exceptions
2023-04-25 11:02:48,653:INFO:Importing libraries
2023-04-25 11:02:48,653:INFO:Copying training dataset
2023-04-25 11:02:48,672:INFO:Defining folds
2023-04-25 11:02:48,672:INFO:Declaring metric variables
2023-04-25 11:02:48,685:INFO:Importing untrained model
2023-04-25 11:02:48,693:INFO:Dummy Classifier Imported successfully
2023-04-25 11:02:48,715:INFO:Starting cross validation
2023-04-25 11:02:48,752:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 11:02:50,712:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 11:02:50,712:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 11:02:50,712:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 11:02:50,884:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 11:03:04,120:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:03:04,167:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:03:04,167:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:03:04,261:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:03:04,354:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 11:03:04,401:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 11:03:04,512:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 11:03:04,603:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 11:03:15,875:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 11:03:15,918:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 11:03:52,673:INFO:Calculating mean and std
2023-04-25 11:03:52,673:INFO:Creating metrics dataframe
2023-04-25 11:04:00,649:INFO:Uploading results into container
2023-04-25 11:04:00,649:INFO:Uploading model into container now
2023-04-25 11:04:00,649:INFO:_master_model_container: 16
2023-04-25 11:04:00,649:INFO:_display_container: 2
2023-04-25 11:04:00,664:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-04-25 11:04:00,664:INFO:create_model() successfully completed......................................
2023-04-25 11:04:00,869:INFO:SubProcess create_model() end ==================================
2023-04-25 11:04:00,869:INFO:Creating metrics dataframe
2023-04-25 11:04:00,925:INFO:Initializing create_model()
2023-04-25 11:04:00,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DC635090>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 11:04:00,925:INFO:Checking exceptions
2023-04-25 11:04:00,941:INFO:Importing libraries
2023-04-25 11:04:00,941:INFO:Copying training dataset
2023-04-25 11:04:00,941:INFO:Defining folds
2023-04-25 11:04:00,941:INFO:Declaring metric variables
2023-04-25 11:04:00,941:INFO:Importing untrained model
2023-04-25 11:04:00,941:INFO:Declaring custom model
2023-04-25 11:04:00,957:INFO:CatBoost Classifier Imported successfully
2023-04-25 11:04:00,974:INFO:Cross validation set to False
2023-04-25 11:04:00,974:INFO:Fitting Model
2023-04-25 11:04:11,715:INFO:<catboost.core.CatBoostClassifier object at 0x000001C7DB696890>
2023-04-25 11:04:11,715:INFO:create_model() successfully completed......................................
2023-04-25 11:04:11,949:INFO:_master_model_container: 16
2023-04-25 11:04:11,950:INFO:_display_container: 2
2023-04-25 11:04:11,951:INFO:<catboost.core.CatBoostClassifier object at 0x000001C7DB696890>
2023-04-25 11:04:11,951:INFO:compare_models() successfully completed......................................
2023-04-25 11:04:39,609:INFO:Initializing create_model()
2023-04-25 11:04:39,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DB696890>, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 11:04:39,610:INFO:Checking exceptions
2023-04-25 11:04:39,660:INFO:Importing libraries
2023-04-25 11:04:39,661:INFO:Copying training dataset
2023-04-25 11:04:39,683:INFO:Defining folds
2023-04-25 11:04:39,683:INFO:Declaring metric variables
2023-04-25 11:04:39,697:INFO:Importing untrained model
2023-04-25 11:04:39,698:INFO:Declaring custom model
2023-04-25 11:04:39,709:INFO:CatBoost Classifier Imported successfully
2023-04-25 11:04:39,737:INFO:Starting cross validation
2023-04-25 11:04:39,765:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 11:05:43,442:INFO:Calculating mean and std
2023-04-25 11:05:43,442:INFO:Creating metrics dataframe
2023-04-25 11:05:43,472:INFO:Finalizing model
2023-04-25 11:05:51,242:INFO:Uploading results into container
2023-04-25 11:05:51,246:INFO:Uploading model into container now
2023-04-25 11:05:51,284:INFO:_master_model_container: 17
2023-04-25 11:05:51,285:INFO:_display_container: 3
2023-04-25 11:05:51,285:INFO:<catboost.core.CatBoostClassifier object at 0x000001C7DC636620>
2023-04-25 11:05:51,286:INFO:create_model() successfully completed......................................
2023-04-25 11:06:27,445:INFO:Initializing tune_model()
2023-04-25 11:06:27,446:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DC636620>, fold=10, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>)
2023-04-25 11:06:27,447:INFO:Checking exceptions
2023-04-25 11:06:27,513:INFO:Copying training dataset
2023-04-25 11:06:27,534:INFO:Checking base model
2023-04-25 11:06:27,535:INFO:Base model : CatBoost Classifier
2023-04-25 11:06:27,548:INFO:Declaring metric variables
2023-04-25 11:06:27,569:INFO:Defining Hyperparameters
2023-04-25 11:06:27,882:INFO:Tuning with n_jobs=-1
2023-04-25 11:06:27,882:INFO:Initializing RandomizedSearchCV
2023-04-25 11:06:44,569:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:06:44,600:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:06:44,645:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:06:45,129:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:06:55,095:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:06:55,220:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:10:28,644:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:17:25,030:INFO:best_params: {'actual_estimator__random_strength': 0.2, 'actual_estimator__n_estimators': 180, 'actual_estimator__l2_leaf_reg': 30, 'actual_estimator__eta': 0.4, 'actual_estimator__depth': 8}
2023-04-25 11:17:25,040:INFO:Hyperparameter search completed
2023-04-25 11:17:25,040:INFO:SubProcess create_model() called ==================================
2023-04-25 11:17:25,040:INFO:Initializing create_model()
2023-04-25 11:17:25,040:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DC3309A0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7D938B1F0>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.2, 'n_estimators': 180, 'l2_leaf_reg': 30, 'eta': 0.4, 'depth': 8})
2023-04-25 11:17:25,040:INFO:Checking exceptions
2023-04-25 11:17:25,040:INFO:Importing libraries
2023-04-25 11:17:25,040:INFO:Copying training dataset
2023-04-25 11:17:25,063:INFO:Defining folds
2023-04-25 11:17:25,063:INFO:Declaring metric variables
2023-04-25 11:17:25,076:INFO:Importing untrained model
2023-04-25 11:17:25,076:INFO:Declaring custom model
2023-04-25 11:17:25,091:INFO:CatBoost Classifier Imported successfully
2023-04-25 11:17:25,106:INFO:Starting cross validation
2023-04-25 11:17:25,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 11:17:27,442:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:17:27,520:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:17:27,551:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:17:41,505:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:17:41,629:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:17:41,642:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:17:41,689:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:17:53,116:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:17:53,162:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 11:18:30,854:INFO:Calculating mean and std
2023-04-25 11:18:30,854:INFO:Creating metrics dataframe
2023-04-25 11:18:30,867:INFO:Finalizing model
2023-04-25 11:18:38,532:INFO:Uploading results into container
2023-04-25 11:18:38,534:INFO:Uploading model into container now
2023-04-25 11:18:38,536:INFO:_master_model_container: 18
2023-04-25 11:18:38,536:INFO:_display_container: 4
2023-04-25 11:18:38,537:INFO:<catboost.core.CatBoostClassifier object at 0x000001C7DC29C070>
2023-04-25 11:18:38,537:INFO:create_model() successfully completed......................................
2023-04-25 11:18:38,736:INFO:SubProcess create_model() end ==================================
2023-04-25 11:18:38,736:INFO:choose_better activated
2023-04-25 11:18:38,736:INFO:SubProcess create_model() called ==================================
2023-04-25 11:18:38,736:INFO:Initializing create_model()
2023-04-25 11:18:38,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DC636620>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 11:18:38,751:INFO:Checking exceptions
2023-04-25 11:18:38,757:INFO:Importing libraries
2023-04-25 11:18:38,757:INFO:Copying training dataset
2023-04-25 11:18:38,777:INFO:Defining folds
2023-04-25 11:18:38,777:INFO:Declaring metric variables
2023-04-25 11:18:38,777:INFO:Importing untrained model
2023-04-25 11:18:38,777:INFO:Declaring custom model
2023-04-25 11:18:38,778:INFO:CatBoost Classifier Imported successfully
2023-04-25 11:18:38,779:INFO:Starting cross validation
2023-04-25 11:18:38,801:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 11:19:40,573:INFO:Calculating mean and std
2023-04-25 11:19:40,573:INFO:Creating metrics dataframe
2023-04-25 11:19:40,573:INFO:Finalizing model
2023-04-25 11:19:50,280:INFO:Uploading results into container
2023-04-25 11:19:50,280:INFO:Uploading model into container now
2023-04-25 11:19:50,280:INFO:_master_model_container: 19
2023-04-25 11:19:50,280:INFO:_display_container: 5
2023-04-25 11:19:50,280:INFO:<catboost.core.CatBoostClassifier object at 0x000001C7DC5C2770>
2023-04-25 11:19:50,280:INFO:create_model() successfully completed......................................
2023-04-25 11:19:50,452:INFO:SubProcess create_model() end ==================================
2023-04-25 11:19:50,452:INFO:<catboost.core.CatBoostClassifier object at 0x000001C7DC5C2770> result for Accuracy is 0.7489
2023-04-25 11:19:50,452:INFO:<catboost.core.CatBoostClassifier object at 0x000001C7DC29C070> result for Accuracy is 0.7505
2023-04-25 11:19:50,452:INFO:<catboost.core.CatBoostClassifier object at 0x000001C7DC29C070> is best model
2023-04-25 11:19:50,452:INFO:choose_better completed
2023-04-25 11:19:50,481:INFO:_master_model_container: 19
2023-04-25 11:19:50,481:INFO:_display_container: 4
2023-04-25 11:19:50,482:INFO:<catboost.core.CatBoostClassifier object at 0x000001C7DC29C070>
2023-04-25 11:19:50,482:INFO:tune_model() successfully completed......................................
2023-04-25 11:31:15,499:INFO:Initializing evaluate_model()
2023-04-25 11:31:15,500:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DC636620>, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-04-25 11:31:15,545:INFO:Initializing plot_model()
2023-04-25 11:31:15,546:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DC636620>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, system=True)
2023-04-25 11:31:15,547:INFO:Checking exceptions
2023-04-25 11:31:15,554:INFO:Preloading libraries
2023-04-25 11:31:15,558:INFO:Copying training dataset
2023-04-25 11:31:15,559:INFO:Plot type: pipeline
2023-04-25 11:31:16,249:INFO:Visual Rendered Successfully
2023-04-25 11:31:16,461:INFO:plot_model() successfully completed......................................
2023-04-25 11:31:18,801:INFO:Initializing predict_model()
2023-04-25 11:31:18,802:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DC29C070>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001C7DA65BD00>)
2023-04-25 11:31:18,802:INFO:Checking exceptions
2023-04-25 11:31:18,803:INFO:Preloading libraries
2023-04-25 11:31:38,832:INFO:Initializing predict_model()
2023-04-25 11:31:38,832:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DC29C070>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001C7DB6BE680>)
2023-04-25 11:31:38,832:INFO:Checking exceptions
2023-04-25 11:31:38,833:INFO:Preloading libraries
2023-04-25 11:31:38,838:INFO:Set up data.
2023-04-25 11:31:38,869:INFO:Set up index.
2023-04-25 11:31:55,310:INFO:Initializing finalize_model()
2023-04-25 11:31:55,310:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DC29C070>, fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-25 11:31:55,310:INFO:Finalizing <catboost.core.CatBoostClassifier object at 0x000001C7DC29C070>
2023-04-25 11:31:55,320:INFO:Initializing create_model()
2023-04-25 11:31:55,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DC29C070>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-25 11:31:55,320:INFO:Checking exceptions
2023-04-25 11:31:55,325:INFO:Importing libraries
2023-04-25 11:31:55,326:INFO:Copying training dataset
2023-04-25 11:31:55,327:INFO:Defining folds
2023-04-25 11:31:55,327:INFO:Declaring metric variables
2023-04-25 11:31:55,328:INFO:Importing untrained model
2023-04-25 11:31:55,329:INFO:Declaring custom model
2023-04-25 11:31:55,329:INFO:CatBoost Classifier Imported successfully
2023-04-25 11:31:55,351:INFO:Cross validation set to False
2023-04-25 11:31:55,352:INFO:Fitting Model
2023-04-25 11:31:58,014:INFO:Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=10,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001C7DBFDFBB0>)],
         verbose=False)
2023-04-25 11:31:58,014:INFO:create_model() successfully completed......................................
2023-04-25 11:31:58,155:INFO:_master_model_container: 19
2023-04-25 11:31:58,155:INFO:_display_container: 6
2023-04-25 11:31:58,217:INFO:Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=10,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001C7DBFDFBB0>)],
         verbose=False)
2023-04-25 11:31:58,217:INFO:finalize_model() successfully completed......................................
2023-04-25 11:32:06,190:INFO:Initializing save_model()
2023-04-25 11:32:06,190:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=10,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001C7DBFDFBB0>)],
         verbose=False), model_name=Final CB Model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=10,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-25 11:32:06,190:INFO:Adding model into prep_pipe
2023-04-25 11:32:06,190:WARNING:Only Model saved as it was a pipeline.
2023-04-25 11:32:06,190:INFO:Final CB Model.pkl saved in current working directory
2023-04-25 11:32:06,190:INFO:<catboost.core.CatBoostClassifier object at 0x000001C7D8F1F4C0>
2023-04-25 11:32:06,190:INFO:save_model() successfully completed......................................
2023-04-25 11:33:12,616:INFO:Initializing predict_model()
2023-04-25 11:33:12,617:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DC636620>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001C7DB65B520>)
2023-04-25 11:33:12,617:INFO:Checking exceptions
2023-04-25 11:33:12,617:INFO:Preloading libraries
2023-04-25 11:33:30,678:INFO:Initializing predict_model()
2023-04-25 11:33:30,679:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DC29C070>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001C7DA65BD00>)
2023-04-25 11:33:30,680:INFO:Checking exceptions
2023-04-25 11:33:30,680:INFO:Preloading libraries
2023-04-25 11:34:04,710:INFO:Initializing predict_model()
2023-04-25 11:34:04,710:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DC29C070>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001C7DA65BF40>)
2023-04-25 11:34:04,711:INFO:Checking exceptions
2023-04-25 11:34:04,711:INFO:Preloading libraries
2023-04-25 11:34:07,973:INFO:Initializing predict_model()
2023-04-25 11:34:07,973:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DC29C070>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001C7DB6BF370>)
2023-04-25 11:34:07,974:INFO:Checking exceptions
2023-04-25 11:34:07,974:INFO:Preloading libraries
2023-04-25 11:34:07,980:INFO:Set up data.
2023-04-25 11:34:08,016:INFO:Set up index.
2023-04-25 11:38:18,926:INFO:Initializing plot_model()
2023-04-25 11:38:18,926:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DC636620>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, system=True)
2023-04-25 11:38:18,927:INFO:Checking exceptions
2023-04-25 11:38:18,932:INFO:Preloading libraries
2023-04-25 11:38:18,936:INFO:Copying training dataset
2023-04-25 11:38:18,936:INFO:Plot type: feature
2023-04-25 11:38:18,936:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 11:38:19,353:INFO:Visual Rendered Successfully
2023-04-25 11:38:19,509:INFO:plot_model() successfully completed......................................
2023-04-25 11:38:58,575:INFO:Initializing plot_model()
2023-04-25 11:38:58,575:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DC636620>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, system=True)
2023-04-25 11:38:58,576:INFO:Checking exceptions
2023-04-25 11:38:58,584:INFO:Preloading libraries
2023-04-25 11:38:58,587:INFO:Copying training dataset
2023-04-25 11:38:58,588:INFO:Plot type: rfe
2023-04-25 11:38:59,068:INFO:Fitting Model
2023-04-25 11:56:27,956:INFO:Initializing load_model()
2023-04-25 11:56:27,956:INFO:load_model(model_name=credit_api, platform=None, authentication=None, verbose=True)
2023-04-25 11:56:28,507:INFO:Initializing plot_model()
2023-04-25 11:56:28,509:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001C7DC636620>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7D937B1F0>, system=True)
2023-04-25 11:56:28,509:INFO:Checking exceptions
2023-04-25 11:56:28,515:INFO:Preloading libraries
2023-04-25 11:56:28,519:INFO:Copying training dataset
2023-04-25 11:56:28,519:INFO:Plot type: feature
2023-04-25 11:56:28,520:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 11:56:28,979:INFO:Visual Rendered Successfully
2023-04-25 11:56:29,182:INFO:plot_model() successfully completed......................................
2023-04-25 11:57:13,658:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 11:57:13,658:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 11:57:13,658:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 11:57:13,658:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 11:57:16,088:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-25 11:57:21,052:INFO:Initializing load_model()
2023-04-25 11:57:21,052:INFO:load_model(model_name=credit_api, platform=None, authentication=None, verbose=True)
2023-04-25 16:13:45,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 16:13:45,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 16:13:45,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 16:13:45,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 16:13:46,971:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-25 16:14:26,325:INFO:PyCaret ClassificationExperiment
2023-04-25 16:14:26,325:INFO:Logging name: clf-default-name
2023-04-25 16:14:26,325:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-25 16:14:26,325:INFO:version 3.0.0
2023-04-25 16:14:26,325:INFO:Initializing setup()
2023-04-25 16:14:26,325:INFO:self.USI: 48ac
2023-04-25 16:14:26,325:INFO:self._variable_keys: {'fold_groups_param', 'gpu_param', 'y', 'gpu_n_jobs_param', 'n_jobs_param', 'html_param', 'exp_name_log', 'idx', 'fold_generator', 'USI', 'is_multiclass', 'exp_id', 'pipeline', 'y_test', '_available_plots', 'logging_param', 'memory', 'seed', 'target_param', 'fix_imbalance', 'y_train', '_ml_usecase', 'log_plots_param', 'X_train', 'X', 'data', 'X_test', 'fold_shuffle_param'}
2023-04-25 16:14:26,325:INFO:Checking environment
2023-04-25 16:14:26,325:INFO:python_version: 3.10.9
2023-04-25 16:14:26,325:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-04-25 16:14:26,325:INFO:machine: AMD64
2023-04-25 16:14:26,325:INFO:platform: Windows-10-10.0.19044-SP0
2023-04-25 16:14:26,325:INFO:Memory: svmem(total=8483184640, available=4101894144, percent=51.6, used=4381290496, free=4101894144)
2023-04-25 16:14:26,325:INFO:Physical Core: 2
2023-04-25 16:14:26,325:INFO:Logical Core: 4
2023-04-25 16:14:26,325:INFO:Checking libraries
2023-04-25 16:14:26,325:INFO:System:
2023-04-25 16:14:26,325:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-04-25 16:14:26,325:INFO:executable: C:\Users\User\.conda\envs\My_envI\python.exe
2023-04-25 16:14:26,325:INFO:   machine: Windows-10-10.0.19044-SP0
2023-04-25 16:14:26,325:INFO:PyCaret required dependencies:
2023-04-25 16:14:26,325:INFO:                 pip: 22.3.1
2023-04-25 16:14:26,325:INFO:          setuptools: 66.0.0
2023-04-25 16:14:26,325:INFO:             pycaret: 3.0.0
2023-04-25 16:14:26,325:INFO:             IPython: 8.12.0
2023-04-25 16:14:26,325:INFO:          ipywidgets: 7.6.5
2023-04-25 16:14:26,325:INFO:                tqdm: 4.64.1
2023-04-25 16:14:26,325:INFO:               numpy: 1.23.5
2023-04-25 16:14:26,325:INFO:              pandas: 1.5.3
2023-04-25 16:14:26,325:INFO:              jinja2: 3.1.2
2023-04-25 16:14:26,325:INFO:               scipy: 1.10.1
2023-04-25 16:14:26,325:INFO:              joblib: 1.2.0
2023-04-25 16:14:26,325:INFO:             sklearn: 1.2.1
2023-04-25 16:14:26,325:INFO:                pyod: 1.0.9
2023-04-25 16:14:26,325:INFO:            imblearn: 0.10.1
2023-04-25 16:14:26,325:INFO:   category_encoders: 2.6.0
2023-04-25 16:14:26,325:INFO:            lightgbm: 3.3.5
2023-04-25 16:14:26,325:INFO:               numba: 0.56.4
2023-04-25 16:14:26,325:INFO:            requests: 2.28.1
2023-04-25 16:14:26,325:INFO:          matplotlib: 3.7.0
2023-04-25 16:14:26,325:INFO:          scikitplot: 0.3.7
2023-04-25 16:14:26,325:INFO:         yellowbrick: 1.5
2023-04-25 16:14:26,325:INFO:              plotly: 5.14.1
2023-04-25 16:14:26,325:INFO:             kaleido: 0.2.1
2023-04-25 16:14:26,325:INFO:         statsmodels: 0.13.5
2023-04-25 16:14:26,325:INFO:              sktime: 0.17.0
2023-04-25 16:14:26,325:INFO:               tbats: 1.1.2
2023-04-25 16:14:26,325:INFO:            pmdarima: 2.0.3
2023-04-25 16:14:26,325:INFO:              psutil: 5.9.0
2023-04-25 16:14:26,325:INFO:PyCaret optional dependencies:
2023-04-25 16:14:27,326:INFO:                shap: 0.41.0
2023-04-25 16:14:27,326:INFO:           interpret: 0.3.2
2023-04-25 16:14:27,326:INFO:                umap: 0.5.3
2023-04-25 16:14:27,326:INFO:    pandas_profiling: 4.1.2
2023-04-25 16:14:27,326:INFO:  explainerdashboard: 0.4.2.1
2023-04-25 16:14:27,326:INFO:             autoviz: 0.1.58
2023-04-25 16:14:27,326:INFO:           fairlearn: 0.7.0
2023-04-25 16:14:27,326:INFO:             xgboost: 1.7.5
2023-04-25 16:14:27,326:INFO:            catboost: 1.1.1
2023-04-25 16:14:27,326:INFO:              kmodes: 0.12.2
2023-04-25 16:14:27,326:INFO:             mlxtend: 0.22.0
2023-04-25 16:14:27,326:INFO:       statsforecast: 1.5.0
2023-04-25 16:14:27,326:INFO:        tune_sklearn: 0.4.5
2023-04-25 16:14:27,326:INFO:                 ray: 2.3.1
2023-04-25 16:14:27,326:INFO:            hyperopt: 0.2.7
2023-04-25 16:14:27,326:INFO:              optuna: 3.1.0
2023-04-25 16:14:27,326:INFO:               skopt: 0.9.0
2023-04-25 16:14:27,326:INFO:              mlflow: 1.30.1
2023-04-25 16:14:27,326:INFO:              gradio: Not installed
2023-04-25 16:14:27,326:INFO:             fastapi: 0.89.1
2023-04-25 16:14:27,326:INFO:             uvicorn: 0.21.1
2023-04-25 16:14:27,326:INFO:              m2cgen: 0.10.0
2023-04-25 16:14:27,326:INFO:           evidently: 0.2.8
2023-04-25 16:14:27,326:INFO:               fugue: 0.8.3
2023-04-25 16:14:27,326:INFO:           streamlit: Not installed
2023-04-25 16:14:27,326:INFO:             prophet: Not installed
2023-04-25 16:14:27,326:INFO:None
2023-04-25 16:14:27,326:INFO:Set up data.
2023-04-25 16:14:27,357:INFO:Set up train/test split.
2023-04-25 16:14:27,389:INFO:Set up index.
2023-04-25 16:14:27,389:INFO:Set up folding strategy.
2023-04-25 16:14:27,389:INFO:Assigning column types.
2023-04-25 16:14:27,389:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 16:14:27,498:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 16:14:27,498:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 16:14:27,623:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 16:14:28,448:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-25 16:14:28,589:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 16:14:28,589:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 16:14:28,651:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 16:14:28,651:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-25 16:14:28,651:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 16:14:28,745:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 16:14:28,792:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 16:14:28,807:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-25 16:14:28,885:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 16:14:28,945:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 16:14:28,945:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-25 16:14:28,945:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-25 16:14:29,104:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 16:14:29,104:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-25 16:14:29,302:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 16:14:29,302:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-25 16:14:29,333:INFO:Preparing preprocessing pipeline...
2023-04-25 16:14:29,333:INFO:Set up label encoding.
2023-04-25 16:14:29,333:INFO:Set up simple imputation.
2023-04-25 16:14:29,333:INFO:Set up encoding of ordinal features.
2023-04-25 16:14:29,348:INFO:Set up encoding of categorical features.
2023-04-25 16:14:29,348:INFO:Set up imbalanced handling.
2023-04-25 16:14:29,348:INFO:Set up feature normalization.
2023-04-25 16:14:29,950:INFO:Finished creating preprocessing pipeline.
2023-04-25 16:14:30,055:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['checking_status', 'duration',
                                             'credit_amount', 'savings_status',
                                             'employment',
                                             'installment_commitment',
                                             '...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2023-04-25 16:14:30,055:INFO:Creating final display dataframe.
2023-04-25 16:14:30,980:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             class
2                   Target type            Binary
3                Target mapping   bad: 0, good: 1
4           Original data shape         (950, 22)
5        Transformed data shape        (1217, 50)
6   Transformed train set shape         (932, 50)
7    Transformed test set shape         (285, 50)
8              Ordinal features                 3
9              Numeric features                10
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19                    Normalize              True
20             Normalize method            minmax
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              48ac
2023-04-25 16:14:31,257:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 16:14:31,272:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-25 16:14:31,397:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-25 16:14:31,397:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-25 16:14:31,397:INFO:setup() successfully completed in 13.53s...............
2023-04-25 16:14:41,988:INFO:Initializing get_config()
2023-04-25 16:14:41,989:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, variable=X_transformed)
2023-04-25 16:14:42,208:INFO:Variable: X returned as      checking_status  duration  credit_history_critical/other existing credit  \
405         0.333333  0.035714                                            1.0   
802         0.000000  0.142857                                            1.0   
368         0.000000  0.250000                                            0.0   
503         0.000000  0.303571                                            1.0   
619         0.333333  0.035714                                            1.0   
..               ...       ...                                            ...   
416         0.000000  0.250000                                            1.0   
771         0.000000  0.321429                                            0.0   
319         0.000000  0.250000                                            0.0   
219         0.333333  0.142857                                            0.0   
311         0.000000  0.357143                                            0.0   

     credit_history_existing paid  credit_history_delayed previously  \
405                           0.0                                0.0   
802                           0.0                                0.0   
368                           1.0                                0.0   
503                           0.0                                0.0   
619                           0.0                                0.0   
..                            ...                                ...   
416                           0.0                                0.0   
771                           1.0                                0.0   
319                           1.0                                0.0   
219                           1.0                                0.0   
311                           1.0                                0.0   

     credit_history_all paid  credit_history_no credits/all paid  \
405                      0.0                                 0.0   
802                      0.0                                 0.0   
368                      0.0                                 0.0   
503                      0.0                                 0.0   
619                      0.0                                 0.0   
..                       ...                                 ...   
416                      0.0                                 0.0   
771                      0.0                                 0.0   
319                      0.0                                 0.0   
219                      0.0                                 0.0   
311                      0.0                                 0.0   

     purpose_radio/tv  purpose_furniture/equipment  purpose_new car  ...  \
405               1.0                          0.0              0.0  ...   
802               0.0                          1.0              0.0  ...   
368               0.0                          1.0              0.0  ...   
503               0.0                          0.0              1.0  ...   
619               0.0                          0.0              1.0  ...   
..                ...                          ...              ...  ...   
416               0.0                          0.0              1.0  ...   
771               0.0                          0.0              1.0  ...   
319               0.0                          0.0              1.0  ...   
219               1.0                          0.0              0.0  ...   
311               0.0                          0.0              1.0  ...   

     job_unskilled resident  job_unemp/unskilled non res  num_dependents  \
405                     0.0                          0.0             0.0   
802                     0.0                          0.0             0.0   
368                     0.0                          0.0             0.0   
503                     0.0                          0.0             0.0   
619                     0.0                          0.0             0.0   
..                      ...                          ...             ...   
416                     0.0                          0.0             0.0   
771                     0.0                          0.0             0.0   
319                     0.0                          0.0             0.0   
219                     1.0                          0.0             0.0   
311                     0.0                          0.0             0.0   

     own_telephone  foreign_worker  sex  marital_status_single  \
405            0.0             1.0  1.0                    1.0   
802            1.0             1.0  0.0                    0.0   
368            1.0             1.0  1.0                    1.0   
503            1.0             1.0  1.0                    1.0   
619            1.0             1.0  0.0                    0.0   
..             ...             ...  ...                    ...   
416            0.0             1.0  1.0                    1.0   
771            0.0             1.0  0.0                    0.0   
319            0.0             0.0  1.0                    1.0   
219            0.0             1.0  1.0                    0.0   
311            1.0             1.0  0.0                    0.0   

     marital_status_div/dep/mar  marital_status_mar/wid  \
405                         0.0                     0.0   
802                         1.0                     0.0   
368                         0.0                     0.0   
503                         0.0                     0.0   
619                         1.0                     0.0   
..                          ...                     ...   
416                         0.0                     0.0   
771                         1.0                     0.0   
319                         0.0                     0.0   
219                         0.0                     1.0   
311                         1.0                     0.0   

     marital_status_div/sep  
405                     0.0  
802                     0.0  
368                     0.0  
503                     0.0  
619                     0.0  
..                      ...  
416                     0.0  
771                     0.0  
319                     0.0  
219                     0.0  
311                     0.0  

[1217 rows x 49 columns]
2023-04-25 16:14:42,208:INFO:get_config() successfully completed......................................
2023-04-25 16:14:45,221:INFO:Initializing compare_models()
2023-04-25 16:14:45,221:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-25 16:14:45,222:INFO:Checking exceptions
2023-04-25 16:14:45,237:INFO:Preparing display monitor
2023-04-25 16:14:45,327:INFO:Initializing Logistic Regression
2023-04-25 16:14:45,327:INFO:Total runtime is 0.0 minutes
2023-04-25 16:14:45,341:INFO:SubProcess create_model() called ==================================
2023-04-25 16:14:45,342:INFO:Initializing create_model()
2023-04-25 16:14:45,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020500B1D8D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:14:45,343:INFO:Checking exceptions
2023-04-25 16:14:45,343:INFO:Importing libraries
2023-04-25 16:14:45,344:INFO:Copying training dataset
2023-04-25 16:14:45,359:INFO:Defining folds
2023-04-25 16:14:45,360:INFO:Declaring metric variables
2023-04-25 16:14:45,372:INFO:Importing untrained model
2023-04-25 16:14:45,384:INFO:Logistic Regression Imported successfully
2023-04-25 16:14:45,400:INFO:Starting cross validation
2023-04-25 16:14:45,408:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:15:25,470:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 16:16:00,622:INFO:Calculating mean and std
2023-04-25 16:16:00,638:INFO:Creating metrics dataframe
2023-04-25 16:16:09,594:INFO:Uploading results into container
2023-04-25 16:16:09,594:INFO:Uploading model into container now
2023-04-25 16:16:09,594:INFO:_master_model_container: 1
2023-04-25 16:16:09,594:INFO:_display_container: 2
2023-04-25 16:16:09,594:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-25 16:16:09,594:INFO:create_model() successfully completed......................................
2023-04-25 16:16:09,753:INFO:SubProcess create_model() end ==================================
2023-04-25 16:16:09,753:INFO:Creating metrics dataframe
2023-04-25 16:16:09,780:INFO:Initializing K Neighbors Classifier
2023-04-25 16:16:09,781:INFO:Total runtime is 1.4075576861699421 minutes
2023-04-25 16:16:09,790:INFO:SubProcess create_model() called ==================================
2023-04-25 16:16:09,791:INFO:Initializing create_model()
2023-04-25 16:16:09,792:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020500B1D8D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:16:09,792:INFO:Checking exceptions
2023-04-25 16:16:09,792:INFO:Importing libraries
2023-04-25 16:16:09,792:INFO:Copying training dataset
2023-04-25 16:16:09,807:INFO:Defining folds
2023-04-25 16:16:09,807:INFO:Declaring metric variables
2023-04-25 16:16:09,815:INFO:Importing untrained model
2023-04-25 16:16:09,826:INFO:K Neighbors Classifier Imported successfully
2023-04-25 16:16:09,863:INFO:Starting cross validation
2023-04-25 16:16:09,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:17:15,487:INFO:Calculating mean and std
2023-04-25 16:17:15,487:INFO:Creating metrics dataframe
2023-04-25 16:17:24,338:INFO:Uploading results into container
2023-04-25 16:17:24,338:INFO:Uploading model into container now
2023-04-25 16:17:24,338:INFO:_master_model_container: 2
2023-04-25 16:17:24,338:INFO:_display_container: 2
2023-04-25 16:17:24,338:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-25 16:17:24,338:INFO:create_model() successfully completed......................................
2023-04-25 16:17:24,511:INFO:SubProcess create_model() end ==================================
2023-04-25 16:17:24,511:INFO:Creating metrics dataframe
2023-04-25 16:17:24,557:INFO:Initializing Naive Bayes
2023-04-25 16:17:24,557:INFO:Total runtime is 2.653828132152557 minutes
2023-04-25 16:17:24,569:INFO:SubProcess create_model() called ==================================
2023-04-25 16:17:24,570:INFO:Initializing create_model()
2023-04-25 16:17:24,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020500B1D8D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:17:24,571:INFO:Checking exceptions
2023-04-25 16:17:24,572:INFO:Importing libraries
2023-04-25 16:17:24,572:INFO:Copying training dataset
2023-04-25 16:17:24,592:INFO:Defining folds
2023-04-25 16:17:24,593:INFO:Declaring metric variables
2023-04-25 16:17:24,607:INFO:Importing untrained model
2023-04-25 16:17:24,621:INFO:Naive Bayes Imported successfully
2023-04-25 16:17:24,658:INFO:Starting cross validation
2023-04-25 16:17:24,671:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:18:31,043:INFO:Calculating mean and std
2023-04-25 16:18:31,043:INFO:Creating metrics dataframe
2023-04-25 16:18:38,232:INFO:Uploading results into container
2023-04-25 16:18:38,234:INFO:Uploading model into container now
2023-04-25 16:18:38,235:INFO:_master_model_container: 3
2023-04-25 16:18:38,235:INFO:_display_container: 2
2023-04-25 16:18:38,235:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-25 16:18:38,236:INFO:create_model() successfully completed......................................
2023-04-25 16:18:38,379:INFO:SubProcess create_model() end ==================================
2023-04-25 16:18:38,379:INFO:Creating metrics dataframe
2023-04-25 16:18:38,394:INFO:Initializing Decision Tree Classifier
2023-04-25 16:18:38,394:INFO:Total runtime is 3.8844467639923095 minutes
2023-04-25 16:18:38,419:INFO:SubProcess create_model() called ==================================
2023-04-25 16:18:38,420:INFO:Initializing create_model()
2023-04-25 16:18:38,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020500B1D8D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:18:38,421:INFO:Checking exceptions
2023-04-25 16:18:38,421:INFO:Importing libraries
2023-04-25 16:18:38,421:INFO:Copying training dataset
2023-04-25 16:18:38,440:INFO:Defining folds
2023-04-25 16:18:38,440:INFO:Declaring metric variables
2023-04-25 16:18:38,450:INFO:Importing untrained model
2023-04-25 16:18:38,470:INFO:Decision Tree Classifier Imported successfully
2023-04-25 16:18:38,504:INFO:Starting cross validation
2023-04-25 16:18:38,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:19:41,854:INFO:Calculating mean and std
2023-04-25 16:19:41,854:INFO:Creating metrics dataframe
2023-04-25 16:19:51,271:INFO:Uploading results into container
2023-04-25 16:19:51,271:INFO:Uploading model into container now
2023-04-25 16:19:51,287:INFO:_master_model_container: 4
2023-04-25 16:19:51,296:INFO:_display_container: 2
2023-04-25 16:19:51,297:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-04-25 16:19:51,297:INFO:create_model() successfully completed......................................
2023-04-25 16:19:51,469:INFO:SubProcess create_model() end ==================================
2023-04-25 16:19:51,469:INFO:Creating metrics dataframe
2023-04-25 16:19:51,510:INFO:Initializing SVM - Linear Kernel
2023-04-25 16:19:51,510:INFO:Total runtime is 5.103036550680796 minutes
2023-04-25 16:19:51,517:INFO:SubProcess create_model() called ==================================
2023-04-25 16:19:51,518:INFO:Initializing create_model()
2023-04-25 16:19:51,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020500B1D8D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:19:51,519:INFO:Checking exceptions
2023-04-25 16:19:51,519:INFO:Importing libraries
2023-04-25 16:19:51,519:INFO:Copying training dataset
2023-04-25 16:19:51,540:INFO:Defining folds
2023-04-25 16:19:51,540:INFO:Declaring metric variables
2023-04-25 16:19:51,553:INFO:Importing untrained model
2023-04-25 16:19:51,567:INFO:SVM - Linear Kernel Imported successfully
2023-04-25 16:19:51,597:INFO:Starting cross validation
2023-04-25 16:19:51,613:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:19:52,483:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 16:19:52,483:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 16:19:52,483:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 16:20:06,952:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 16:20:06,984:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 16:20:07,062:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 16:20:07,062:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 16:20:17,847:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 16:20:17,893:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 16:20:57,910:INFO:Calculating mean and std
2023-04-25 16:20:57,910:INFO:Creating metrics dataframe
2023-04-25 16:21:06,010:INFO:Uploading results into container
2023-04-25 16:21:06,010:INFO:Uploading model into container now
2023-04-25 16:21:06,010:INFO:_master_model_container: 5
2023-04-25 16:21:06,010:INFO:_display_container: 2
2023-04-25 16:21:06,027:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-25 16:21:06,028:INFO:create_model() successfully completed......................................
2023-04-25 16:21:06,197:INFO:SubProcess create_model() end ==================================
2023-04-25 16:21:06,197:INFO:Creating metrics dataframe
2023-04-25 16:21:06,228:INFO:Initializing Ridge Classifier
2023-04-25 16:21:06,228:INFO:Total runtime is 6.348351196448008 minutes
2023-04-25 16:21:06,243:INFO:SubProcess create_model() called ==================================
2023-04-25 16:21:06,244:INFO:Initializing create_model()
2023-04-25 16:21:06,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020500B1D8D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:21:06,246:INFO:Checking exceptions
2023-04-25 16:21:06,246:INFO:Importing libraries
2023-04-25 16:21:06,246:INFO:Copying training dataset
2023-04-25 16:21:06,267:INFO:Defining folds
2023-04-25 16:21:06,267:INFO:Declaring metric variables
2023-04-25 16:21:06,281:INFO:Importing untrained model
2023-04-25 16:21:06,296:INFO:Ridge Classifier Imported successfully
2023-04-25 16:21:06,325:INFO:Starting cross validation
2023-04-25 16:21:06,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:21:07,234:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 16:21:07,250:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 16:21:07,266:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 16:21:07,297:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 16:21:19,453:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 16:21:19,609:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 16:21:19,624:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 16:21:19,640:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 16:21:31,201:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 16:21:31,232:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 16:22:10,767:INFO:Calculating mean and std
2023-04-25 16:22:10,767:INFO:Creating metrics dataframe
2023-04-25 16:22:19,195:INFO:Uploading results into container
2023-04-25 16:22:19,195:INFO:Uploading model into container now
2023-04-25 16:22:19,195:INFO:_master_model_container: 6
2023-04-25 16:22:19,195:INFO:_display_container: 2
2023-04-25 16:22:19,195:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-04-25 16:22:19,195:INFO:create_model() successfully completed......................................
2023-04-25 16:22:19,349:INFO:SubProcess create_model() end ==================================
2023-04-25 16:22:19,349:INFO:Creating metrics dataframe
2023-04-25 16:22:19,385:INFO:Initializing Random Forest Classifier
2023-04-25 16:22:19,385:INFO:Total runtime is 7.567621266841888 minutes
2023-04-25 16:22:19,397:INFO:SubProcess create_model() called ==================================
2023-04-25 16:22:19,399:INFO:Initializing create_model()
2023-04-25 16:22:19,399:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020500B1D8D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:22:19,400:INFO:Checking exceptions
2023-04-25 16:22:19,400:INFO:Importing libraries
2023-04-25 16:22:19,400:INFO:Copying training dataset
2023-04-25 16:22:19,417:INFO:Defining folds
2023-04-25 16:22:19,418:INFO:Declaring metric variables
2023-04-25 16:22:19,430:INFO:Importing untrained model
2023-04-25 16:22:19,444:INFO:Random Forest Classifier Imported successfully
2023-04-25 16:22:19,476:INFO:Starting cross validation
2023-04-25 16:22:19,489:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:23:24,168:INFO:Calculating mean and std
2023-04-25 16:23:24,168:INFO:Creating metrics dataframe
2023-04-25 16:23:33,221:INFO:Uploading results into container
2023-04-25 16:23:33,221:INFO:Uploading model into container now
2023-04-25 16:23:33,221:INFO:_master_model_container: 7
2023-04-25 16:23:33,221:INFO:_display_container: 2
2023-04-25 16:23:33,221:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-25 16:23:33,221:INFO:create_model() successfully completed......................................
2023-04-25 16:23:33,391:INFO:SubProcess create_model() end ==================================
2023-04-25 16:23:33,391:INFO:Creating metrics dataframe
2023-04-25 16:23:33,423:INFO:Initializing Quadratic Discriminant Analysis
2023-04-25 16:23:33,423:INFO:Total runtime is 8.801585765679677 minutes
2023-04-25 16:23:33,443:INFO:SubProcess create_model() called ==================================
2023-04-25 16:23:33,443:INFO:Initializing create_model()
2023-04-25 16:23:33,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020500B1D8D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:23:33,443:INFO:Checking exceptions
2023-04-25 16:23:33,443:INFO:Importing libraries
2023-04-25 16:23:33,443:INFO:Copying training dataset
2023-04-25 16:23:33,458:INFO:Defining folds
2023-04-25 16:23:33,458:INFO:Declaring metric variables
2023-04-25 16:23:33,478:INFO:Importing untrained model
2023-04-25 16:23:33,490:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-25 16:23:33,527:INFO:Starting cross validation
2023-04-25 16:23:33,545:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:23:34,285:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 16:23:34,285:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 16:23:34,332:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 16:23:34,407:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 16:23:47,701:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 16:23:47,701:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 16:23:47,764:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 16:23:47,857:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 16:23:59,239:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 16:23:59,271:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 16:24:41,051:INFO:Calculating mean and std
2023-04-25 16:24:41,051:INFO:Creating metrics dataframe
2023-04-25 16:24:48,636:INFO:Uploading results into container
2023-04-25 16:24:48,636:INFO:Uploading model into container now
2023-04-25 16:24:48,636:INFO:_master_model_container: 8
2023-04-25 16:24:48,652:INFO:_display_container: 2
2023-04-25 16:24:48,652:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-25 16:24:48,652:INFO:create_model() successfully completed......................................
2023-04-25 16:24:48,814:INFO:SubProcess create_model() end ==================================
2023-04-25 16:24:48,814:INFO:Creating metrics dataframe
2023-04-25 16:24:48,859:INFO:Initializing Ada Boost Classifier
2023-04-25 16:24:48,859:INFO:Total runtime is 10.058858080705006 minutes
2023-04-25 16:24:48,872:INFO:SubProcess create_model() called ==================================
2023-04-25 16:24:48,872:INFO:Initializing create_model()
2023-04-25 16:24:48,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020500B1D8D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:24:48,874:INFO:Checking exceptions
2023-04-25 16:24:48,874:INFO:Importing libraries
2023-04-25 16:24:48,874:INFO:Copying training dataset
2023-04-25 16:24:48,891:INFO:Defining folds
2023-04-25 16:24:48,891:INFO:Declaring metric variables
2023-04-25 16:24:48,905:INFO:Importing untrained model
2023-04-25 16:24:48,918:INFO:Ada Boost Classifier Imported successfully
2023-04-25 16:24:48,950:INFO:Starting cross validation
2023-04-25 16:24:48,965:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:25:54,128:INFO:Calculating mean and std
2023-04-25 16:25:54,128:INFO:Creating metrics dataframe
2023-04-25 16:26:02,631:INFO:Uploading results into container
2023-04-25 16:26:02,631:INFO:Uploading model into container now
2023-04-25 16:26:02,631:INFO:_master_model_container: 9
2023-04-25 16:26:02,631:INFO:_display_container: 2
2023-04-25 16:26:02,631:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-04-25 16:26:02,631:INFO:create_model() successfully completed......................................
2023-04-25 16:26:02,779:INFO:SubProcess create_model() end ==================================
2023-04-25 16:26:02,779:INFO:Creating metrics dataframe
2023-04-25 16:26:02,810:INFO:Initializing Gradient Boosting Classifier
2023-04-25 16:26:02,810:INFO:Total runtime is 11.291381076971689 minutes
2023-04-25 16:26:02,810:INFO:SubProcess create_model() called ==================================
2023-04-25 16:26:02,810:INFO:Initializing create_model()
2023-04-25 16:26:02,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020500B1D8D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:26:02,810:INFO:Checking exceptions
2023-04-25 16:26:02,810:INFO:Importing libraries
2023-04-25 16:26:02,810:INFO:Copying training dataset
2023-04-25 16:26:02,843:INFO:Defining folds
2023-04-25 16:26:02,843:INFO:Declaring metric variables
2023-04-25 16:26:02,857:INFO:Importing untrained model
2023-04-25 16:26:02,872:INFO:Gradient Boosting Classifier Imported successfully
2023-04-25 16:26:02,898:INFO:Starting cross validation
2023-04-25 16:26:02,911:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:26:04,598:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 16:26:04,661:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 16:26:18,957:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 16:26:19,098:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 16:26:19,098:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 16:26:19,223:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 16:26:31,097:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 16:26:31,331:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 16:27:07,340:INFO:Calculating mean and std
2023-04-25 16:27:07,340:INFO:Creating metrics dataframe
2023-04-25 16:27:16,049:INFO:Uploading results into container
2023-04-25 16:27:16,049:INFO:Uploading model into container now
2023-04-25 16:27:16,049:INFO:_master_model_container: 10
2023-04-25 16:27:16,049:INFO:_display_container: 2
2023-04-25 16:27:16,049:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-25 16:27:16,049:INFO:create_model() successfully completed......................................
2023-04-25 16:27:16,221:INFO:SubProcess create_model() end ==================================
2023-04-25 16:27:16,221:INFO:Creating metrics dataframe
2023-04-25 16:27:16,236:INFO:Initializing Linear Discriminant Analysis
2023-04-25 16:27:16,236:INFO:Total runtime is 12.515147217114766 minutes
2023-04-25 16:27:16,259:INFO:SubProcess create_model() called ==================================
2023-04-25 16:27:16,259:INFO:Initializing create_model()
2023-04-25 16:27:16,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020500B1D8D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:27:16,259:INFO:Checking exceptions
2023-04-25 16:27:16,259:INFO:Importing libraries
2023-04-25 16:27:16,259:INFO:Copying training dataset
2023-04-25 16:27:16,275:INFO:Defining folds
2023-04-25 16:27:16,275:INFO:Declaring metric variables
2023-04-25 16:27:16,300:INFO:Importing untrained model
2023-04-25 16:27:16,314:INFO:Linear Discriminant Analysis Imported successfully
2023-04-25 16:27:16,344:INFO:Starting cross validation
2023-04-25 16:27:16,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:28:22,755:INFO:Calculating mean and std
2023-04-25 16:28:22,755:INFO:Creating metrics dataframe
2023-04-25 16:28:30,417:INFO:Uploading results into container
2023-04-25 16:28:30,417:INFO:Uploading model into container now
2023-04-25 16:28:30,417:INFO:_master_model_container: 11
2023-04-25 16:28:30,417:INFO:_display_container: 2
2023-04-25 16:28:30,417:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-25 16:28:30,417:INFO:create_model() successfully completed......................................
2023-04-25 16:28:30,567:INFO:SubProcess create_model() end ==================================
2023-04-25 16:28:30,567:INFO:Creating metrics dataframe
2023-04-25 16:28:30,598:INFO:Initializing Extra Trees Classifier
2023-04-25 16:28:30,598:INFO:Total runtime is 13.754508884747823 minutes
2023-04-25 16:28:30,598:INFO:SubProcess create_model() called ==================================
2023-04-25 16:28:30,598:INFO:Initializing create_model()
2023-04-25 16:28:30,598:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020500B1D8D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:28:30,598:INFO:Checking exceptions
2023-04-25 16:28:30,598:INFO:Importing libraries
2023-04-25 16:28:30,598:INFO:Copying training dataset
2023-04-25 16:28:30,627:INFO:Defining folds
2023-04-25 16:28:30,627:INFO:Declaring metric variables
2023-04-25 16:28:30,636:INFO:Importing untrained model
2023-04-25 16:28:30,645:INFO:Extra Trees Classifier Imported successfully
2023-04-25 16:28:30,671:INFO:Starting cross validation
2023-04-25 16:28:30,683:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:29:53,922:INFO:Calculating mean and std
2023-04-25 16:29:53,939:INFO:Creating metrics dataframe
2023-04-25 16:30:04,284:INFO:Uploading results into container
2023-04-25 16:30:04,286:INFO:Uploading model into container now
2023-04-25 16:30:04,287:INFO:_master_model_container: 12
2023-04-25 16:30:04,287:INFO:_display_container: 2
2023-04-25 16:30:04,290:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-04-25 16:30:04,293:INFO:create_model() successfully completed......................................
2023-04-25 16:30:04,447:INFO:SubProcess create_model() end ==================================
2023-04-25 16:30:04,448:INFO:Creating metrics dataframe
2023-04-25 16:30:04,479:INFO:Initializing Extreme Gradient Boosting
2023-04-25 16:30:04,480:INFO:Total runtime is 15.319218039512634 minutes
2023-04-25 16:30:04,492:INFO:SubProcess create_model() called ==================================
2023-04-25 16:30:04,493:INFO:Initializing create_model()
2023-04-25 16:30:04,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020500B1D8D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:30:04,494:INFO:Checking exceptions
2023-04-25 16:30:04,494:INFO:Importing libraries
2023-04-25 16:30:04,494:INFO:Copying training dataset
2023-04-25 16:30:04,509:INFO:Defining folds
2023-04-25 16:30:04,509:INFO:Declaring metric variables
2023-04-25 16:30:04,522:INFO:Importing untrained model
2023-04-25 16:30:04,532:INFO:Extreme Gradient Boosting Imported successfully
2023-04-25 16:30:04,562:INFO:Starting cross validation
2023-04-25 16:30:04,572:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:31:16,575:INFO:Calculating mean and std
2023-04-25 16:31:16,575:INFO:Creating metrics dataframe
2023-04-25 16:31:24,224:INFO:Uploading results into container
2023-04-25 16:31:24,224:INFO:Uploading model into container now
2023-04-25 16:31:24,224:INFO:_master_model_container: 13
2023-04-25 16:31:24,224:INFO:_display_container: 2
2023-04-25 16:31:24,230:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-25 16:31:24,235:INFO:create_model() successfully completed......................................
2023-04-25 16:31:24,379:INFO:SubProcess create_model() end ==================================
2023-04-25 16:31:24,379:INFO:Creating metrics dataframe
2023-04-25 16:31:24,410:INFO:Initializing Light Gradient Boosting Machine
2023-04-25 16:31:24,410:INFO:Total runtime is 16.651377002398174 minutes
2023-04-25 16:31:24,428:INFO:SubProcess create_model() called ==================================
2023-04-25 16:31:24,429:INFO:Initializing create_model()
2023-04-25 16:31:24,430:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020500B1D8D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:31:24,430:INFO:Checking exceptions
2023-04-25 16:31:24,431:INFO:Importing libraries
2023-04-25 16:31:24,431:INFO:Copying training dataset
2023-04-25 16:31:24,443:INFO:Defining folds
2023-04-25 16:31:24,444:INFO:Declaring metric variables
2023-04-25 16:31:24,454:INFO:Importing untrained model
2023-04-25 16:31:24,468:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 16:31:24,494:INFO:Starting cross validation
2023-04-25 16:31:24,504:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:32:31,071:INFO:Calculating mean and std
2023-04-25 16:32:31,071:INFO:Creating metrics dataframe
2023-04-25 16:32:40,934:INFO:Uploading results into container
2023-04-25 16:32:40,934:INFO:Uploading model into container now
2023-04-25 16:32:40,934:INFO:_master_model_container: 14
2023-04-25 16:32:40,934:INFO:_display_container: 2
2023-04-25 16:32:40,943:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-25 16:32:40,943:INFO:create_model() successfully completed......................................
2023-04-25 16:32:41,090:INFO:SubProcess create_model() end ==================================
2023-04-25 16:32:41,090:INFO:Creating metrics dataframe
2023-04-25 16:32:41,105:INFO:Initializing CatBoost Classifier
2023-04-25 16:32:41,105:INFO:Total runtime is 17.92963214715322 minutes
2023-04-25 16:32:41,129:INFO:SubProcess create_model() called ==================================
2023-04-25 16:32:41,129:INFO:Initializing create_model()
2023-04-25 16:32:41,129:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020500B1D8D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:32:41,129:INFO:Checking exceptions
2023-04-25 16:32:41,129:INFO:Importing libraries
2023-04-25 16:32:41,129:INFO:Copying training dataset
2023-04-25 16:32:41,145:INFO:Defining folds
2023-04-25 16:32:41,145:INFO:Declaring metric variables
2023-04-25 16:32:41,153:INFO:Importing untrained model
2023-04-25 16:32:41,169:INFO:CatBoost Classifier Imported successfully
2023-04-25 16:32:41,193:INFO:Starting cross validation
2023-04-25 16:32:41,209:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:33:48,451:INFO:Calculating mean and std
2023-04-25 16:33:48,451:INFO:Creating metrics dataframe
2023-04-25 16:33:57,457:INFO:Uploading results into container
2023-04-25 16:33:57,457:INFO:Uploading model into container now
2023-04-25 16:33:57,457:INFO:_master_model_container: 15
2023-04-25 16:33:57,457:INFO:_display_container: 2
2023-04-25 16:33:57,457:INFO:<catboost.core.CatBoostClassifier object at 0x0000020504084B80>
2023-04-25 16:33:57,457:INFO:create_model() successfully completed......................................
2023-04-25 16:33:57,632:INFO:SubProcess create_model() end ==================================
2023-04-25 16:33:57,632:INFO:Creating metrics dataframe
2023-04-25 16:33:57,679:INFO:Initializing Dummy Classifier
2023-04-25 16:33:57,679:INFO:Total runtime is 19.205864437421166 minutes
2023-04-25 16:33:57,690:INFO:SubProcess create_model() called ==================================
2023-04-25 16:33:57,690:INFO:Initializing create_model()
2023-04-25 16:33:57,690:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020500B1D8D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:33:57,690:INFO:Checking exceptions
2023-04-25 16:33:57,690:INFO:Importing libraries
2023-04-25 16:33:57,690:INFO:Copying training dataset
2023-04-25 16:33:57,714:INFO:Defining folds
2023-04-25 16:33:57,714:INFO:Declaring metric variables
2023-04-25 16:33:57,730:INFO:Importing untrained model
2023-04-25 16:33:57,738:INFO:Dummy Classifier Imported successfully
2023-04-25 16:33:57,778:INFO:Starting cross validation
2023-04-25 16:33:57,786:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:33:58,770:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 16:33:58,785:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 16:33:58,785:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 16:33:58,801:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 16:34:12,584:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 16:34:12,600:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 16:34:12,615:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 16:34:12,678:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 16:34:23,414:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 16:34:23,445:WARNING:C:\Users\User\.conda\envs\My_envI\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 16:35:02,978:INFO:Calculating mean and std
2023-04-25 16:35:02,978:INFO:Creating metrics dataframe
2023-04-25 16:35:10,375:INFO:Uploading results into container
2023-04-25 16:35:10,375:INFO:Uploading model into container now
2023-04-25 16:35:10,375:INFO:_master_model_container: 16
2023-04-25 16:35:10,375:INFO:_display_container: 2
2023-04-25 16:35:10,375:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-04-25 16:35:10,375:INFO:create_model() successfully completed......................................
2023-04-25 16:35:10,520:INFO:SubProcess create_model() end ==================================
2023-04-25 16:35:10,520:INFO:Creating metrics dataframe
2023-04-25 16:35:10,578:INFO:Initializing create_model()
2023-04-25 16:35:10,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=<catboost.core.CatBoostClassifier object at 0x0000020504084B80>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:35:10,579:INFO:Checking exceptions
2023-04-25 16:35:10,583:INFO:Importing libraries
2023-04-25 16:35:10,583:INFO:Copying training dataset
2023-04-25 16:35:10,599:INFO:Defining folds
2023-04-25 16:35:10,599:INFO:Declaring metric variables
2023-04-25 16:35:10,599:INFO:Importing untrained model
2023-04-25 16:35:10,599:INFO:Declaring custom model
2023-04-25 16:35:10,600:INFO:CatBoost Classifier Imported successfully
2023-04-25 16:35:10,604:INFO:Cross validation set to False
2023-04-25 16:35:10,604:INFO:Fitting Model
2023-04-25 16:35:16,556:INFO:<catboost.core.CatBoostClassifier object at 0x0000020503F16CB0>
2023-04-25 16:35:16,556:INFO:create_model() successfully completed......................................
2023-04-25 16:35:16,852:INFO:_master_model_container: 16
2023-04-25 16:35:16,852:INFO:_display_container: 2
2023-04-25 16:35:16,853:INFO:<catboost.core.CatBoostClassifier object at 0x0000020503F16CB0>
2023-04-25 16:35:16,853:INFO:compare_models() successfully completed......................................
2023-04-25 16:41:32,565:INFO:Initializing create_model()
2023-04-25 16:41:32,565:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=<catboost.core.CatBoostClassifier object at 0x0000020503F16CB0>, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:41:32,565:INFO:Checking exceptions
2023-04-25 16:41:32,621:INFO:Importing libraries
2023-04-25 16:41:32,622:INFO:Copying training dataset
2023-04-25 16:41:32,645:INFO:Defining folds
2023-04-25 16:41:32,645:INFO:Declaring metric variables
2023-04-25 16:41:32,657:INFO:Importing untrained model
2023-04-25 16:41:32,657:INFO:Declaring custom model
2023-04-25 16:41:32,669:INFO:CatBoost Classifier Imported successfully
2023-04-25 16:41:32,696:INFO:Starting cross validation
2023-04-25 16:41:32,705:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:42:56,905:INFO:Calculating mean and std
2023-04-25 16:42:56,905:INFO:Creating metrics dataframe
2023-04-25 16:42:56,920:INFO:Finalizing model
2023-04-25 16:43:06,411:INFO:Uploading results into container
2023-04-25 16:43:06,425:INFO:Uploading model into container now
2023-04-25 16:43:06,463:INFO:_master_model_container: 17
2023-04-25 16:43:06,463:INFO:_display_container: 3
2023-04-25 16:43:06,464:INFO:<catboost.core.CatBoostClassifier object at 0x00000205040867D0>
2023-04-25 16:43:06,464:INFO:create_model() successfully completed......................................
2023-04-25 16:43:25,850:INFO:Initializing tune_model()
2023-04-25 16:43:25,851:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x00000205040867D0>, fold=10, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>)
2023-04-25 16:43:25,851:INFO:Checking exceptions
2023-04-25 16:43:25,908:INFO:Copying training dataset
2023-04-25 16:43:25,921:INFO:Checking base model
2023-04-25 16:43:25,922:INFO:Base model : CatBoost Classifier
2023-04-25 16:43:25,935:INFO:Declaring metric variables
2023-04-25 16:43:25,946:INFO:Defining Hyperparameters
2023-04-25 16:43:26,157:INFO:Tuning with n_jobs=-1
2023-04-25 16:43:26,157:INFO:Initializing RandomizedSearchCV
2023-04-25 16:54:51,966:INFO:best_params: {'actual_estimator__random_strength': 0.7, 'actual_estimator__n_estimators': 250, 'actual_estimator__l2_leaf_reg': 50, 'actual_estimator__eta': 0.15, 'actual_estimator__depth': 3}
2023-04-25 16:54:51,966:INFO:Hyperparameter search completed
2023-04-25 16:54:51,966:INFO:SubProcess create_model() called ==================================
2023-04-25 16:54:51,966:INFO:Initializing create_model()
2023-04-25 16:54:51,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=<catboost.core.CatBoostClassifier object at 0x0000020503DE3A00>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020500B1D8D0>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.7, 'n_estimators': 250, 'l2_leaf_reg': 50, 'eta': 0.15, 'depth': 3})
2023-04-25 16:54:51,966:INFO:Checking exceptions
2023-04-25 16:54:51,966:INFO:Importing libraries
2023-04-25 16:54:51,966:INFO:Copying training dataset
2023-04-25 16:54:51,986:INFO:Defining folds
2023-04-25 16:54:51,986:INFO:Declaring metric variables
2023-04-25 16:54:51,999:INFO:Importing untrained model
2023-04-25 16:54:52,000:INFO:Declaring custom model
2023-04-25 16:54:52,015:INFO:CatBoost Classifier Imported successfully
2023-04-25 16:54:52,037:INFO:Starting cross validation
2023-04-25 16:54:52,050:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:55:57,111:INFO:Calculating mean and std
2023-04-25 16:55:57,111:INFO:Creating metrics dataframe
2023-04-25 16:55:57,135:INFO:Finalizing model
2023-04-25 16:56:06,647:INFO:Uploading results into container
2023-04-25 16:56:06,650:INFO:Uploading model into container now
2023-04-25 16:56:06,651:INFO:_master_model_container: 18
2023-04-25 16:56:06,652:INFO:_display_container: 4
2023-04-25 16:56:06,652:INFO:<catboost.core.CatBoostClassifier object at 0x0000020503D4F850>
2023-04-25 16:56:06,652:INFO:create_model() successfully completed......................................
2023-04-25 16:56:06,849:INFO:SubProcess create_model() end ==================================
2023-04-25 16:56:06,849:INFO:choose_better activated
2023-04-25 16:56:06,849:INFO:SubProcess create_model() called ==================================
2023-04-25 16:56:06,849:INFO:Initializing create_model()
2023-04-25 16:56:06,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=<catboost.core.CatBoostClassifier object at 0x00000205040867D0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 16:56:06,849:INFO:Checking exceptions
2023-04-25 16:56:06,849:INFO:Importing libraries
2023-04-25 16:56:06,865:INFO:Copying training dataset
2023-04-25 16:56:06,883:INFO:Defining folds
2023-04-25 16:56:06,883:INFO:Declaring metric variables
2023-04-25 16:56:06,884:INFO:Importing untrained model
2023-04-25 16:56:06,884:INFO:Declaring custom model
2023-04-25 16:56:06,884:INFO:CatBoost Classifier Imported successfully
2023-04-25 16:56:06,884:INFO:Starting cross validation
2023-04-25 16:56:06,892:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 16:57:13,556:INFO:Calculating mean and std
2023-04-25 16:57:13,556:INFO:Creating metrics dataframe
2023-04-25 16:57:13,556:INFO:Finalizing model
2023-04-25 16:57:21,157:INFO:Uploading results into container
2023-04-25 16:57:21,157:INFO:Uploading model into container now
2023-04-25 16:57:21,157:INFO:_master_model_container: 19
2023-04-25 16:57:21,157:INFO:_display_container: 5
2023-04-25 16:57:21,157:INFO:<catboost.core.CatBoostClassifier object at 0x0000020503E83160>
2023-04-25 16:57:21,157:INFO:create_model() successfully completed......................................
2023-04-25 16:57:21,313:INFO:SubProcess create_model() end ==================================
2023-04-25 16:57:21,313:INFO:<catboost.core.CatBoostClassifier object at 0x0000020503E83160> result for Accuracy is 0.7579
2023-04-25 16:57:21,313:INFO:<catboost.core.CatBoostClassifier object at 0x0000020503D4F850> result for Accuracy is 0.7595
2023-04-25 16:57:21,313:INFO:<catboost.core.CatBoostClassifier object at 0x0000020503D4F850> is best model
2023-04-25 16:57:21,313:INFO:choose_better completed
2023-04-25 16:57:21,329:INFO:_master_model_container: 19
2023-04-25 16:57:21,329:INFO:_display_container: 4
2023-04-25 16:57:21,329:INFO:<catboost.core.CatBoostClassifier object at 0x0000020503D4F850>
2023-04-25 16:57:21,329:INFO:tune_model() successfully completed......................................
2023-04-25 16:58:04,160:INFO:Initializing evaluate_model()
2023-04-25 16:58:04,161:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=<catboost.core.CatBoostClassifier object at 0x0000020503D4F850>, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-04-25 16:58:04,208:INFO:Initializing plot_model()
2023-04-25 16:58:04,209:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000020503D4F850>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, system=True)
2023-04-25 16:58:04,209:INFO:Checking exceptions
2023-04-25 16:58:04,216:INFO:Preloading libraries
2023-04-25 16:58:04,216:INFO:Copying training dataset
2023-04-25 16:58:04,217:INFO:Plot type: pipeline
2023-04-25 16:58:04,727:INFO:Visual Rendered Successfully
2023-04-25 16:58:04,852:INFO:plot_model() successfully completed......................................
2023-04-25 16:58:09,945:INFO:Initializing plot_model()
2023-04-25 16:58:09,946:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000020503D4F850>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, system=True)
2023-04-25 16:58:09,946:INFO:Checking exceptions
2023-04-25 16:58:09,955:INFO:Preloading libraries
2023-04-25 16:58:09,956:INFO:Copying training dataset
2023-04-25 16:58:09,957:INFO:Plot type: feature
2023-04-25 16:58:09,958:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 16:58:10,476:INFO:Visual Rendered Successfully
2023-04-25 16:58:10,648:INFO:plot_model() successfully completed......................................
2023-04-25 16:58:42,528:INFO:Initializing predict_model()
2023-04-25 16:58:42,529:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=<catboost.core.CatBoostClassifier object at 0x0000020503D4F850>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000020575FD8550>)
2023-04-25 16:58:42,529:INFO:Checking exceptions
2023-04-25 16:58:42,530:INFO:Preloading libraries
2023-04-25 17:00:17,767:INFO:Initializing predict_model()
2023-04-25 17:00:17,768:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020501743790>, estimator=<catboost.core.CatBoostClassifier object at 0x0000020503D4F850>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000020503D33880>)
2023-04-25 17:00:17,768:INFO:Checking exceptions
2023-04-25 17:00:17,769:INFO:Preloading libraries
2023-04-25 17:00:17,774:INFO:Set up data.
2023-04-25 17:00:17,814:INFO:Set up index.
